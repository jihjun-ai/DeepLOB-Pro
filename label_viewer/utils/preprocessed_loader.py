"""
é è™•ç†æ•¸æ“šè¼‰å…¥æ¨¡çµ„

åŠŸèƒ½ï¼š
1. è¼‰å…¥ preprocess_single_day.py ç”¢ç”Ÿçš„ NPZ æ•¸æ“š
2. è§£æ label_preview è³‡è¨Š
3. ç”Ÿæˆæ—¥æœŸ/è‚¡ç¥¨åˆ—è¡¨
4. LRU Cache å¿«å–æ©Ÿåˆ¶

ä½œè€…ï¼šDeepLOB-Pro Team
æœ€å¾Œæ›´æ–°ï¼š2025-10-23
"""

import os
import json
import functools
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import numpy as np


@functools.lru_cache(maxsize=10)
def load_preprocessed_stock(npz_path: str) -> Dict:
    """
    è¼‰å…¥å–®ä¸€è‚¡ç¥¨çš„é è™•ç†æ•¸æ“š

    Args:
        npz_path: NPZ æª”æ¡ˆè·¯å¾‘

    Returns:
        å­—å…¸ï¼ŒåŒ…å«ï¼š
        - features: (T, 20) LOB ç‰¹å¾µ
        - mids: (T,) ä¸­é–“åƒ¹
        - metadata: å…ƒæ•¸æ“šå­—å…¸ï¼ˆåŒ…å« label_previewï¼‰
        - bucket_event_count: æ¯ç§’äº‹ä»¶æ•¸
        - bucket_mask: æ™‚é–“æ¡¶é®ç½©

    Raises:
        FileNotFoundError: æª”æ¡ˆä¸å­˜åœ¨
        ValueError: æ•¸æ“šæ ¼å¼éŒ¯èª¤
    """
    if not Path(npz_path).exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {npz_path}")

    print(f"[INFO] è¼‰å…¥é è™•ç†æ•¸æ“š: {npz_path}")

    # è¼‰å…¥ NPZ
    data = np.load(npz_path, allow_pickle=True)

    # æª¢æŸ¥å¿…è¦éµ
    required_keys = ['features', 'mids', 'metadata']
    actual_keys = list(data.keys())
    missing_keys = set(required_keys) - set(actual_keys)

    if missing_keys:
        raise ValueError(f"ç¼ºå°‘å¿…è¦éµ: {missing_keys}ï¼Œæª”æ¡ˆéµ: {actual_keys}")

    # è§£æ metadata
    metadata_str = str(data['metadata'])
    try:
        metadata = json.loads(metadata_str)
    except json.JSONDecodeError as e:
        raise ValueError(f"ç„¡æ³•è§£æ metadata: {e}")

    return {
        'features': data['features'],
        'mids': data['mids'],
        'metadata': metadata,
        'bucket_event_count': data.get('bucket_event_count', None),
        'bucket_mask': data.get('bucket_mask', None),
        'labels': data.get('labels', None)  # ğŸ†• è®€å–æ¨™ç±¤æ•¸æ“šï¼ˆå¦‚æœæœ‰ï¼‰
    }


def scan_preprocessed_directory(preprocessed_dir: str) -> Dict[str, List[str]]:
    """
    æƒæé è™•ç†æ•¸æ“šç›®éŒ„ï¼Œç”Ÿæˆæ—¥æœŸå’Œè‚¡ç¥¨åˆ—è¡¨

    Args:
        preprocessed_dir: é è™•ç†æ•¸æ“šæ ¹ç›®éŒ„
            ä¾‹å¦‚: data/preprocessed_v5 æˆ– data/preprocessed_v5_1hz

    Returns:
        å­—å…¸ï¼š
        {
            'dates': ['20250901', '20250902', ...],
            'stocks_by_date': {
                '20250901': ['2330', '2317', ...],
                '20250902': [...],
            }
        }

    ç›®éŒ„çµæ§‹ï¼š
        preprocessed_dir/
        â””â”€â”€ daily/
            â”œâ”€â”€ 20250901/
            â”‚   â”œâ”€â”€ 2330.npz
            â”‚   â”œâ”€â”€ 2317.npz
            â”‚   â””â”€â”€ summary.json
            â”œâ”€â”€ 20250902/
            â”‚   â”œâ”€â”€ ...
    """
    daily_dir = Path(preprocessed_dir) / "daily"

    if not daily_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° daily ç›®éŒ„: {daily_dir}")

    dates = []
    stocks_by_date = {}

    # éæ­·æ—¥æœŸç›®éŒ„
    for date_dir in sorted(daily_dir.iterdir()):
        if not date_dir.is_dir():
            continue

        date = date_dir.name
        dates.append(date)

        # æƒæè©²æ—¥æœŸçš„è‚¡ç¥¨ NPZ
        stocks = []
        for npz_file in sorted(date_dir.glob("*.npz")):
            symbol = npz_file.stem  # å»æ‰ .npz å¾Œç¶´
            stocks.append(symbol)

        stocks_by_date[date] = stocks

    print(f"[INFO] æƒæå®Œæˆ:")
    print(f"  æ‰¾åˆ° {len(dates)} å€‹äº¤æ˜“æ—¥")
    total_stocks = sum(len(stocks) for stocks in stocks_by_date.values())
    print(f"  æ‰¾åˆ° {total_stocks} å€‹è‚¡ç¥¨æ•¸æ“š")

    return {
        'dates': dates,
        'stocks_by_date': stocks_by_date
    }


def get_label_preview_stats(preprocessed_dir: str, date: str) -> Dict:
    """
    ç²å–æŒ‡å®šæ—¥æœŸçš„æ¨™ç±¤é è¦½çµ±è¨ˆ

    Args:
        preprocessed_dir: é è™•ç†æ•¸æ“šæ ¹ç›®éŒ„
        date: æ—¥æœŸï¼ˆä¾‹å¦‚ '20250901'ï¼‰

    Returns:
        å­—å…¸ï¼ŒåŒ…å«ï¼š
        - total_stocks: ç¸½è‚¡ç¥¨æ•¸
        - stocks_with_labels: æœ‰æ¨™ç±¤é è¦½çš„è‚¡ç¥¨æ•¸
        - overall_dist: æ•´é«”æ¨™ç±¤åˆ†å¸ƒ (down_pct, neutral_pct, up_pct)
        - stock_details: æ¯å€‹è‚¡ç¥¨çš„æ¨™ç±¤é è¦½ [(symbol, label_preview), ...]
    """
    daily_dir = Path(preprocessed_dir) / "daily" / date

    if not daily_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ—¥æœŸç›®éŒ„: {daily_dir}")

    stock_details = []
    total_down = 0
    total_neutral = 0
    total_up = 0
    stocks_with_labels = 0

    # éæ­·è©²æ—¥æœŸçš„æ‰€æœ‰ NPZ
    for npz_file in sorted(daily_dir.glob("*.npz")):
        symbol = npz_file.stem

        try:
            stock_data = load_preprocessed_stock(str(npz_file))
            metadata = stock_data['metadata']

            # æª¢æŸ¥æ˜¯å¦æœ‰ label_preview
            if 'label_preview' in metadata and metadata['label_preview'] is not None:
                lp = metadata['label_preview']
                stock_details.append((symbol, lp))

                # ç´¯åŠ çµ±è¨ˆ
                total_down += lp['down_count']
                total_neutral += lp['neutral_count']
                total_up += lp['up_count']
                stocks_with_labels += 1
            else:
                stock_details.append((symbol, None))

        except Exception as e:
            print(f"[WARN] è¼‰å…¥ {symbol} å¤±æ•—: {e}")
            stock_details.append((symbol, None))

    # è¨ˆç®—æ•´é«”åˆ†å¸ƒ
    total_all = total_down + total_neutral + total_up
    if total_all > 0:
        overall_dist = {
            'down_pct': total_down / total_all,
            'neutral_pct': total_neutral / total_all,
            'up_pct': total_up / total_all,
            'total_labels': total_all
        }
    else:
        overall_dist = None

    return {
        'total_stocks': len(stock_details),
        'stocks_with_labels': stocks_with_labels,
        'overall_dist': overall_dist,
        'stock_details': stock_details
    }


def load_summary_json(preprocessed_dir: str, date: str) -> Optional[Dict]:
    """
    è¼‰å…¥ summary.json

    Args:
        preprocessed_dir: é è™•ç†æ•¸æ“šæ ¹ç›®éŒ„
        date: æ—¥æœŸï¼ˆä¾‹å¦‚ '20250901'ï¼‰

    Returns:
        summary å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡è¿”å› None
    """
    summary_path = Path(preprocessed_dir) / "daily" / date / "summary.json"

    if not summary_path.exists():
        print(f"[WARN] æ‰¾ä¸åˆ° summary.json: {summary_path}")
        return None

    with open(summary_path, 'r', encoding='utf-8') as f:
        summary = json.load(f)

    return summary


# ============================================================================
# å¿«å–ç®¡ç†
# ============================================================================

def get_cache_info() -> str:
    """ç²å–å¿«å–çµ±è¨ˆè³‡è¨Š"""
    info = load_preprocessed_stock.cache_info()
    return (
        f"å¿«å–çµ±è¨ˆï¼šå‘½ä¸­ {info.hits} æ¬¡ï¼Œ"
        f"æœªå‘½ä¸­ {info.misses} æ¬¡ï¼Œ"
        f"ç•¶å‰å¤§å° {info.currsize}/{info.maxsize}"
    )


def clear_cache():
    """æ¸…é™¤å¿«å–"""
    load_preprocessed_stock.cache_clear()
    print("[INFO] å¿«å–å·²æ¸…é™¤")


# ============================================================================
# ä¾¿åˆ©å‡½æ•¸
# ============================================================================

def get_stock_list_for_date(preprocessed_dir: str, date: str,
                            filter_by_label: bool = True) -> List[Tuple[str, Optional[Dict]]]:
    """
    ç²å–æŒ‡å®šæ—¥æœŸçš„è‚¡ç¥¨åˆ—è¡¨

    Args:
        preprocessed_dir: é è™•ç†æ•¸æ“šæ ¹ç›®éŒ„
        date: æ—¥æœŸ
        filter_by_label: æ˜¯å¦åªè¿”å›æœ‰æ¨™ç±¤é è¦½çš„è‚¡ç¥¨

    Returns:
        [(symbol, label_preview), ...]
        æŒ‰æ¨™ç±¤ç¸½æ•¸æ’åºï¼ˆå¤šçš„åœ¨å‰ï¼‰
    """
    stats = get_label_preview_stats(preprocessed_dir, date)
    stock_details = stats['stock_details']

    if filter_by_label:
        # éæ¿¾æ‰æ²’æœ‰æ¨™ç±¤é è¦½çš„è‚¡ç¥¨
        stock_details = [(sym, lp) for sym, lp in stock_details if lp is not None]

    # æŒ‰æ¨™ç±¤ç¸½æ•¸æ’åºï¼ˆå¤šçš„åœ¨å‰ï¼‰
    stock_details_sorted = sorted(
        stock_details,
        key=lambda x: x[1]['total_labels'] if x[1] else 0,
        reverse=True
    )

    return stock_details_sorted


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    import sys

    if len(sys.argv) > 1:
        preprocessed_dir = sys.argv[1]
    else:
        preprocessed_dir = "data/preprocessed_v5_1hz"

    print(f"æ¸¬è©¦è¼‰å…¥é è™•ç†æ•¸æ“š: {preprocessed_dir}\n")

    # æ¸¬è©¦ 1: æƒæç›®éŒ„
    print("="*70)
    print("æ¸¬è©¦ 1: æƒæç›®éŒ„")
    print("="*70)
    try:
        dir_info = scan_preprocessed_directory(preprocessed_dir)
        print(f"æ‰¾åˆ°æ—¥æœŸ: {dir_info['dates'][:5]} ...")
        for date in dir_info['dates'][:2]:
            print(f"  {date}: {len(dir_info['stocks_by_date'][date])} æª”è‚¡ç¥¨")
    except Exception as e:
        print(f"éŒ¯èª¤: {e}")

    # æ¸¬è©¦ 2: è¼‰å…¥å–®ä¸€è‚¡ç¥¨
    if 'dates' in locals() and len(dir_info['dates']) > 0:
        test_date = dir_info['dates'][0]
        test_stocks = dir_info['stocks_by_date'][test_date][:2]

        print(f"\n{'='*70}")
        print(f"æ¸¬è©¦ 2: è¼‰å…¥è‚¡ç¥¨æ•¸æ“š ({test_date})")
        print("="*70)

        for symbol in test_stocks:
            npz_path = f"{preprocessed_dir}/daily/{test_date}/{symbol}.npz"
            try:
                stock_data = load_preprocessed_stock(npz_path)
                print(f"\n{symbol}:")
                print(f"  Features shape: {stock_data['features'].shape}")
                print(f"  Mids shape: {stock_data['mids'].shape}")
                print(f"  Pass filter: {stock_data['metadata'].get('pass_filter', 'N/A')}")

                if 'label_preview' in stock_data['metadata']:
                    lp = stock_data['metadata']['label_preview']
                    if lp:
                        print(f"  Label preview:")
                        print(f"    Total: {lp['total_labels']}")
                        print(f"    Down: {lp['down_pct']:.1%}")
                        print(f"    Neutral: {lp['neutral_pct']:.1%}")
                        print(f"    Up: {lp['up_pct']:.1%}")
            except Exception as e:
                print(f"  éŒ¯èª¤: {e}")

    # æ¸¬è©¦ 3: ç²å–æ¨™ç±¤çµ±è¨ˆ
    if 'dates' in locals() and len(dir_info['dates']) > 0:
        test_date = dir_info['dates'][0]

        print(f"\n{'='*70}")
        print(f"æ¸¬è©¦ 3: æ¨™ç±¤é è¦½çµ±è¨ˆ ({test_date})")
        print("="*70)

        try:
            stats = get_label_preview_stats(preprocessed_dir, test_date)
            print(f"ç¸½è‚¡ç¥¨æ•¸: {stats['total_stocks']}")
            print(f"æœ‰æ¨™ç±¤çš„è‚¡ç¥¨: {stats['stocks_with_labels']}")

            if stats['overall_dist']:
                od = stats['overall_dist']
                print(f"\næ•´é«”æ¨™ç±¤åˆ†å¸ƒ:")
                print(f"  Down: {od['down_pct']:.1%}")
                print(f"  Neutral: {od['neutral_pct']:.1%}")
                print(f"  Up: {od['up_pct']:.1%}")
                print(f"  Total: {od['total_labels']:,}")

            # é¡¯ç¤ºå‰ 5 æª”è‚¡ç¥¨
            print(f"\nå‰ 5 æª”è‚¡ç¥¨ï¼ˆæŒ‰æ¨™ç±¤æ•¸æ’åºï¼‰:")
            top_stocks = get_stock_list_for_date(preprocessed_dir, test_date)[:5]
            for symbol, lp in top_stocks:
                if lp:
                    print(f"  {symbol}: {lp['total_labels']:,} æ¨™ç±¤ "
                          f"(Down {lp['down_pct']:.1%} | "
                          f"Neutral {lp['neutral_pct']:.1%} | "
                          f"Up {lp['up_pct']:.1%})")

        except Exception as e:
            print(f"éŒ¯èª¤: {e}")

    print(f"\n{'='*70}")
    print(get_cache_info())
    print("="*70)
