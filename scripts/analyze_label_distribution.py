# -*- coding: utf-8 -*-
"""
analyze_label_distribution.py - åˆ†æä¸¦å¯è¦–åŒ–æ¨™ç±¤åˆ†å¸ƒ
=============================================================================
ç”¨é€”ï¼šå¹«åŠ©ä½ ç†è§£æ•¸æ“šçš„æ¨™ç±¤åˆ†å¸ƒï¼Œä¸¦ç”Ÿæˆè‚¡ç¥¨é¸å–å»ºè­°

ä½¿ç”¨æ–¹å¼ï¼š
  # åˆ†ææ‰€æœ‰æ•¸æ“š
  python scripts/analyze_label_distribution.py \
      --preprocessed-dir data/preprocessed_v5 \
      --output analysis_report.json

  # ç”Ÿæˆè‚¡ç¥¨é¸å–æ¸…å–®
  python scripts/analyze_label_distribution.py \
      --preprocessed-dir data/preprocessed_v5 \
      --mode recommend \
      --target-dist "0.30,0.40,0.30" \
      --output stock_selection.json

åŠŸèƒ½ï¼š
  1. åˆ†ææ‰€æœ‰è‚¡ç¥¨çš„æ¨™ç±¤åˆ†å¸ƒ
  2. æŒ‰ä¸åŒç¶­åº¦åˆ†çµ„ï¼ˆæŒå¹³æ¯”ä¾‹ã€æ³¢å‹•ç‡ç­‰ï¼‰
  3. ç”Ÿæˆè‚¡ç¥¨é¸å–å»ºè­°ï¼ˆé”åˆ°ç›®æ¨™æ¨™ç±¤åˆ†å¸ƒï¼‰
  4. å¯è¦–åŒ–æ¨™ç±¤åˆ†å¸ƒï¼ˆç›´æ–¹åœ–ã€æ•£é»åœ–ï¼‰
"""

import os
import json
import glob
import argparse
import logging
from typing import List, Dict, Any, Tuple
from collections import defaultdict

import numpy as np
import pandas as pd
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)


def load_all_stocks_metadata(preprocessed_dir: str) -> List[Dict]:
    """è¼‰å…¥æ‰€æœ‰è‚¡ç¥¨çš„ metadata"""
    all_metadata = []

    # æ‰¾åˆ°æ‰€æœ‰ NPZ æª”æ¡ˆ
    npz_pattern = os.path.join(preprocessed_dir, "daily", "*", "*.npz")
    npz_files = glob.glob(npz_pattern)

    logging.info(f"æ‰¾åˆ° {len(npz_files)} å€‹ NPZ æª”æ¡ˆ")

    for npz_file in npz_files:
        try:
            data = np.load(npz_file, allow_pickle=True)
            metadata = json.loads(str(data['metadata']))

            # åªä¿ç•™é€šééæ¿¾ä¸”æœ‰æ¨™ç±¤é è¦½çš„è‚¡ç¥¨
            if metadata.get('pass_filter', False) and metadata.get('label_preview') is not None:
                lp = metadata['label_preview']
                all_metadata.append({
                    'symbol': metadata['symbol'],
                    'date': metadata['date'],
                    'file_path': npz_file,
                    'range_pct': metadata['range_pct'],
                    'n_points': metadata['n_points'],
                    'total_labels': lp['total_labels'],
                    'down_count': lp['down_count'],
                    'neutral_count': lp['neutral_count'],
                    'up_count': lp['up_count'],
                    'down_pct': lp['down_pct'],
                    'neutral_pct': lp['neutral_pct'],
                    'up_pct': lp['up_pct']
                })
        except Exception as e:
            logging.warning(f"è®€å– {npz_file} å¤±æ•—: {e}")
            continue

    logging.info(f"è¼‰å…¥ {len(all_metadata)} æª”æœ‰æ•ˆè‚¡ç¥¨")
    return all_metadata


def analyze_overall_distribution(stocks: List[Dict]) -> Dict:
    """åˆ†ææ•´é«”æ¨™ç±¤åˆ†å¸ƒ"""
    total_down = sum(s['down_count'] for s in stocks)
    total_neutral = sum(s['neutral_count'] for s in stocks)
    total_up = sum(s['up_count'] for s in stocks)
    total_all = total_down + total_neutral + total_up

    return {
        'total_stocks': len(stocks),
        'total_labels': total_all,
        'down_count': total_down,
        'neutral_count': total_neutral,
        'up_count': total_up,
        'down_pct': total_down / total_all if total_all > 0 else 0,
        'neutral_pct': total_neutral / total_all if total_all > 0 else 0,
        'up_pct': total_up / total_all if total_all > 0 else 0
    }


def group_by_neutral_ratio(stocks: List[Dict]) -> Dict[str, List[Dict]]:
    """æŒ‰æŒå¹³æ¯”ä¾‹åˆ†çµ„"""
    groups = {
        'very_low': [],    # < 10%
        'low': [],         # 10-20%
        'medium': [],      # 20-30%
        'high': [],        # 30-40%
        'very_high': []    # > 40%
    }

    for stock in stocks:
        neutral_pct = stock['neutral_pct']
        if neutral_pct < 0.10:
            groups['very_low'].append(stock)
        elif neutral_pct < 0.20:
            groups['low'].append(stock)
        elif neutral_pct < 0.30:
            groups['medium'].append(stock)
        elif neutral_pct < 0.40:
            groups['high'].append(stock)
        else:
            groups['very_high'].append(stock)

    return groups


def recommend_stock_selection(
    stocks: List[Dict],
    target_dist: Tuple[float, float, float] = (0.30, 0.40, 0.30)
) -> Dict:
    """
    æ ¹æ“šç›®æ¨™æ¨™ç±¤åˆ†å¸ƒï¼Œæ¨è–¦è‚¡ç¥¨é¸å–ç­–ç•¥

    Args:
        stocks: æ‰€æœ‰è‚¡ç¥¨ metadata
        target_dist: ç›®æ¨™åˆ†å¸ƒ (down%, neutral%, up%)

    Returns:
        æ¨è–¦çµæœï¼ŒåŒ…å«ï¼š
        - é¸å–çš„è‚¡ç¥¨æ¸…å–®
        - é æœŸé”åˆ°çš„æ¨™ç±¤åˆ†å¸ƒ
        - é¸å–é‚è¼¯èªªæ˜
    """
    target_down, target_neutral, target_up = target_dist

    # ç•¶å‰æ•´é«”åˆ†å¸ƒ
    current = analyze_overall_distribution(stocks)
    current_dist = (current['down_pct'], current['neutral_pct'], current['up_pct'])

    logging.info(f"\nç›®æ¨™åˆ†å¸ƒ: Down {target_down:.1%} | Neutral {target_neutral:.1%} | Up {target_up:.1%}")
    logging.info(f"ç•¶å‰åˆ†å¸ƒ: Down {current_dist[0]:.1%} | Neutral {current_dist[1]:.1%} | Up {current_dist[2]:.1%}")

    # åˆ†æç¼ºå£
    neutral_gap = target_neutral - current_dist[1]
    up_gap = target_up - current_dist[2]
    down_gap = target_down - current_dist[0]

    recommendations = []

    # ç­–ç•¥ 1ï¼šå¦‚æœæŒå¹³é¡ä¸è¶³ï¼Œå„ªå…ˆé¸æŒå¹³æ¯”ä¾‹é«˜çš„è‚¡ç¥¨
    if neutral_gap > 0.05:
        high_neutral_stocks = [s for s in stocks if s['neutral_pct'] > 0.25]
        recommendations.append({
            'strategy': 'boost_neutral',
            'reason': f'æŒå¹³é¡ä¸è¶³ ({neutral_gap:.1%})ï¼Œé¸å–æŒå¹³æ¯”ä¾‹ > 25% çš„è‚¡ç¥¨',
            'stocks': [s['symbol'] for s in high_neutral_stocks],
            'count': len(high_neutral_stocks)
        })

    # ç­–ç•¥ 2ï¼šå¦‚æœä¸Šæ¼²é¡ä¸è¶³ï¼Œé¸ä¸Šæ¼²æ¯”ä¾‹é«˜çš„è‚¡ç¥¨
    if up_gap > 0.05:
        high_up_stocks = [s for s in stocks if s['up_pct'] > 0.45]
        recommendations.append({
            'strategy': 'boost_up',
            'reason': f'ä¸Šæ¼²é¡ä¸è¶³ ({up_gap:.1%})ï¼Œé¸å–ä¸Šæ¼²æ¯”ä¾‹ > 45% çš„è‚¡ç¥¨',
            'stocks': [s['symbol'] for s in high_up_stocks],
            'count': len(high_up_stocks)
        })

    # ç­–ç•¥ 3ï¼šå¦‚æœä¸‹è·Œé¡ä¸è¶³ï¼Œé¸ä¸‹è·Œæ¯”ä¾‹é«˜çš„è‚¡ç¥¨
    if down_gap > 0.05:
        high_down_stocks = [s for s in stocks if s['down_pct'] > 0.45]
        recommendations.append({
            'strategy': 'boost_down',
            'reason': f'ä¸‹è·Œé¡ä¸è¶³ ({down_gap:.1%})ï¼Œé¸å–ä¸‹è·Œæ¯”ä¾‹ > 45% çš„è‚¡ç¥¨',
            'stocks': [s['symbol'] for s in high_down_stocks],
            'count': len(high_down_stocks)
        })

    # ç­–ç•¥ 4ï¼šå¦‚æœå·²ç¶“å¾ˆå¹³è¡¡ï¼Œé¸å–ä¸­ç­‰æ¯”ä¾‹çš„è‚¡ç¥¨
    if abs(neutral_gap) < 0.05 and abs(up_gap) < 0.05 and abs(down_gap) < 0.05:
        balanced_stocks = [s for s in stocks
                          if 0.20 <= s['neutral_pct'] <= 0.35
                          and 0.25 <= s['up_pct'] <= 0.45
                          and 0.25 <= s['down_pct'] <= 0.45]
        recommendations.append({
            'strategy': 'maintain_balance',
            'reason': 'ç•¶å‰å·²å¹³è¡¡ï¼Œé¸å–ä¸­ç­‰æ¯”ä¾‹çš„è‚¡ç¥¨ç¶­æŒå¹³è¡¡',
            'stocks': [s['symbol'] for s in balanced_stocks],
            'count': len(balanced_stocks)
        })

    return {
        'target_dist': {
            'down': target_down,
            'neutral': target_neutral,
            'up': target_up
        },
        'current_dist': {
            'down': current_dist[0],
            'neutral': current_dist[1],
            'up': current_dist[2]
        },
        'gap_analysis': {
            'down_gap': down_gap,
            'neutral_gap': neutral_gap,
            'up_gap': up_gap
        },
        'recommendations': recommendations
    }


def print_summary_report(stocks: List[Dict]):
    """åˆ—å°æ‘˜è¦å ±å‘Š"""
    print("\n" + "="*80)
    print("æ¨™ç±¤åˆ†å¸ƒåˆ†æå ±å‘Š")
    print("="*80)

    # æ•´é«”åˆ†å¸ƒ
    overall = analyze_overall_distribution(stocks)
    print(f"\nğŸ“Š æ•´é«”æ¨™ç±¤åˆ†å¸ƒ ({overall['total_stocks']} æª”è‚¡ç¥¨):")
    print(f"   ç¸½æ¨™ç±¤æ•¸: {overall['total_labels']:,}")
    print(f"   Down:    {overall['down_count']:>10,} ({overall['down_pct']:>6.2%})")
    print(f"   Neutral: {overall['neutral_count']:>10,} ({overall['neutral_pct']:>6.2%})")
    print(f"   Up:      {overall['up_count']:>10,} ({overall['up_pct']:>6.2%})")

    # æŒ‰æŒå¹³æ¯”ä¾‹åˆ†çµ„
    groups = group_by_neutral_ratio(stocks)
    print(f"\nğŸ“ˆ æŒ‰æŒå¹³æ¯”ä¾‹åˆ†çµ„:")
    for group_name, group_stocks in groups.items():
        if not group_stocks:
            continue
        group_dist = analyze_overall_distribution(group_stocks)
        print(f"\n   {group_name.upper()} ({len(group_stocks)} æª”):")
        print(f"      Down: {group_dist['down_pct']:.1%} | "
              f"Neutral: {group_dist['neutral_pct']:.1%} | "
              f"Up: {group_dist['up_pct']:.1%}")

    # æ¥µç«¯æ¡ˆä¾‹
    print(f"\nâš ï¸  æ¥µç«¯æ¡ˆä¾‹:")
    very_low_neutral = [s for s in stocks if s['neutral_pct'] < 0.05]
    very_high_neutral = [s for s in stocks if s['neutral_pct'] > 0.50]

    if very_low_neutral:
        print(f"   æŒå¹³ < 5%: {len(very_low_neutral)} æª”")
        for s in very_low_neutral[:3]:
            print(f"      {s['symbol']}: Down {s['down_pct']:.1%} | "
                  f"Neutral {s['neutral_pct']:.1%} | Up {s['up_pct']:.1%}")

    if very_high_neutral:
        print(f"   æŒå¹³ > 50%: {len(very_high_neutral)} æª”")
        for s in very_high_neutral[:3]:
            print(f"      {s['symbol']}: Down {s['down_pct']:.1%} | "
                  f"Neutral {s['neutral_pct']:.1%} | Up {s['up_pct']:.1%}")


def main():
    parser = argparse.ArgumentParser(description="åˆ†ææ¨™ç±¤åˆ†å¸ƒ")
    parser.add_argument("--preprocessed-dir", required=True, help="é è™•ç†æ•¸æ“šç›®éŒ„")
    parser.add_argument("--mode", default="analyze", choices=["analyze", "recommend"],
                       help="æ¨¡å¼: analyze=åˆ†æ, recommend=æ¨è–¦é¸å–")
    parser.add_argument("--target-dist", default="0.30,0.40,0.30",
                       help="ç›®æ¨™åˆ†å¸ƒ (down,neutral,up), ä¾‹å¦‚: 0.30,0.40,0.30")
    parser.add_argument("--output", help="è¼¸å‡º JSON æª”æ¡ˆè·¯å¾‘")

    args = parser.parse_args()

    # è¼‰å…¥æ•¸æ“š
    stocks = load_all_stocks_metadata(args.preprocessed_dir)

    if not stocks:
        logging.error("æ‰¾ä¸åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨æ•¸æ“šï¼")
        return

    # æ¨¡å¼ 1: åˆ†æ
    if args.mode == "analyze":
        print_summary_report(stocks)

    # æ¨¡å¼ 2: æ¨è–¦é¸å–
    elif args.mode == "recommend":
        target_dist = tuple(map(float, args.target_dist.split(',')))
        result = recommend_stock_selection(stocks, target_dist)

        print(f"\n{'='*80}")
        print("è‚¡ç¥¨é¸å–å»ºè­°")
        print(f"{'='*80}")

        print(f"\nç›®æ¨™åˆ†å¸ƒ: Down {result['target_dist']['down']:.1%} | "
              f"Neutral {result['target_dist']['neutral']:.1%} | "
              f"Up {result['target_dist']['up']:.1%}")

        print(f"\nç•¶å‰åˆ†å¸ƒ: Down {result['current_dist']['down']:.1%} | "
              f"Neutral {result['current_dist']['neutral']:.1%} | "
              f"Up {result['current_dist']['up']:.1%}")

        print(f"\nç¼ºå£åˆ†æ:")
        print(f"   Down gap:    {result['gap_analysis']['down_gap']:>+7.1%}")
        print(f"   Neutral gap: {result['gap_analysis']['neutral_gap']:>+7.1%}")
        print(f"   Up gap:      {result['gap_analysis']['up_gap']:>+7.1%}")

        print(f"\næ¨è–¦ç­–ç•¥:")
        for i, rec in enumerate(result['recommendations'], 1):
            print(f"\n   ç­–ç•¥ {i}: {rec['strategy']}")
            print(f"      ç†ç”±: {rec['reason']}")
            print(f"      è‚¡ç¥¨æ•¸: {rec['count']}")
            print(f"      è‚¡ç¥¨ä»£ç¢¼: {', '.join(rec['stocks'][:10])}" +
                  (f" ... ({rec['count'] - 10} æª”æ›´å¤š)" if rec['count'] > 10 else ""))

        # ä¿å­˜çµæœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logging.info(f"çµæœå·²ä¿å­˜åˆ°: {args.output}")

    print("\n" + "="*80)
    print("âœ… åˆ†æå®Œæˆ")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
