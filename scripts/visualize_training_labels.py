# -*- coding: utf-8 -*-
"""
visualize_training_labels.py - è¨“ç·´æ•¸æ“šæ¨™ç±¤è¦–è¦ºåŒ–å·¥å…·
=============================================================================
ã€åŠŸèƒ½ã€‘æª¢æŸ¥ extract_tw_stock_data_v5.py ç”¢ç”Ÿçš„è¨“ç·´è³‡æ–™æ¨™ç±¤æ˜¯å¦æ­£ç¢º

ã€è¼¸å‡ºåœ–è¡¨ã€‘
1. æ”¶ç›¤åƒ¹æ›²ç·šèˆ‡æ¨™ç±¤é¡è‰²ç–ŠåŠ ï¼ˆæª¢æŸ¥æ¨™ç±¤èˆ‡è¶¨å‹¢æ˜¯å¦å°æ‡‰ï¼‰
2. æ¨™ç±¤åˆ†å¸ƒçµ±è¨ˆï¼ˆæª¢æŸ¥é¡åˆ¥å¹³è¡¡ï¼‰
3. Triple-Barrier è§¸ç™¼åˆ†æï¼ˆæª¢æŸ¥æ­¢ç›ˆæ­¢æåˆç†æ€§ï¼‰
4. æ¨£æœ¬æ¬Šé‡åˆ†å¸ƒï¼ˆæª¢æŸ¥æ¬Šé‡åˆ†é…ï¼‰

ã€ä½¿ç”¨æ–¹å¼ã€‘
python scripts/visualize_training_labels.py --data-dir ./data/processed_v5/npz --split train --n-stocks 5

ã€åƒæ•¸èªªæ˜ã€‘
--data-dir: NPZ æ•¸æ“šç›®éŒ„ï¼ˆåŒ…å« stock_embedding_*.npzï¼‰
--split: æ•¸æ“šé›†åŠƒåˆ† {train, val, test}
--n-stocks: é¡¯ç¤ºå‰ N æª”è‚¡ç¥¨çš„è©³ç´°åœ–è¡¨ï¼ˆé è¨­ 3ï¼‰
--output-dir: åœ–è¡¨è¼¸å‡ºç›®éŒ„ï¼ˆé è¨­ ./results/label_visualizationï¼‰

ç‰ˆæœ¬ï¼šv1.0
æ—¥æœŸï¼š2025-10-20
"""

import os
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# è¨­å®šä¸­æ–‡å­—å‹ï¼ˆé¿å…äº‚ç¢¼ï¼‰
plt.rcParams['font.sans-serif'] = ['Microsoft YahHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ¨™ç±¤å®šç¾©
LABEL_NAMES = {0: 'ä¸‹è·Œ', 1: 'æŒå¹³', 2: 'ä¸Šæ¼²'}
LABEL_COLORS = {0: '#e74c3c', 1: '#95a5a6', 2: '#2ecc71'}  # ç´…/ç°/ç¶ 


def parse_args():
    """è§£æå‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(
        "visualize_training_labels",
        description="è¨“ç·´æ•¸æ“šæ¨™ç±¤è¦–è¦ºåŒ–å·¥å…· - æª¢æŸ¥æ¨™ç±¤è¶¨å‹¢æ˜¯å¦æ­£ç¢º"
    )
    parser.add_argument(
        "--data-dir",
        default="./data/processed_v5/npz",
        type=str,
        help="NPZ æ•¸æ“šç›®éŒ„è·¯å¾‘"
    )
    parser.add_argument(
        "--split",
        default="train",
        choices=["train", "val", "test"],
        help="æ•¸æ“šé›†åŠƒåˆ†"
    )
    parser.add_argument(
        "--n-stocks",
        default=3,
        type=int,
        help="é¡¯ç¤ºå‰ N æª”è‚¡ç¥¨çš„è©³ç´°åœ–è¡¨"
    )
    parser.add_argument(
        "--output-dir",
        default="./results/label_visualization",
        type=str,
        help="åœ–è¡¨è¼¸å‡ºç›®éŒ„"
    )
    parser.add_argument(
        "--max-points",
        default=500,
        type=int,
        help="å–®æª”è‚¡ç¥¨æœ€å¤šé¡¯ç¤ºçš„æ™‚é–“é»æ•¸ï¼ˆé¿å…åœ–è¡¨éæ–¼å¯†é›†ï¼‰"
    )
    return parser.parse_args()


def load_data(data_dir: str, split: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict]:
    """
    è¼‰å…¥ NPZ æ•¸æ“šèˆ‡ metadata

    Returns:
        X: (N, 100, 20) æ™‚é–“åºåˆ—ç‰¹å¾µ
        y: (N,) æ¨™ç±¤ {0, 1, 2}
        weights: (N,) æ¨£æœ¬æ¬Šé‡
        stock_ids: (N,) è‚¡ç¥¨ä»£ç¢¼
        metadata: å…ƒæ•¸æ“šå­—å…¸
    """
    npz_path = os.path.join(data_dir, f"stock_embedding_{split}.npz")
    meta_path = os.path.join(data_dir, "normalization_meta.json")

    if not os.path.exists(npz_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•¸æ“šæ–‡ä»¶: {npz_path}")

    if not os.path.exists(meta_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å…ƒæ•¸æ“šæ–‡ä»¶: {meta_path}")

    # è¼‰å…¥ NPZ
    data = np.load(npz_path, allow_pickle=True)
    X = data['X']
    y = data['y']
    weights = data['weights']
    stock_ids = data['stock_ids']

    # è¼‰å…¥ metadata
    with open(meta_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    logging.info(f"âœ… å·²è¼‰å…¥ {split} æ•¸æ“š: {X.shape[0]:,} å€‹æ¨£æœ¬")
    logging.info(f"   å½¢ç‹€: X={X.shape}, y={y.shape}, weights={weights.shape}")

    return X, y, weights, stock_ids, metadata


def reconstruct_close_price(X: np.ndarray, metadata: Dict) -> np.ndarray:
    """
    å¾ Z-Score æ­£è¦åŒ–çš„ç‰¹å¾µé‡å»ºä¸­é–“åƒ¹ï¼ˆè¿‘ä¼¼æ”¶ç›¤åƒ¹ï¼‰

    Args:
        X: (N, 100, 20) æ­£è¦åŒ–å¾Œçš„ LOB ç‰¹å¾µ
        metadata: åŒ…å« Z-Score åƒæ•¸çš„å…ƒæ•¸æ“š

    Returns:
        close_prices: (N,) æ¯å€‹çª—å£æœ€å¾Œä¸€å€‹æ™‚é–“é»çš„ä¸­é–“åƒ¹
    """
    # æå– Z-Score åƒæ•¸
    mu = np.array(metadata['normalization']['feature_means'])
    sd = np.array(metadata['normalization']['feature_stds'])

    # åå‘ Z-Scoreï¼ˆåªå–æœ€å¾Œä¸€å€‹æ™‚é–“é»ï¼‰
    X_last = X[:, -1, :]  # (N, 20)
    X_denorm = X_last * sd.reshape(1, -1) + mu.reshape(1, -1)

    # è¨ˆç®—ä¸­é–“åƒ¹ï¼š(bid1 + ask1) / 2
    # æ ¹æ“š extract_tw_stock_data_v5.py çš„ç‰¹å¾µå®šç¾©ï¼š
    # feat = bids_p + asks_p + bids_q + asks_q
    # ç´¢å¼• 0-4: bid prices, 5-9: ask prices
    bid1 = X_denorm[:, 0]
    ask1 = X_denorm[:, 5]
    close = (bid1 + ask1) / 2.0

    return close


def plot_stock_labels(
    stock_id: str,
    close: np.ndarray,
    labels: np.ndarray,
    weights: np.ndarray,
    output_path: str,
    max_points: int = 500
):
    """
    ç¹ªè£½å–®æª”è‚¡ç¥¨çš„æ”¶ç›¤åƒ¹èˆ‡æ¨™ç±¤è¶¨å‹¢åœ–

    Args:
        stock_id: è‚¡ç¥¨ä»£ç¢¼
        close: (T,) æ”¶ç›¤åƒ¹åºåˆ—
        labels: (T,) æ¨™ç±¤åºåˆ—
        weights: (T,) æ¨£æœ¬æ¬Šé‡
        output_path: åœ–è¡¨ä¿å­˜è·¯å¾‘
        max_points: æœ€å¤šé¡¯ç¤ºçš„æ™‚é–“é»æ•¸
    """
    # å¦‚æœæ™‚é–“é»å¤ªå¤šï¼Œé€²è¡Œé™æ¡æ¨£
    T = len(close)
    if T > max_points:
        indices = np.linspace(0, T - 1, max_points, dtype=int)
        close = close[indices]
        labels = labels[indices]
        weights = weights[indices]
        T = max_points

    # å‰µå»ºåœ–è¡¨ï¼ˆ2 è¡Œä½ˆå±€ï¼‰
    fig = plt.figure(figsize=(16, 10))
    gs = GridSpec(3, 2, figure=fig, height_ratios=[2, 1, 1])

    # åœ– 1: æ”¶ç›¤åƒ¹èˆ‡æ¨™ç±¤è¶¨å‹¢ï¼ˆä¸»åœ–ï¼‰
    ax1 = fig.add_subplot(gs[0, :])

    # ç¹ªè£½æ”¶ç›¤åƒ¹æ›²ç·š
    ax1.plot(range(T), close, color='#3498db', linewidth=1.5, label='æ”¶ç›¤åƒ¹', alpha=0.8)

    # ç”¨æ¨™ç±¤é¡è‰²æ¨™è¨»èƒŒæ™¯
    for i in range(T):
        label = int(labels[i])
        ax1.axvspan(i - 0.5, i + 0.5, alpha=0.2, color=LABEL_COLORS[label])

    ax1.set_xlabel('æ™‚é–“é»', fontsize=12)
    ax1.set_ylabel('åƒ¹æ ¼', fontsize=12)
    ax1.set_title(f'{stock_id} - æ”¶ç›¤åƒ¹èˆ‡æ¨™ç±¤è¶¨å‹¢', fontsize=14, fontweight='bold')
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)

    # åœ– 2: æ¨™ç±¤åºåˆ—ï¼ˆæ™‚é–“è»¸ï¼‰
    ax2 = fig.add_subplot(gs[1, :])

    colors = [LABEL_COLORS[int(l)] for l in labels]
    ax2.bar(range(T), np.ones(T), color=colors, width=1.0, edgecolor='none')
    ax2.set_xlabel('æ™‚é–“é»', fontsize=12)
    ax2.set_ylabel('æ¨™ç±¤', fontsize=12)
    ax2.set_title('æ¨™ç±¤åºåˆ—ï¼ˆç´…=ä¸‹è·Œ, ç°=æŒå¹³, ç¶ =ä¸Šæ¼²ï¼‰', fontsize=12)
    ax2.set_ylim(0, 1.2)
    ax2.set_yticks([])
    ax2.grid(True, alpha=0.3, axis='x')

    # åœ– 3: æ¨™ç±¤åˆ†å¸ƒçµ±è¨ˆ
    ax3 = fig.add_subplot(gs[2, 0])

    label_counts = pd.Series(labels).value_counts().sort_index()
    label_pcts = label_counts / len(labels) * 100

    bars = ax3.bar(
        [LABEL_NAMES[i] for i in label_counts.index],
        label_counts.values,
        color=[LABEL_COLORS[i] for i in label_counts.index],
        edgecolor='black',
        linewidth=1.5
    )

    # æ·»åŠ ç™¾åˆ†æ¯”æ¨™è¨»
    for i, (bar, pct) in enumerate(zip(bars, label_pcts.values)):
        height = bar.get_height()
        ax3.text(
            bar.get_x() + bar.get_width() / 2,
            height,
            f'{pct:.1f}%',
            ha='center',
            va='bottom',
            fontsize=10,
            fontweight='bold'
        )

    ax3.set_ylabel('æ¨£æœ¬æ•¸', fontsize=12)
    ax3.set_title('æ¨™ç±¤åˆ†å¸ƒ', fontsize=12)
    ax3.grid(True, alpha=0.3, axis='y')

    # åœ– 4: æ¨£æœ¬æ¬Šé‡åˆ†å¸ƒ
    ax4 = fig.add_subplot(gs[2, 1])

    ax4.hist(weights, bins=50, color='#9b59b6', alpha=0.7, edgecolor='black')
    ax4.axvline(weights.mean(), color='red', linestyle='--', linewidth=2, label=f'å‡å€¼={weights.mean():.2f}')
    ax4.set_xlabel('æ¨£æœ¬æ¬Šé‡', fontsize=12)
    ax4.set_ylabel('é »ç‡', fontsize=12)
    ax4.set_title('æ¨£æœ¬æ¬Šé‡åˆ†å¸ƒ', fontsize=12)
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    logging.info(f"  âœ… å·²ä¿å­˜: {output_path}")


def plot_overall_statistics(
    y: np.ndarray,
    weights: np.ndarray,
    stock_ids: np.ndarray,
    output_path: str
):
    """
    ç¹ªè£½æ•´é«”æ•¸æ“šé›†çš„çµ±è¨ˆåœ–è¡¨

    Args:
        y: (N,) æ¨™ç±¤
        weights: (N,) æ¨£æœ¬æ¬Šé‡
        stock_ids: (N,) è‚¡ç¥¨ä»£ç¢¼
        output_path: åœ–è¡¨ä¿å­˜è·¯å¾‘
    """
    fig = plt.figure(figsize=(16, 10))
    gs = GridSpec(2, 3, figure=fig)

    # åœ– 1: æ¨™ç±¤åˆ†å¸ƒï¼ˆæ•´é«”ï¼‰
    ax1 = fig.add_subplot(gs[0, 0])

    label_counts = pd.Series(y).value_counts().sort_index()
    label_pcts = label_counts / len(y) * 100

    bars = ax1.bar(
        [LABEL_NAMES[i] for i in label_counts.index],
        label_counts.values,
        color=[LABEL_COLORS[i] for i in label_counts.index],
        edgecolor='black',
        linewidth=1.5
    )

    for i, (bar, pct, count) in enumerate(zip(bars, label_pcts.values, label_counts.values)):
        height = bar.get_height()
        ax1.text(
            bar.get_x() + bar.get_width() / 2,
            height,
            f'{count:,}\n({pct:.1f}%)',
            ha='center',
            va='bottom',
            fontsize=11,
            fontweight='bold'
        )

    ax1.set_ylabel('æ¨£æœ¬æ•¸', fontsize=12)
    ax1.set_title('æ¨™ç±¤åˆ†å¸ƒï¼ˆæ•´é«”ï¼‰', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3, axis='y')

    # åœ– 2: æ¯æª”è‚¡ç¥¨çš„æ¨£æœ¬æ•¸åˆ†å¸ƒ
    ax2 = fig.add_subplot(gs[0, 1])

    stock_counts = pd.Series(stock_ids).value_counts().sort_values(ascending=False)
    ax2.hist(stock_counts.values, bins=30, color='#3498db', alpha=0.7, edgecolor='black')
    ax2.axvline(stock_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'å‡å€¼={stock_counts.mean():.0f}')
    ax2.set_xlabel('æ¯æª”è‚¡ç¥¨çš„æ¨£æœ¬æ•¸', fontsize=12)
    ax2.set_ylabel('è‚¡ç¥¨æ•¸é‡', fontsize=12)
    ax2.set_title('è‚¡ç¥¨æ¨£æœ¬æ•¸åˆ†å¸ƒ', fontsize=12)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # åœ– 3: æ¬Šé‡åˆ†å¸ƒï¼ˆæ•´é«”ï¼‰
    ax3 = fig.add_subplot(gs[0, 2])

    # ä½¿ç”¨å°æ•¸å°ºåº¦è™•ç†æ¥µç«¯æ¬Šé‡
    weights_clipped = np.clip(weights, 0, np.percentile(weights, 99))
    ax3.hist(weights_clipped, bins=50, color='#9b59b6', alpha=0.7, edgecolor='black')
    ax3.axvline(weights.mean(), color='red', linestyle='--', linewidth=2, label=f'å‡å€¼={weights.mean():.2f}')
    ax3.set_xlabel('æ¨£æœ¬æ¬Šé‡', fontsize=12)
    ax3.set_ylabel('é »ç‡', fontsize=12)
    ax3.set_title('æ¨£æœ¬æ¬Šé‡åˆ†å¸ƒï¼ˆå»é™¤æ¥µå€¼ï¼‰', fontsize=12)
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # åœ– 4: å„è‚¡ç¥¨çš„æ¨™ç±¤åˆ†å¸ƒï¼ˆå †ç–Šåœ–ï¼‰
    ax4 = fig.add_subplot(gs[1, :])

    # é¸å–æ¨£æœ¬æ•¸å‰ 20 çš„è‚¡ç¥¨
    top_stocks = stock_counts.head(20).index
    stock_label_dist = []

    for stock in top_stocks:
        mask = stock_ids == stock
        labels_stock = y[mask]
        counts = pd.Series(labels_stock).value_counts().reindex([0, 1, 2], fill_value=0).values
        stock_label_dist.append(counts)

    stock_label_dist = np.array(stock_label_dist).T  # (3, 20)

    x = np.arange(len(top_stocks))
    width = 0.8

    bottom = np.zeros(len(top_stocks))
    for i, (label_name, color) in enumerate([(0, LABEL_COLORS[0]), (1, LABEL_COLORS[1]), (2, LABEL_COLORS[2])]):
        ax4.bar(x, stock_label_dist[i], width, label=LABEL_NAMES[i], color=color, bottom=bottom, edgecolor='black', linewidth=0.5)
        bottom += stock_label_dist[i]

    ax4.set_xlabel('è‚¡ç¥¨ä»£ç¢¼', fontsize=12)
    ax4.set_ylabel('æ¨£æœ¬æ•¸', fontsize=12)
    ax4.set_title('å‰ 20 æª”è‚¡ç¥¨çš„æ¨™ç±¤åˆ†å¸ƒï¼ˆå †ç–Šåœ–ï¼‰', fontsize=14, fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels(top_stocks, rotation=45, ha='right')
    ax4.legend(loc='upper right')
    ax4.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    logging.info(f"âœ… å·²ä¿å­˜æ•´é«”çµ±è¨ˆåœ–: {output_path}")


def main():
    """ä¸»ç¨‹å¼"""
    args = parse_args()

    # è¼‰å…¥æ•¸æ“š
    logging.info(f"è¼‰å…¥ {args.split} æ•¸æ“šé›†...")
    X, y, weights, stock_ids, metadata = load_data(args.data_dir, args.split)

    # é‡å»ºæ”¶ç›¤åƒ¹
    logging.info("é‡å»ºæ”¶ç›¤åƒ¹åºåˆ—...")
    close_prices = reconstruct_close_price(X, metadata)

    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output_dir) / args.split
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ•´é«”çµ±è¨ˆåœ–
    logging.info("\nç”Ÿæˆæ•´é«”çµ±è¨ˆåœ–...")
    plot_overall_statistics(
        y, weights, stock_ids,
        str(output_dir / "overall_statistics.png")
    )

    # é¸å–å‰ N æª”è‚¡ç¥¨ç¹ªè£½è©³ç´°åœ–è¡¨
    logging.info(f"\nç”Ÿæˆå‰ {args.n_stocks} æª”è‚¡ç¥¨çš„è©³ç´°åœ–è¡¨...")
    stock_counts = pd.Series(stock_ids).value_counts().sort_values(ascending=False)
    top_stocks = stock_counts.head(args.n_stocks).index

    for i, stock in enumerate(top_stocks, 1):
        mask = stock_ids == stock
        stock_close = close_prices[mask]
        stock_labels = y[mask]
        stock_weights = weights[mask]

        logging.info(f"  [{i}/{args.n_stocks}] è™•ç† {stock}ï¼ˆ{len(stock_close):,} å€‹æ¨£æœ¬ï¼‰...")

        output_path = output_dir / f"stock_{stock}.png"
        plot_stock_labels(
            stock, stock_close, stock_labels, stock_weights,
            str(output_path),
            max_points=args.max_points
        )

    # è¼¸å‡ºæ‘˜è¦å ±å‘Š
    logging.info(f"\n{'='*60}")
    logging.info("ğŸ“Š æ¨™ç±¤æª¢æŸ¥æ‘˜è¦å ±å‘Š")
    logging.info(f"{'='*60}")
    logging.info(f"æ•¸æ“šé›†: {args.split}")
    logging.info(f"ç¸½æ¨£æœ¬æ•¸: {len(y):,}")
    logging.info(f"è‚¡ç¥¨æ•¸é‡: {len(np.unique(stock_ids))}")

    label_counts = pd.Series(y).value_counts().sort_index()
    label_pcts = label_counts / len(y) * 100
    logging.info(f"\næ¨™ç±¤åˆ†å¸ƒ:")
    for label, count in label_counts.items():
        pct = label_pcts[label]
        logging.info(f"  {LABEL_NAMES[label]}: {count:,} ({pct:.2f}%)")

    logging.info(f"\næ¨£æœ¬æ¬Šé‡çµ±è¨ˆ:")
    logging.info(f"  å‡å€¼: {weights.mean():.3f}")
    logging.info(f"  æ¨™æº–å·®: {weights.std():.3f}")
    logging.info(f"  æœ€å¤§å€¼: {weights.max():.3f}")
    logging.info(f"  æœ€å°å€¼: {weights.min():.3f}")

    logging.info(f"\nåœ–è¡¨å·²ä¿å­˜è‡³: {output_dir}")
    logging.info(f"{'='*60}\n")


if __name__ == "__main__":
    main()
