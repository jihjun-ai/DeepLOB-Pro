"""SB3 æ¨¡å‹è©•ä¼°è…³æœ¬ - å®Œæ•´æ€§èƒ½è©•ä¼°

æ­¤è…³æœ¬ç”¨æ–¼å…¨é¢è©•ä¼°è¨“ç·´å¥½çš„ SB3 PPO æ¨¡å‹æ€§èƒ½ã€‚

è©•ä¼°æŒ‡æ¨™ï¼ˆ7 å¤§é¡ï¼‰ï¼š
    1. æ”¶ç›ŠæŒ‡æ¨™: ç¸½æ”¶ç›Šã€æ”¶ç›Šç‡ã€Sharpe Ratio
    2. é¢¨éšªæŒ‡æ¨™: æœ€å¤§å›æ’¤ã€æ³¢å‹•ç‡ã€å‹ç‡
    3. äº¤æ˜“çµ±è¨ˆ: äº¤æ˜“æ¬¡æ•¸ã€å¹³å‡æŒå€‰æ™‚é–“ã€äº¤æ˜“æˆæœ¬
    4. æŒå€‰çµ±è¨ˆ: å¹³å‡å€‰ä½ã€å€‰ä½åˆ©ç”¨ç‡
    5. æ€§èƒ½å°æ¯”: vs Buy-and-Hold, vs Random Policy
    6. Episode çµ±è¨ˆ: å¹³å‡çå‹µã€æ¨™æº–å·®
    7. æ™‚é–“æ•ˆç‡: æ¨ç†é€Ÿåº¦

ä½¿ç”¨ç¯„ä¾‹ï¼š
    # è©•ä¼°æœ€ä½³æ¨¡å‹
    python scripts/evaluate_sb3.py --model checkpoints/sb3/ppo_deeplob/best_model

    # è©³ç´°è©•ä¼°ï¼ˆ20 episodes + ä¿å­˜å ±å‘Šï¼‰
    python scripts/evaluate_sb3.py \
        --model checkpoints/sb3/ppo_deeplob/best_model \
        --n-episodes 20 \
        --save-report

    # æŒ‡å®šæ¸¬è©¦é›†è©•ä¼°
    python scripts/evaluate_sb3.py \
        --model checkpoints/sb3/ppo_deeplob/ppo_deeplob_final \
        --data-mode test \
        --deterministic

ä½œè€…: SB3-DeepLOB å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-10-24
ç‰ˆæœ¬: v1.0
"""

import sys
import os
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import argparse
import yaml
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple

import numpy as np
import torch
from stable_baselines3 import PPO

from src.envs.tw_lob_trading_env import TaiwanLOBTradingEnv

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config(config_path: str = 'configs/sb3_config.yaml') -> dict:
    """è¼‰å…¥é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def load_model(model_path: str, device: str = 'cuda') -> PPO:
    """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
    if not os.path.exists(model_path) and not os.path.exists(f"{model_path}.zip"):
        raise FileNotFoundError(f"æ¨¡å‹ä¸å­˜åœ¨: {model_path}")

    try:
        model = PPO.load(model_path, device=device)
        logger.info(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ: {model_path}")
        return model
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        raise


def create_eval_env(config: dict, data_mode: str = 'test') -> TaiwanLOBTradingEnv:
    """å‰µå»ºè©•ä¼°ç’°å¢ƒ"""
    env_config = config['env_config'].copy()
    env_config['data_mode'] = data_mode

    env = TaiwanLOBTradingEnv(env_config)
    logger.info(f"âœ… è©•ä¼°ç’°å¢ƒå‰µå»ºæˆåŠŸï¼ˆæ•¸æ“šæ¨¡å¼: {data_mode}ï¼‰")

    return env


def evaluate_episode(
    model: PPO,
    env: TaiwanLOBTradingEnv,
    deterministic: bool = True,
    render: bool = False
) -> Dict:
    """è©•ä¼°å–®å€‹ episode"""
    obs, info = env.reset()
    episode_reward = 0
    episode_length = 0

    # äº¤æ˜“çµ±è¨ˆ
    trades = []
    positions = []
    rewards = []
    actions_taken = []

    done = False
    while not done:
        # é æ¸¬å‹•ä½œ
        action, _states = model.predict(obs, deterministic=deterministic)

        # åŸ·è¡Œå‹•ä½œ
        obs, reward, terminated, truncated, info = env.step(action)

        # è¨˜éŒ„
        episode_reward += reward
        episode_length += 1
        rewards.append(reward)
        actions_taken.append(action)
        positions.append(env.position)

        # è¨˜éŒ„äº¤æ˜“
        if action != 0:  # Buy or Sell
            trades.append({
                'step': episode_length,
                'action': int(action),
                'position': env.position,
                'price': info.get('price', 0),
                'reward': reward
            })

        done = terminated or truncated

        if render:
            env.render()

    # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
    episode_stats = {
        'total_reward': episode_reward,
        'episode_length': episode_length,
        'n_trades': len(trades),
        'final_position': env.position,
        'final_balance': env.balance,
        'rewards': rewards,
        'positions': positions,
        'actions': actions_taken,
        'trades': trades
    }

    return episode_stats


def calculate_metrics(all_episodes: List[Dict]) -> Dict:
    """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
    n_episodes = len(all_episodes)

    # 1. æ”¶ç›ŠæŒ‡æ¨™
    total_rewards = [ep['total_reward'] for ep in all_episodes]
    final_balances = [ep['final_balance'] for ep in all_episodes]

    avg_reward = np.mean(total_rewards)
    std_reward = np.std(total_rewards)
    avg_balance = np.mean(final_balances)

    # è¨ˆç®—æ”¶ç›Šç‡
    initial_balance = 10000.0  # å¾é…ç½®è®€å–
    returns = [(b - initial_balance) / initial_balance * 100 for b in final_balances]
    avg_return = np.mean(returns)

    # è¨ˆç®— Sharpe Ratioï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
    if std_reward > 0:
        sharpe_ratio = avg_reward / std_reward * np.sqrt(252)  # å¹´åŒ–
    else:
        sharpe_ratio = 0.0

    # 2. é¢¨éšªæŒ‡æ¨™
    # æœ€å¤§å›æ’¤
    max_drawdowns = []
    for ep in all_episodes:
        rewards = ep['rewards']
        cumsum = np.cumsum(rewards)
        running_max = np.maximum.accumulate(cumsum)
        drawdown = running_max - cumsum
        max_drawdown = np.max(drawdown) if len(drawdown) > 0 else 0
        max_drawdowns.append(max_drawdown)

    avg_max_drawdown = np.mean(max_drawdowns)

    # å‹ç‡
    wins = sum(1 for r in total_rewards if r > 0)
    win_rate = wins / n_episodes * 100

    # 3. äº¤æ˜“çµ±è¨ˆ
    total_trades = [ep['n_trades'] for ep in all_episodes]
    avg_trades = np.mean(total_trades)

    # å¹³å‡æŒå€‰æ™‚é–“
    avg_position_sizes = []
    for ep in all_episodes:
        positions = ep['positions']
        non_zero = [abs(p) for p in positions if p != 0]
        if len(non_zero) > 0:
            avg_position_sizes.append(np.mean(non_zero))

    avg_position = np.mean(avg_position_sizes) if len(avg_position_sizes) > 0 else 0

    # æŒå€‰åˆ©ç”¨ç‡
    position_utilization = []
    for ep in all_episodes:
        positions = ep['positions']
        non_zero_ratio = sum(1 for p in positions if p != 0) / len(positions) * 100
        position_utilization.append(non_zero_ratio)

    avg_utilization = np.mean(position_utilization)

    # 4. å‹•ä½œåˆ†å¸ƒ
    all_actions = []
    for ep in all_episodes:
        all_actions.extend(ep['actions'])

    action_dist = {
        'hold': sum(1 for a in all_actions if a == 0) / len(all_actions) * 100,
        'buy': sum(1 for a in all_actions if a == 1) / len(all_actions) * 100,
        'sell': sum(1 for a in all_actions if a == 2) / len(all_actions) * 100
    }

    # çµ„ç¹”çµæœ
    metrics = {
        # æ”¶ç›ŠæŒ‡æ¨™
        'avg_reward': float(avg_reward),
        'std_reward': float(std_reward),
        'avg_return_pct': float(avg_return),
        'sharpe_ratio': float(sharpe_ratio),
        'avg_final_balance': float(avg_balance),

        # é¢¨éšªæŒ‡æ¨™
        'avg_max_drawdown': float(avg_max_drawdown),
        'win_rate_pct': float(win_rate),

        # äº¤æ˜“çµ±è¨ˆ
        'avg_trades_per_episode': float(avg_trades),
        'avg_position_size': float(avg_position),
        'position_utilization_pct': float(avg_utilization),

        # å‹•ä½œåˆ†å¸ƒ
        'action_distribution': action_dist,

        # Episode çµ±è¨ˆ
        'n_episodes': n_episodes,
        'avg_episode_length': float(np.mean([ep['episode_length'] for ep in all_episodes]))
    }

    return metrics


def print_metrics(metrics: Dict):
    """æ‰“å°è©•ä¼°æŒ‡æ¨™"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š è©•ä¼°çµæœ")
    logger.info("=" * 60)

    logger.info("\nã€æ”¶ç›ŠæŒ‡æ¨™ã€‘")
    logger.info(f"  å¹³å‡ Episode çå‹µ: {metrics['avg_reward']:.4f} Â± {metrics['std_reward']:.4f}")
    logger.info(f"  å¹³å‡æ”¶ç›Šç‡: {metrics['avg_return_pct']:.2f}%")
    logger.info(f"  Sharpe Ratio: {metrics['sharpe_ratio']:.4f}")
    logger.info(f"  å¹³å‡æœ€çµ‚é¤˜é¡: ${metrics['avg_final_balance']:.2f}")

    logger.info("\nã€é¢¨éšªæŒ‡æ¨™ã€‘")
    logger.info(f"  å¹³å‡æœ€å¤§å›æ’¤: {metrics['avg_max_drawdown']:.4f}")
    logger.info(f"  å‹ç‡: {metrics['win_rate_pct']:.2f}%")

    logger.info("\nã€äº¤æ˜“çµ±è¨ˆã€‘")
    logger.info(f"  å¹³å‡äº¤æ˜“æ¬¡æ•¸: {metrics['avg_trades_per_episode']:.1f}")
    logger.info(f"  å¹³å‡æŒå€‰å¤§å°: {metrics['avg_position_size']:.2f}")
    logger.info(f"  æŒå€‰åˆ©ç”¨ç‡: {metrics['position_utilization_pct']:.2f}%")

    logger.info("\nã€å‹•ä½œåˆ†å¸ƒã€‘")
    action_dist = metrics['action_distribution']
    logger.info(f"  Hold: {action_dist['hold']:.2f}%")
    logger.info(f"  Buy:  {action_dist['buy']:.2f}%")
    logger.info(f"  Sell: {action_dist['sell']:.2f}%")

    logger.info("\nã€Episode çµ±è¨ˆã€‘")
    logger.info(f"  è©•ä¼° Episodes: {metrics['n_episodes']}")
    logger.info(f"  å¹³å‡ Episode é•·åº¦: {metrics['avg_episode_length']:.1f}")

    # æ€§èƒ½è©•ä¼°
    logger.info("\nã€æ€§èƒ½è©•ä¼°ã€‘")
    if metrics['sharpe_ratio'] >= 2.0:
        logger.info("  âœ… å„ªç§€ (Sharpe Ratio >= 2.0)")
    elif metrics['sharpe_ratio'] >= 1.5:
        logger.info("  âœ… è‰¯å¥½ (Sharpe Ratio >= 1.5)")
    elif metrics['sharpe_ratio'] >= 1.0:
        logger.info("  âš ï¸  åŠæ ¼ (Sharpe Ratio >= 1.0)")
    else:
        logger.info("  âŒ éœ€æ”¹é€² (Sharpe Ratio < 1.0)")


def save_report(metrics: Dict, all_episodes: List[Dict], output_path: str):
    """ä¿å­˜è©•ä¼°å ±å‘Š"""
    report = {
        'evaluation_time': datetime.now().isoformat(),
        'metrics': metrics,
        'episode_details': [
            {
                'episode': i,
                'total_reward': ep['total_reward'],
                'episode_length': ep['episode_length'],
                'n_trades': ep['n_trades'],
                'final_balance': ep['final_balance']
            }
            for i, ep in enumerate(all_episodes)
        ]
    }

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    logger.info(f"âœ… è©•ä¼°å ±å‘Šå·²ä¿å­˜: {output_path}")


def main():
    parser = argparse.ArgumentParser(description='SB3 æ¨¡å‹è©•ä¼°')
    parser.add_argument('--model', type=str, required=True,
                      help='æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--config', type=str, default='configs/sb3_config.yaml',
                      help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--n-episodes', type=int, default=10,
                      help='è©•ä¼° episode æ•¸é‡')
    parser.add_argument('--data-mode', type=str, default='test',
                      help='æ•¸æ“šæ¨¡å¼: train / val / test')
    parser.add_argument('--deterministic', action='store_true', default=True,
                      help='ä½¿ç”¨ç¢ºå®šæ€§ç­–ç•¥')
    parser.add_argument('--device', type=str, default='cuda',
                      help='è¨­å‚™: cuda / cpu')
    parser.add_argument('--save-report', action='store_true',
                      help='ä¿å­˜è©•ä¼°å ±å‘Š')
    parser.add_argument('--output-dir', type=str, default='results/sb3_eval',
                      help='è¼¸å‡ºç›®éŒ„')

    args = parser.parse_args()

    logger.info("=" * 60)
    logger.info("ğŸš€ SB3 æ¨¡å‹è©•ä¼°è…³æœ¬")
    logger.info("=" * 60)

    # æª¢æŸ¥ CUDA
    if args.device == 'cuda' and not torch.cuda.is_available():
        logger.warning("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œæ”¹ç”¨ CPU")
        args.device = 'cpu'

    try:
        # 1. è¼‰å…¥é…ç½®
        logger.info(f"\nğŸ“„ è¼‰å…¥é…ç½®: {args.config}")
        config = load_config(args.config)

        # 2. è¼‰å…¥æ¨¡å‹
        logger.info(f"\nğŸ¤– è¼‰å…¥æ¨¡å‹: {args.model}")
        model = load_model(args.model, device=args.device)

        # 3. å‰µå»ºè©•ä¼°ç’°å¢ƒ
        logger.info(f"\nğŸ—ï¸  å‰µå»ºè©•ä¼°ç’°å¢ƒ")
        env = create_eval_env(config, data_mode=args.data_mode)

        # 4. é‹è¡Œè©•ä¼°
        logger.info(f"\nğŸ¯ é–‹å§‹è©•ä¼° ({args.n_episodes} episodes)")
        all_episodes = []

        for i in range(args.n_episodes):
            logger.info(f"  Episode {i+1}/{args.n_episodes}...")
            episode_stats = evaluate_episode(model, env, deterministic=args.deterministic)
            all_episodes.append(episode_stats)

            logger.info(f"    çå‹µ: {episode_stats['total_reward']:.4f}, "
                       f"äº¤æ˜“: {episode_stats['n_trades']}, "
                       f"æœ€çµ‚é¤˜é¡: ${episode_stats['final_balance']:.2f}")

        # 5. è¨ˆç®—æŒ‡æ¨™
        logger.info("\nğŸ“Š è¨ˆç®—è©•ä¼°æŒ‡æ¨™")
        metrics = calculate_metrics(all_episodes)

        # 6. æ‰“å°çµæœ
        print_metrics(metrics)

        # 7. ä¿å­˜å ±å‘Š
        if args.save_report:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_name = os.path.basename(args.model)
            output_path = os.path.join(
                args.output_dir,
                f"eval_{model_name}_{timestamp}.json"
            )
            save_report(metrics, all_episodes, output_path)

        # 8. ç¸½çµ
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ è©•ä¼°å®Œæˆ")
        logger.info("=" * 60)

        return 0

    except Exception as e:
        logger.error("\n" + "=" * 60)
        logger.error("âŒ è©•ä¼°å¤±æ•—")
        logger.error("=" * 60)
        logger.error(f"éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
