"""PPO + DeepLOB å®Œæ•´è¨“ç·´è…³æœ¬ - é›™å±¤å­¸ç¿’æ¶æ§‹

æ­¤è…³æœ¬å¯¦ç¾å®Œæ•´çš„ DeepLOB + SB3 PPO æ•´åˆè¨“ç·´ï¼š
    ç¬¬ä¸€å±¤: DeepLOB æå– LOB æ·±å±¤ç‰¹å¾µï¼ˆå‡çµæ¬Šé‡ï¼‰
    ç¬¬äºŒå±¤: PPO å­¸ç¿’æœ€å„ªäº¤æ˜“ç­–ç•¥

åŠŸèƒ½ï¼š
    1. è¼‰å…¥é è¨“ç·´ DeepLOB æ¨¡å‹
    2. å‰µå»ºå¸¶ DeepLOB ç‰¹å¾µæå–å™¨çš„ PPO æ¨¡å‹
    3. åŸ·è¡Œå®Œæ•´è¨“ç·´ï¼ˆæ¨è–¦ 1M stepsï¼‰
    4. æŒçºŒè©•ä¼°èˆ‡ä¿å­˜æœ€ä½³æ¨¡å‹

ä½¿ç”¨ç¯„ä¾‹ï¼š
    # å®Œæ•´è¨“ç·´ï¼ˆ1M stepsï¼Œæ¨è–¦ï¼Œ4-8 å°æ™‚ RTX 5090ï¼‰
    python scripts/train_sb3_deeplob.py

    # å¿«é€Ÿæ¸¬è©¦ï¼ˆ10K stepsï¼Œ10 åˆ†é˜ï¼‰
    python scripts/train_sb3_deeplob.py --test

    # æŒ‡å®šé…ç½®æ–‡ä»¶
    python scripts/train_sb3_deeplob.py --config configs/sb3_deeplob_config.yaml

    # æŒ‡å®š DeepLOB æª¢æŸ¥é»
    python scripts/train_sb3_deeplob.py \
        --deeplob-checkpoint checkpoints/v5/deeplob_v5_best.pth

    # é«˜æ€§èƒ½è¨“ç·´ï¼ˆå¤§ batch size + ä¸¦è¡Œç’°å¢ƒï¼‰
    python scripts/train_sb3_deeplob.py --n-envs 4 --device cuda

    # ç›£æ§è¨“ç·´
    tensorboard --logdir logs/sb3_deeplob/

ä½œè€…: SB3-DeepLOB å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-10-26
ç‰ˆæœ¬: v2.0 (ç§»é™¤æ‰€æœ‰ç¡¬ç·¨ç¢¼ï¼Œä½¿ç”¨ YAMLManager)
"""

import sys
import os
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import argparse
import logging
from datetime import datetime

import torch
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
from stable_baselines3.common.callbacks import (
    CheckpointCallback,
    EvalCallback,
    CallbackList
)
from stable_baselines3.common.monitor import Monitor

from src.envs.tw_lob_trading_env import TaiwanLOBTradingEnv
from src.models.deeplob_feature_extractor import (
    DeepLOBExtractor,
    make_deeplob_policy_kwargs
)
from src.utils.yaml_manager import YAMLManager

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config(config_path: str) -> dict:
    """è¼‰å…¥é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨ YAMLManagerï¼‰"""
    try:
        yaml_manager = YAMLManager(config_path)
        config = yaml_manager.as_dict()
        logger.info(f"âœ… é…ç½®è¼‰å…¥æˆåŠŸ: {config_path}")
        return config
    except FileNotFoundError:
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    except Exception as e:
        raise RuntimeError(f"é…ç½®è¼‰å…¥å¤±æ•—: {e}")


def verify_deeplob_checkpoint(checkpoint_path: str, config: dict):
    """é©—è­‰ DeepLOB æª¢æŸ¥é»å­˜åœ¨"""
    # æª¢æŸ¥æ˜¯å¦éœ€è¦é©—è­‰
    if not config.get('validation', {}).get('verify_checkpoint', True):
        logger.info("â­ï¸  è·³é DeepLOB æª¢æŸ¥é»é©—è­‰")
        return

    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(
            f"DeepLOB æª¢æŸ¥é»ä¸å­˜åœ¨: {checkpoint_path}\n"
            f"è«‹ç¢ºèªæ–‡ä»¶è·¯å¾‘æˆ–å…ˆè¨“ç·´ DeepLOB æ¨¡å‹"
        )

    # å˜—è©¦è¼‰å…¥æª¢æŸ¥é»
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        logger.info(f"âœ… DeepLOB æª¢æŸ¥é»é©—è­‰æˆåŠŸ: {checkpoint_path}")

        # é¡¯ç¤ºæª¢æŸ¥é»ä¿¡æ¯
        if isinstance(checkpoint, dict):
            if 'epoch' in checkpoint:
                logger.info(f"  - Epoch: {checkpoint['epoch']}")
            if 'val_acc' in checkpoint:
                logger.info(f"  - é©—è­‰æº–ç¢ºç‡: {checkpoint['val_acc']:.4f}")
            if 'test_acc' in checkpoint:
                logger.info(f"  - æ¸¬è©¦æº–ç¢ºç‡: {checkpoint['test_acc']:.4f}")

    except Exception as e:
        raise RuntimeError(f"DeepLOB æª¢æŸ¥é»è¼‰å…¥å¤±æ•—: {e}")


def make_env(env_config: dict, rank: int = 0):
    """å‰µå»ºç’°å¢ƒå·¥å» å‡½æ•¸ï¼ˆç”¨æ–¼å‘é‡åŒ–ç’°å¢ƒï¼‰"""
    def _init():
        env = TaiwanLOBTradingEnv(env_config)
        env = Monitor(env)
        return env
    return _init


def create_vec_env(config: dict, n_envs: int = None, vec_type: str = None):
    """å‰µå»ºå‘é‡åŒ–ç’°å¢ƒ"""
    env_config = config['env_config']

    # å¾é…ç½®è®€å–é è¨­å€¼ï¼ˆå¦‚æœå‘½ä»¤è¡ŒæœªæŒ‡å®šï¼‰
    if n_envs is None:
        n_envs = config.get('vec_env', {}).get('n_envs', 1)
    if vec_type is None:
        vec_type = config.get('vec_env', {}).get('vec_type', 'dummy')

    if n_envs == 1:
        env = TaiwanLOBTradingEnv(env_config)
        env = Monitor(env)
        env = DummyVecEnv([lambda: env])
        logger.info("âœ… å‰µå»ºå–®ä¸€ç’°å¢ƒ")
    else:
        env_fns = [make_env(env_config, i) for i in range(n_envs)]

        if vec_type == "subproc":
            env = SubprocVecEnv(env_fns)
            logger.info(f"âœ… å‰µå»º SubprocVecEnv ({n_envs} å€‹ç’°å¢ƒ)")
        else:
            env = DummyVecEnv(env_fns)
            logger.info(f"âœ… å‰µå»º DummyVecEnv ({n_envs} å€‹ç’°å¢ƒ)")

    return env


def create_eval_env(config: dict):
    """å‰µå»ºè©•ä¼°ç’°å¢ƒï¼ˆä½¿ç”¨é©—è­‰é›†ï¼‰"""
    eval_config = config.get('evaluation', {}).get('eval_env_config', {})
    env_config = config['env_config'].copy()
    env_config.update(eval_config)

    env = TaiwanLOBTradingEnv(env_config)
    env = Monitor(env)
    logger.info("âœ… å‰µå»ºè©•ä¼°ç’°å¢ƒï¼ˆé©—è­‰é›†ï¼‰")

    return env


def create_callbacks(config: dict, eval_env):
    """å‰µå»ºè¨“ç·´å›èª¿"""
    callbacks = []

    # Checkpoint Callback
    checkpoint_config = config.get('callbacks', {}).get('checkpoint', {})
    if checkpoint_config.get('enabled', True):
        checkpoint_callback = CheckpointCallback(
            save_freq=checkpoint_config.get('save_freq', 50000),
            save_path=checkpoint_config.get('save_path', 'checkpoints/sb3/ppo_deeplob'),
            name_prefix=checkpoint_config.get('name_prefix', 'ppo_model'),
            save_replay_buffer=checkpoint_config.get('save_replay_buffer', False),
            save_vecnormalize=checkpoint_config.get('save_vecnormalize', False),
        )
        callbacks.append(checkpoint_callback)
        logger.info(f"âœ… Checkpoint Callback (æ¯ {checkpoint_config.get('save_freq', 50000)} steps)")

    # Eval Callback
    eval_config = config.get('callbacks', {}).get('eval', {})
    if eval_config.get('enabled', True) and eval_env is not None:
        eval_callback = EvalCallback(
            eval_env,
            eval_freq=eval_config.get('eval_freq', 10000),
            n_eval_episodes=eval_config.get('n_eval_episodes', 10),
            best_model_save_path=eval_config.get('best_model_save_path', 'checkpoints/sb3/ppo_deeplob'),
            log_path=eval_config.get('log_path', 'logs/sb3_eval'),
            deterministic=eval_config.get('deterministic', True),
            render=False,
        )
        callbacks.append(eval_callback)
        logger.info(f"âœ… Eval Callback (æ¯ {eval_config.get('eval_freq', 10000)} steps)")

    if len(callbacks) > 0:
        return CallbackList(callbacks)
    else:
        return None


def create_ppo_deeplob_model(env, config: dict, deeplob_checkpoint: str, device: str = None):
    """å‰µå»ºæ•´åˆ DeepLOB çš„ PPO æ¨¡å‹"""
    ppo_config = config.get('ppo', {})
    deeplob_config = config.get('deeplob_extractor', {})

    # å¾é…ç½®è®€å–è¨­å‚™ï¼ˆå¦‚æœå‘½ä»¤è¡ŒæœªæŒ‡å®šï¼‰
    if device is None:
        device = config.get('device', {}).get('default', 'cuda')

    logger.info("ğŸ”¨ æ§‹å»º PPO + DeepLOB æ¨¡å‹")

    # ä½¿ç”¨ DeepLOB ç‰¹å¾µæå–å™¨
    if deeplob_config.get('use_deeplob', True):
        logger.info("  - æ¨¡å¼: DeepLOB ç‰¹å¾µæå–å™¨")

        # å‰µå»º policy_kwargs
        policy_kwargs = make_deeplob_policy_kwargs(
            deeplob_checkpoint=deeplob_checkpoint,
            features_dim=deeplob_config.get('features_dim', 128),
            use_lstm_hidden=deeplob_config.get('use_lstm_hidden', False),
            net_arch=ppo_config.get('net_arch', dict(pi=[256, 128], vf=[256, 128]))
        )

        logger.info(f"  - DeepLOB æª¢æŸ¥é»: {deeplob_checkpoint}")
        logger.info(f"  - ç‰¹å¾µç¶­åº¦: {deeplob_config.get('features_dim', 128)}")
        logger.info(f"  - å‡çµ DeepLOB: {deeplob_config.get('freeze_deeplob', True)}")

    else:
        # ä¸ä½¿ç”¨ DeepLOBï¼ˆå›é€€åˆ°åŸºç¤ MlpPolicyï¼‰
        logger.warning("âš ï¸  æœªå•Ÿç”¨ DeepLOB ç‰¹å¾µæå–å™¨ï¼Œä½¿ç”¨åŸºç¤ MlpPolicy")
        policy_kwargs = dict(
            net_arch=ppo_config.get('net_arch', dict(pi=[256, 128], vf=[256, 128]))
        )

    # å‰µå»º PPO æ¨¡å‹
    model = PPO(
        "MlpPolicy",
        env,
        learning_rate=ppo_config.get('learning_rate', 3e-4),
        n_steps=ppo_config.get('n_steps', 2048),
        batch_size=ppo_config.get('batch_size', 64),
        n_epochs=ppo_config.get('n_epochs', 10),
        gamma=ppo_config.get('gamma', 0.99),
        gae_lambda=ppo_config.get('gae_lambda', 0.95),
        clip_range=ppo_config.get('clip_range', 0.2),
        ent_coef=ppo_config.get('ent_coef', 0.01),
        vf_coef=ppo_config.get('vf_coef', 0.5),
        max_grad_norm=ppo_config.get('max_grad_norm', 0.5),
        policy_kwargs=policy_kwargs,
        tensorboard_log=config.get('training', {}).get('tensorboard_log', 'logs/sb3_deeplob'),
        verbose=ppo_config.get('verbose', 1),
        seed=ppo_config.get('seed', 42),
        device=device
    )

    logger.info("âœ… PPO + DeepLOB æ¨¡å‹å‰µå»ºæˆåŠŸ")
    logger.info(f"  - Policy: MlpPolicy + DeepLOBExtractor")
    logger.info(f"  - Learning Rate: {ppo_config.get('learning_rate', 3e-4)}")
    logger.info(f"  - Gamma: {ppo_config.get('gamma', 0.99)}")
    logger.info(f"  - N Steps: {ppo_config.get('n_steps', 2048)}")
    logger.info(f"  - Batch Size: {ppo_config.get('batch_size', 64)}")
    logger.info(f"  - Device: {device}")

    return model


def train_model(model, config: dict, callbacks=None):
    """è¨“ç·´æ¨¡å‹"""
    training_config = config.get('training', {})
    total_timesteps = training_config.get('total_timesteps', 1000000)
    log_interval = training_config.get('log_interval', 10)
    progress_bar = training_config.get('progress_bar', True)

    logger.info("=" * 60)
    logger.info("ğŸš€ é–‹å§‹è¨“ç·´ (PPO + DeepLOB)")
    logger.info("=" * 60)
    logger.info(f"ç¸½æ­¥æ•¸: {total_timesteps:,}")

    start_time = datetime.now()

    model.learn(
        total_timesteps=total_timesteps,
        callback=callbacks,
        log_interval=log_interval,
        progress_bar=progress_bar
    )

    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()

    logger.info("=" * 60)
    logger.info("âœ… è¨“ç·´å®Œæˆ")
    logger.info("=" * 60)
    logger.info(f"è¨“ç·´æ™‚é–“: {duration/60:.2f} åˆ†é˜ ({duration/3600:.2f} å°æ™‚)")
    logger.info(f"è¨“ç·´é€Ÿåº¦: {total_timesteps/duration:.1f} steps/sec")

    return model


def save_final_model(model, config: dict):
    """ä¿å­˜æœ€çµ‚æ¨¡å‹"""
    training_config = config.get('training', {})
    save_dir = training_config.get('checkpoint_dir', 'checkpoints/sb3/ppo_deeplob')
    model_name = training_config.get('final_model_name', 'ppo_deeplob_final')

    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, model_name)

    model.save(save_path)
    logger.info(f"âœ… æœ€çµ‚æ¨¡å‹å·²ä¿å­˜: {save_path}.zip")

    return save_path


def apply_test_mode(config: dict):
    """æ‡‰ç”¨æ¸¬è©¦æ¨¡å¼é…ç½®"""
    test_config = config.get('test_mode', {})

    # æ›´æ–°è¨“ç·´é…ç½®
    config['training']['total_timesteps'] = test_config.get('total_timesteps', 10000)
    config['callbacks']['checkpoint']['save_freq'] = test_config.get('save_freq', 5000)
    config['callbacks']['eval']['eval_freq'] = test_config.get('eval_freq', 5000)
    config['callbacks']['eval']['n_eval_episodes'] = test_config.get('n_eval_episodes', 3)
    config['ppo']['n_steps'] = test_config.get('n_steps', 512)
    config['ppo']['batch_size'] = test_config.get('batch_size', 32)

    logger.info("ğŸ§ª æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨")
    logger.info(f"  - è¨“ç·´æ­¥æ•¸: {config['training']['total_timesteps']:,}")
    logger.info(f"  - Checkpoint é »ç‡: {config['callbacks']['checkpoint']['save_freq']:,}")
    logger.info(f"  - è©•ä¼°é »ç‡: {config['callbacks']['eval']['eval_freq']:,}")


def show_next_steps(config: dict):
    """é¡¯ç¤ºè¨“ç·´å®Œæˆå¾Œçš„ä¸‹ä¸€æ­¥å»ºè­°"""
    if not config.get('output', {}).get('show_next_steps', True):
        return

    output_config = config.get('output', {})
    tensorboard_log = config.get('training', {}).get('tensorboard_log', 'logs/sb3_deeplob')
    best_model_path = output_config.get('best_model_path', 'checkpoints/sb3/ppo_deeplob/best_model')

    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‰ è¨“ç·´æµç¨‹å®Œæˆ")
    logger.info("=" * 60)
    logger.info(f"âœ… æ—¥èªŒç›®éŒ„: {tensorboard_log}")
    logger.info("\nä¸‹ä¸€æ­¥:")
    logger.info(f"  1. æŸ¥çœ‹è¨“ç·´æ—¥èªŒ: tensorboard --logdir {tensorboard_log}")
    logger.info(f"  2. è©•ä¼°æœ€ä½³æ¨¡å‹: python scripts/evaluate_sb3.py --model {best_model_path}")
    logger.info(f"  3. é–‹å§‹è¶…åƒæ•¸å„ªåŒ–ï¼ˆéšæ®µä¸‰ï¼‰")


def main():
    parser = argparse.ArgumentParser(description='PPO + DeepLOB å®Œæ•´è¨“ç·´')
    parser.add_argument('--config', type=str, default='configs/sb3_deeplob_config.yaml',
                      help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--deeplob-checkpoint', type=str, default=None,
                      help='DeepLOB æª¢æŸ¥é»è·¯å¾‘ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--timesteps', type=int, default=None,
                      help='è¨“ç·´æ­¥æ•¸ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--device', type=str, default=None,
                      help='è¨­å‚™: cuda / cpuï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--test', action='store_true',
                      help='æ¸¬è©¦æ¨¡å¼ï¼ˆå¿«é€Ÿé©—è­‰æµç¨‹ï¼‰')
    parser.add_argument('--n-envs', type=int, default=None,
                      help='ä¸¦è¡Œç’°å¢ƒæ•¸é‡ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--vec-type', type=str, default=None,
                      help='å‘é‡åŒ–é¡å‹: dummy / subprocï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰')

    args = parser.parse_args()

    logger.info("=" * 60)
    logger.info("ğŸš€ PPO + DeepLOB å®Œæ•´è¨“ç·´è…³æœ¬ v2.0")
    logger.info("=" * 60)

    try:
        # 1. è¼‰å…¥é…ç½®
        logger.info(f"\nğŸ“„ è¼‰å…¥é…ç½®: {args.config}")
        config = load_config(args.config)

        # é¡¯ç¤ºå°ˆæ¡ˆä¿¡æ¯
        project_info = config.get('project', {})
        if project_info:
            logger.info(f"  - å°ˆæ¡ˆ: {project_info.get('name', 'N/A')}")
            logger.info(f"  - ç‰ˆæœ¬: {project_info.get('version', 'N/A')}")
            logger.info(f"  - æè¿°: {project_info.get('description', 'N/A')}")

        # 2. æ‡‰ç”¨å‘½ä»¤è¡Œåƒæ•¸è¦†è“‹
        if args.test:
            apply_test_mode(config)

        if args.timesteps is not None:
            config['training']['total_timesteps'] = args.timesteps
            logger.info(f"âš™ï¸  è¦†è“‹è¨“ç·´æ­¥æ•¸: {args.timesteps:,}")

        # 3. ç¢ºå®š DeepLOB æª¢æŸ¥é»è·¯å¾‘
        deeplob_checkpoint = args.deeplob_checkpoint or config['env_config'].get('deeplob_checkpoint')
        if not deeplob_checkpoint:
            raise ValueError("æœªæŒ‡å®š DeepLOB æª¢æŸ¥é»è·¯å¾‘")

        # 4. ç¢ºå®šè¨­å‚™
        device = args.device
        if device is None:
            device = config.get('device', {}).get('default', 'cuda')

        # æª¢æŸ¥ CUDA
        auto_fallback = config.get('device', {}).get('auto_fallback', True)
        if device == 'cuda' and not torch.cuda.is_available():
            if auto_fallback:
                logger.warning("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œè‡ªå‹•å›é€€åˆ° CPU")
                device = 'cpu'
            else:
                raise RuntimeError("CUDA ä¸å¯ç”¨ä¸”æœªå•Ÿç”¨è‡ªå‹•å›é€€")

        logger.info(f"âœ… ä½¿ç”¨è¨­å‚™: {device}")
        if device == 'cuda':
            logger.info(f"  - GPU: {torch.cuda.get_device_name(0)}")
            total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            logger.info(f"  - ç¸½é¡¯å­˜: {total_memory:.2f} GB")

        # 5. é©—è­‰ DeepLOB æª¢æŸ¥é»
        logger.info(f"\nğŸ” é©—è­‰ DeepLOB æª¢æŸ¥é»")
        verify_deeplob_checkpoint(deeplob_checkpoint, config)

        # 6. å‰µå»ºè¨“ç·´ç’°å¢ƒ
        logger.info("\nğŸ—ï¸  å‰µå»ºè¨“ç·´ç’°å¢ƒ")
        env = create_vec_env(config, n_envs=args.n_envs, vec_type=args.vec_type)

        # 7. å‰µå»ºè©•ä¼°ç’°å¢ƒ
        logger.info("\nğŸ—ï¸  å‰µå»ºè©•ä¼°ç’°å¢ƒ")
        eval_env = create_eval_env(config)

        # 8. å‰µå»ºå›èª¿
        logger.info("\nğŸ”” è¨­ç½®è¨“ç·´å›èª¿")
        callbacks = create_callbacks(config, eval_env)

        # 9. å‰µå»º PPO + DeepLOB æ¨¡å‹
        logger.info("\nğŸ¤– å‰µå»º PPO + DeepLOB æ¨¡å‹")
        model = create_ppo_deeplob_model(
            env,
            config,
            deeplob_checkpoint=deeplob_checkpoint,
            device=device
        )

        # 10. é–‹å§‹è¨“ç·´
        model = train_model(model, config, callbacks=callbacks)

        # 11. ä¿å­˜æœ€çµ‚æ¨¡å‹
        logger.info("\nğŸ’¾ ä¿å­˜æœ€çµ‚æ¨¡å‹")
        save_path = save_final_model(model, config)

        # 12. é¡¯ç¤ºä¸‹ä¸€æ­¥å»ºè­°
        show_next_steps(config)

        return 0

    except Exception as e:
        logger.error("\n" + "=" * 60)
        logger.error("âŒ è¨“ç·´å¤±æ•—")
        logger.error("=" * 60)
        logger.error(f"éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
