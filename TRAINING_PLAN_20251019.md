# DeepLOB V5 重訓計畫 - 2025-10-19

## 🎯 訓練目標

修復實驗 #4 的過擬合和驗證損失爆炸問題，恢復接近 72.98% 的性能水準。

---

## 📊 當前問題診斷

### 實驗 #4 失敗表現 (Epoch 1-15 觀察)

| 問題 | 數據 | 嚴重性 |
|------|------|--------|
| 驗證損失爆炸 | 1.0045 → 2.0036 (+100%) | 🔴 嚴重 |
| 過擬合 | Train 56.13% vs Val 36.92% (差距 19.21%) | 🔴 嚴重 |
| 梯度不穩定 | 1.47 → 7.06 持續增長 | 🔴 嚴重 |
| 性能停滯 | Epoch 14 達最佳後無改善 | 🟡 中等 |

### 根本原因分析

1. **過小的 batch size (256)** → 梯度噪聲過大
2. **過低的 dropout (0.3)** → 正則化不足
3. **過高的學習率 (0.00012)** → 跳躍式學習
4. **過鬆的梯度裁剪 (0.8)** → 梯度爆炸
5. **缺乏標籤平滑 (0.0)** → 過度自信

---

## ⚙️ 新配置：train_v5_recovery.yaml

### 關鍵修復措施

| 類別 | 參數 | 舊值 (#4) | 新值 (#5) | 效果 |
|------|------|----------|----------|------|
| **正則化** | Dropout | 0.3 | **0.5** | 防止過擬合 |
| | Weight decay | 0.0003 | **0.0005** | 增強 L2 |
| | Label smoothing | 0.0 | **0.1** | 防過度自信 |
| **優化器** | Learning rate | 0.00012 | **0.00008** | 更穩定學習 |
| | Batch size | 256 | **512** | 降低梯度噪聲 |
| | Grad clip | 0.8 | **0.5** | 控制梯度爆炸 |
| | Warmup ratio | 0.1 | **0.15** | 穩定啟動 |
| **損失權重** | Manual weights | [1.2, 1.0, 1.3] | **[2.5, 1.0, 2.8]** | 更激進 |
| **訓練長度** | Epochs | 60 | **80** | 延長觀察期 |
| | Patience | 15 | **20** | 更寬容早停 |
| **網絡容量** | LSTM hidden | 48 | **64** | 保持擴容 ✅ |
| | FC hidden | 48 | **64** | 保持擴容 ✅ |

### 設計理念

1. **強正則化策略**：Dropout ↑, Weight decay ↑, Label smoothing ↑
2. **穩定優化策略**：LR ↓, Batch ↑, Grad clip ↓, Warmup ↑
3. **激進加權策略**：Class 0/2 權重大幅提升 (2.5x/2.8x)
4. **延長訓練策略**：更多 epochs 和更寬容的早停

---

## 🚀 執行指令

### 1. 啟動訓練

```bash
conda activate deeplob-pro

python scripts/train_deeplob_v5.py \
    --config configs/train_v5_recovery.yaml \
    --data-dir ./data/processed_v5_balanced/npz \
    --epochs 80
```

### 2. 監控指標

**關鍵指標**:
- ✅ 驗證損失 < 1.5 (不爆炸)
- ✅ Train-Val Acc 差距 < 10%
- ✅ 梯度範數 < 5.0
- ✅ 驗證 F1 > 50% (目標 > 65%)

**每 5 個 epoch 檢查**:
```python
# 過擬合檢測
overfitting_gap = train_acc - val_acc
if overfitting_gap > 10%:
    print("⚠️ 過擬合警告")

# 梯度爆炸檢測
if grad_norm > 5.0:
    print("⚠️ 梯度不穩定")

# 驗證損失檢測
if val_loss > 1.5:
    print("⚠️ 驗證損失過高")
```

---

## 📈 預期結果

### 成功標準

| 指標 | 目標 | 當前最佳 (#4) |
|------|------|-------------|
| 驗證 F1 (Weighted) | **> 65%** | 40.75% ❌ |
| 測試 F1 (Weighted) | **> 60%** | 34.15% ❌ |
| Class 1 Recall | **> 35%** | 25.3% ❌ |
| Train-Val Gap | **< 10%** | 19.21% ❌ |
| 驗證損失 | **< 1.5** | 2.0036 ❌ |
| 梯度範數 | **< 5.0** | 7.06 ❌ |

### 各類別目標

| Class | Precision | Recall | F1 |
|-------|-----------|--------|-----|
| 0 (下跌) | > 60% | > 55% | > 57% |
| 1 (持平) | > 65% | > 40% | > 50% |
| 2 (上漲) | > 55% | > 50% | > 52% |

---

## 📝 數據資訊

**數據源**: `data/processed_v5_balanced/npz/`

- 訓練集: **1,249,419** 樣本
  - Class 0 (下跌): 387,476 (31.0%)
  - Class 1 (持平): 524,563 (42.0%)
  - Class 2 (上漲): 337,380 (27.0%)

**輸出目錄**: `checkpoints/v5_recovery/`

---

## 🔍 故障排除

### 如果驗證損失仍然爆炸
1. 進一步降低學習率至 `0.00005`
2. 增加 dropout 至 `0.6`
3. 增大 batch size 至 `1024`

### 如果過擬合仍然嚴重
1. 增加 label smoothing 至 `0.15`
2. 增加 weight decay 至 `0.001`
3. 考慮添加數據增強

### 如果 Class 1 Recall 仍低
1. 調整手動權重為 `[3.0, 1.0, 3.2]`
2. 啟用平衡採樣器 (但禁用手動權重)
3. 增加訓練 epochs 至 `100`

---

## 📚 參考資料

- **調參歷史**: `docs/20251018-調參歷史.md`
- **配置文件**: `configs/train_v5_recovery.yaml`
- **原始成功配置**: 實驗 #2 (F1 = 72.98%)
- **CLAUDE.md**: 專案整體指導文檔

---

**創建時間**: 2025-10-19
**實驗編號**: #5
**預計訓練時間**: 4-6 小時 (RTX GPU)
**狀態**: 🔄 待執行
