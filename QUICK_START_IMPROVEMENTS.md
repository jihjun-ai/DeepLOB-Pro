# DeepLOB æ”¹é€²æ–¹æ¡ˆ - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

**æ—¥æœŸ**: 2025-10-19
**ç›®æ¨™**: çªç ´ 45-46% è¨“ç·´å¹³å°ï¼Œé”åˆ° 65% æº–ç¢ºç‡

---

## ğŸ“‹ ç¸½è¦½

åŸºæ–¼ ChatGPT çš„ 7 å€‹è¨ºæ–·å•é¡Œï¼Œæˆ‘å·²ç¶“ç‚ºä½ å‰µå»ºäº†å®Œæ•´çš„æ”¹é€²æ–¹æ¡ˆï¼š

### âœ… å·²å®Œæˆçš„å¯¦ä½œ

1. **è¨ºæ–·æ–‡æª”** - [TRAINING_DIAGNOSIS_AND_IMPROVEMENTS.md](TRAINING_DIAGNOSIS_AND_IMPROVEMENTS.md)
2. **é©—è­‰è…³æœ¬** - [scripts/verify_class_weights.py](scripts/verify_class_weights.py)
3. **æ”¹é€²ç‰ˆæ¨¡å‹** - [src/models/deeplob_improved.py](src/models/deeplob_improved.py)
4. **Focal Loss** - [src/models/focal_loss.py](src/models/focal_loss.py)
5. **ECE è©•ä¼°** - [src/evaluation/calibration.py](src/evaluation/calibration.py)

---

## ğŸš€ ç«‹å³é–‹å§‹ï¼ˆ3 æ­¥é©Ÿï¼‰

### éšæ®µ 1: é©—è­‰ç•¶å‰é…ç½®ï¼ˆ5 åˆ†é˜ï¼‰

```bash
# å•Ÿå‹•ç’°å¢ƒ
conda activate deeplob-pro

# é©—è­‰ class weights è¨ˆç®—
python scripts/verify_class_weights.py
```

**é æœŸè¼¸å‡º**:
```
âœ… é¡åˆ¥æ¬Šé‡è¨ˆç®—æ­£ç¢º
âœ… æå¤±å‡½æ•¸æ­£ç¢ºæ‡‰ç”¨æ¬Šé‡
âœ… æ¨£æœ¬æ¬Šé‡å·²ç¦ç”¨ï¼ˆé¿å…å•é¡Œï¼‰
```

---

### éšæ®µ 2: æ¸¬è©¦æ”¹é€²ç‰ˆæ¨¡å‹ï¼ˆ10 åˆ†é˜ï¼‰

#### æ–¹æ¡ˆ A: å¢åŠ æ¨¡å‹å®¹é‡ï¼ˆæœ€ç°¡å–®ï¼Œæœ€å¯èƒ½æœ‰æ•ˆï¼‰

```bash
# 1. è¤‡è£½é…ç½®
cp configs/train_v5_recovery.yaml configs/train_v5_capacity_test.yaml

# 2. æ‰‹å‹•ç·¨è¼¯ configs/train_v5_capacity_test.yaml
#    ä¿®æ”¹ä»¥ä¸‹å…©è¡Œ:
#      lstm_hidden_size: 64  # å¾ 48 å¢åŠ åˆ° 64
#      fc_hidden_size: 64    # å¾ 48 å¢åŠ åˆ° 64

# 3. å¿«é€Ÿè¨“ç·´æ¸¬è©¦ï¼ˆ10 epochsï¼‰
python scripts/train_deeplob_v5.py \
    --config configs/train_v5_capacity_test.yaml \
    --epochs 10
```

**åˆ¤æ–·æ¨™æº–**:
- âœ… å¦‚æœ 10 epochs å¾Œé©—è­‰æº–ç¢ºç‡ > 48%ï¼Œç¹¼çºŒå®Œæ•´è¨“ç·´
- âŒ å¦‚æœä»å¡åœ¨ 45-46%ï¼Œé€²å…¥æ–¹æ¡ˆ B

---

#### æ–¹æ¡ˆ B: ä½¿ç”¨æ”¹é€²ç‰ˆ DeepLOBï¼ˆLayerNorm + Attentionï¼‰

**æ¸¬è©¦æ¨¡å‹**ï¼ˆç¨ç«‹é‹è¡Œï¼‰:

```bash
python -c "
from src.models.deeplob_improved import DeepLOBImproved
import torch

model = DeepLOBImproved(
    num_classes=3,
    lstm_hidden=64,
    dropout=0.5,
    use_layer_norm=True,
    use_attention=True
)

x = torch.randn(16, 100, 20)
logits = model(x)
print(f'âœ… æ¨¡å‹æ¸¬è©¦æˆåŠŸ: {logits.shape}')
"
```

**æ•´åˆåˆ°è¨“ç·´**ï¼ˆéœ€è¦ä¿®æ”¹è¨“ç·´è…³æœ¬ï¼‰:

1. æ‰“é–‹ `scripts/train_deeplob_v5.py`
2. åœ¨ imports éƒ¨åˆ†åŠ å…¥:
   ```python
   from src.models.deeplob_improved import DeepLOBImproved
   ```
3. åœ¨é…ç½®ä¸­åŠ å…¥æ¨¡å‹é¡å‹é¸é …:
   ```yaml
   model:
     type: "deeplob_improved"  # æˆ– "deeplob" (åŸç‰ˆ)
     use_layer_norm: true
     use_attention: true
   ```
4. ä¿®æ”¹æ¨¡å‹åˆå§‹åŒ–é‚è¼¯ï¼ˆè¦‹ä¸‹æ–¹å®Œæ•´ä¿®æ”¹ï¼‰

---

### éšæ®µ 3: è©¦ç”¨ Focal Lossï¼ˆ20 åˆ†é˜ï¼‰

**æ¸¬è©¦ Focal Loss**:

```bash
python -c "
from src.models.focal_loss import FocalLoss
import torch

criterion = FocalLoss(gamma=2.0, label_smoothing=0.15)

logits = torch.randn(32, 3)
labels = torch.randint(0, 3, (32,))

loss = criterion(logits, labels)
print(f'âœ… Focal Loss æ¸¬è©¦æˆåŠŸ: {loss.item():.4f}')
"
```

**æ•´åˆåˆ°è¨“ç·´**ï¼ˆè¦‹ä¸‹æ–¹å®Œæ•´ä¿®æ”¹ï¼‰

---

## ğŸ“ å®Œæ•´è¨“ç·´è…³æœ¬ä¿®æ”¹æŒ‡å—

### ä¿®æ”¹ `scripts/train_deeplob_v5.py`

#### 1ï¸âƒ£ åŠ å…¥æ–°çš„ imports

åœ¨æ–‡ä»¶é–‹é ­çš„ imports å€åŸŸåŠ å…¥:

```python
# æ–°å¢ï¼šæ”¹é€²ç‰ˆæ¨¡çµ„
from src.models.deeplob_improved import DeepLOBImproved
from src.models.focal_loss import FocalLoss
from src.evaluation.calibration import evaluate_calibration
```

#### 2ï¸âƒ£ ä¿®æ”¹æ¨¡å‹åˆå§‹åŒ–ï¼ˆç´„åœ¨ç¬¬ 700-800 è¡Œï¼‰

æ‰¾åˆ°åŸæœ¬çš„æ¨¡å‹å‰µå»ºéƒ¨åˆ†:

```python
# åŸä»£ç¢¼ï¼ˆå¤§ç´„åœ¨ main() å‡½æ•¸ä¸­ï¼‰
model = DeepLOB(
    num_classes=config['model']['num_classes'],
    ...
)
```

**æ›¿æ›ç‚º**:

```python
# æ–°ä»£ç¢¼ï¼šæ”¯æŒå¤šç¨®æ¨¡å‹
model_type = config['model'].get('type', 'deeplob')  # é»˜èªåŸç‰ˆ

if model_type == 'deeplob_improved':
    logger.info("ä½¿ç”¨æ”¹é€²ç‰ˆ DeepLOBï¼ˆLayerNorm + Attentionï¼‰")
    model = DeepLOBImproved(
        num_classes=config['model']['num_classes'],
        conv_filters=config['model'].get('conv1_filters', 32),
        lstm_hidden=config['model']['lstm_hidden_size'],
        fc_hidden=config['model']['fc_hidden_size'],
        dropout=config['model']['dropout'],
        use_layer_norm=config['model'].get('use_layer_norm', True),
        use_attention=config['model'].get('use_attention', True),
        input_shape=tuple(config['model']['input']['shape'])
    )
elif model_type == 'deeplob':
    logger.info("ä½¿ç”¨åŸç‰ˆ DeepLOB")
    model = DeepLOB(
        num_classes=config['model']['num_classes'],
        # ... åŸæœ‰åƒæ•¸
    )
else:
    raise ValueError(f"Unknown model type: {model_type}")
```

#### 3ï¸âƒ£ ä¿®æ”¹æå¤±å‡½æ•¸ï¼ˆç´„åœ¨ç¬¬ 600-650 è¡Œï¼‰

æ‰¾åˆ° `train_epoch` å‡½æ•¸ä¸­çš„æå¤±è¨ˆç®—éƒ¨åˆ†:

```python
# åŸä»£ç¢¼
loss_per_sample = nn.functional.cross_entropy(
    logits, labels,
    reduction='none',
    label_smoothing=label_smoothing,
    weight=class_weights
)
```

**æ›¿æ›ç‚º**:

```python
# æ–°ä»£ç¢¼ï¼šæ”¯æŒ Focal Loss
loss_type = config['loss'].get('type', 'ce')

if loss_type == 'focal':
    # ä½¿ç”¨ Focal Loss
    if not hasattr(train_epoch, 'focal_criterion'):
        # åªåˆå§‹åŒ–ä¸€æ¬¡
        gamma = config['loss'].get('gamma', 2.0)
        train_epoch.focal_criterion = FocalLoss(
            alpha=class_weights,
            gamma=gamma,
            label_smoothing=label_smoothing,
            reduction='none'
        ).to(device)

    loss_per_sample = train_epoch.focal_criterion(logits, labels)

elif loss_type == 'ce':
    # åŸæœ‰ CE Loss
    loss_per_sample = nn.functional.cross_entropy(
        logits, labels,
        reduction='none',
        label_smoothing=label_smoothing,
        weight=class_weights
    )
else:
    raise ValueError(f"Unknown loss type: {loss_type}")
```

#### 4ï¸âƒ£ åŠ å…¥ ECE è©•ä¼°ï¼ˆåœ¨è©•ä¼°å‡½æ•¸ä¸­ï¼‰

åœ¨ `evaluate()` å‡½æ•¸è¿”å›çµæœå‰åŠ å…¥:

```python
# åœ¨ evaluate() å‡½æ•¸æœ«å°¾ï¼Œè¿”å› results ä¹‹å‰åŠ å…¥:

if config.get('calibration', {}).get('enabled', False):
    # è©•ä¼°æ ¡æº–å“è³ª
    all_logits_tensor = torch.FloatTensor(all_logits)
    all_labels_tensor = torch.LongTensor(all_labels)

    from src.evaluation.calibration import compute_ece

    ece = compute_ece(all_logits_tensor, all_labels_tensor, n_bins=15)
    results['calibration'] = {'ece': ece}

    logger.info(f"  ECE: {ece:.4f}")
```

---

## ğŸ”§ é…ç½®æ–‡ä»¶ç¯„ä¾‹

### æ–¹æ¡ˆ 1: å¢åŠ å®¹é‡ + Focal Loss

**å‰µå»º**: `configs/train_v5_improved_v1.yaml`

```yaml
# åŸºæ–¼ train_v5_recovery.yamlï¼Œä¿®æ”¹ä»¥ä¸‹éƒ¨åˆ†:

model:
  arch: "DeepLOB"
  type: "deeplob"  # ä¿æŒåŸç‰ˆæ¶æ§‹
  lstm_hidden_size: 64  # âœ¨ 48 â†’ 64
  fc_hidden_size: 64    # âœ¨ 48 â†’ 64
  dropout: 0.6

loss:
  type: "focal"         # âœ¨ ce â†’ focal
  gamma: 2.0            # âœ¨ æ–°å¢
  class_weights: "auto"
  label_smoothing:
    global: 0.15

calibration:
  enabled: true         # âœ¨ å•Ÿç”¨ ECE è¨ˆç®—

train:
  early_stop:
    patience: 20        # âœ¨ 15 â†’ 20
```

---

### æ–¹æ¡ˆ 2: æ”¹é€²ç‰ˆ DeepLOB + Focal Loss

**å‰µå»º**: `configs/train_v5_improved_v2.yaml`

```yaml
model:
  type: "deeplob_improved"  # âœ¨ ä½¿ç”¨æ”¹é€²ç‰ˆ
  use_layer_norm: true      # âœ¨ æ–°å¢
  use_attention: true       # âœ¨ æ–°å¢
  lstm_hidden_size: 64
  fc_hidden_size: 64
  dropout: 0.6

loss:
  type: "focal"
  gamma: 2.0
  class_weights: "auto"
  label_smoothing:
    global: 0.15

calibration:
  enabled: true

train:
  epochs: 50
  early_stop:
    patience: 20
```

---

## ğŸ¯ åŸ·è¡Œè¨ˆåŠƒ

### Day 1ï¼ˆä»Šå¤©ï¼‰

#### âœ… ä»»å‹™ 1: é©—è­‰åŸºç¤é…ç½®ï¼ˆå·²å®Œæˆï¼‰
```bash
conda activate deeplob-pro
python scripts/verify_class_weights.py
```

#### â³ ä»»å‹™ 2: å¿«é€Ÿå®¹é‡æ¸¬è©¦ï¼ˆ10 åˆ†é˜ï¼‰
```bash
# æ¸¬è©¦å¢åŠ å®¹é‡çš„æ•ˆæœ
python scripts/train_deeplob_v5.py \
    --config configs/train_v5_capacity_test.yaml \
    --epochs 10
```

**æ±ºç­–é»**:
- å¦‚æœé©—è­‰æå¤±æ”¹å–„ â†’ ç¹¼çºŒå®Œæ•´è¨“ç·´
- å¦‚æœæ²’æ”¹å–„ â†’ å˜—è©¦æ”¹é€²ç‰ˆæ¨¡å‹

---

### Day 2ï¼ˆæ˜å¤©ï¼‰

#### ä»»å‹™ 3: å®Œæ•´è¨“ç·´ï¼ˆæœ€ä½³é…ç½®ï¼‰

åŸºæ–¼ Day 1 çµæœé¸æ“‡:

**é¸é … Aï¼ˆå¦‚æœå®¹é‡æ¸¬è©¦æœ‰æ•ˆï¼‰**:
```bash
python scripts/train_deeplob_v5.py \
    --config configs/train_v5_improved_v1.yaml \
    --epochs 50
```

**é¸é … Bï¼ˆå¦‚æœéœ€è¦æ¶æ§‹æ”¹é€²ï¼‰**:
```bash
# å…ˆå®Œæˆè¨“ç·´è…³æœ¬ä¿®æ”¹ï¼ˆè¦‹ä¸Šæ–¹ï¼‰ï¼Œç„¶å¾Œé‹è¡Œ:
python scripts/train_deeplob_v5.py \
    --config configs/train_v5_improved_v2.yaml \
    --epochs 50
```

---

### Day 3ï¼ˆå¾Œå¤©ï¼‰

#### ä»»å‹™ 4: A/B æ¸¬è©¦èˆ‡è¶…åƒæ•¸å„ªåŒ–

```bash
# æ¸¬è©¦ä¸åŒ gamma å€¼
for gamma in 1.5 2.0 2.5; do
    python scripts/train_deeplob_v5.py \
        --config configs/train_v5_improved_v1.yaml \
        --override loss.gamma=$gamma \
        --epochs 50
done

# æ¸¬è©¦ä¸åŒ dropout
for dropout in 0.5 0.6 0.7; do
    python scripts/train_deeplob_v5.py \
        --config configs/train_v5_improved_v1.yaml \
        --override model.dropout=$dropout \
        --epochs 50
done
```

---

## ğŸ“Š é æœŸæ”¹é€²æ•ˆæœ

| æ”¹é€²é …ç›® | ç•¶å‰å€¼ | å»ºè­°å€¼ | é æœŸæå‡ |
|---------|--------|--------|---------|
| LSTM Hidden | 48 | 64 | +2-3% |
| FC Hidden | 48 | 64 | +1-2% |
| æå¤±å‡½æ•¸ | CE | Focal (Î³=2.0) | +1-2% |
| æ¶æ§‹ | åŸç‰ˆ | LayerNorm + Attention | +3-5% |
| Early Stop Patience | 15 | 20 | é¿å…éæ—©åœæ­¢ |

**ç´¯è¨ˆé æœŸ**: 45-46% â†’ **52-58%**ï¼ˆä¿å®ˆä¼°è¨ˆï¼‰

---

## ğŸ› æ•…éšœæ’é™¤

### å•é¡Œ 1: æ”¹é€²ç‰ˆæ¨¡å‹æ‰¾ä¸åˆ°

**éŒ¯èª¤**:
```
ImportError: cannot import name 'DeepLOBImproved'
```

**è§£æ±º**:
```bash
# ç¢ºèªæ–‡ä»¶å­˜åœ¨
ls src/models/deeplob_improved.py

# æ¸¬è©¦å°å…¥
python -c "from src.models.deeplob_improved import DeepLOBImproved; print('OK')"
```

---

### å•é¡Œ 2: Focal Loss æå¤±å€¼ç•°å¸¸

**ç¾è±¡**: Loss è®Šæˆ NaN æˆ– Inf

**è§£æ±º**:
1. é™ä½ gammaï¼ˆå¾ 2.0 â†’ 1.5ï¼‰
2. é™ä½å­¸ç¿’ç‡ï¼ˆå¾ 8e-5 â†’ 5e-5ï¼‰
3. æª¢æŸ¥ logits è£å‰ªæ˜¯å¦ç”Ÿæ•ˆ

---

### å•é¡Œ 3: ECE è¨ˆç®—å¤±æ•—

**éŒ¯èª¤**:
```
RuntimeError: Expected all tensors to be on the same device
```

**è§£æ±º**:
```python
# åœ¨ calibration.py ä¸­ç¢ºä¿æ‰€æœ‰ tensor åœ¨ CPU
logits = logits.cpu()
labels = labels.cpu()
```

---

## ğŸ“š ç›¸é—œè³‡æº

### å¿…è®€æ–‡æª”
1. [TRAINING_DIAGNOSIS_AND_IMPROVEMENTS.md](TRAINING_DIAGNOSIS_AND_IMPROVEMENTS.md) - å®Œæ•´è¨ºæ–·å ±å‘Š
2. [CLAUDE.md](CLAUDE.md) - å°ˆæ¡ˆç¸½è¦½

### åƒè€ƒè«–æ–‡
1. **Focal Loss**: [Lin et al., 2017](https://arxiv.org/abs/1708.02002)
2. **Temperature Scaling**: [Guo et al., 2017](https://arxiv.org/abs/1706.04599)
3. **DeepLOB**: [Zhang et al., 2019](https://arxiv.org/abs/1808.03668)

---

## âœ… æª¢æŸ¥æ¸…å–®

### åœ¨é–‹å§‹è¨“ç·´å‰ï¼Œç¢ºèª:

- [ ] âœ… å·²é‹è¡Œ `verify_class_weights.py`
- [ ] âœ… å·²æ¸¬è©¦æ”¹é€²ç‰ˆæ¨¡å‹ï¼ˆå¦‚ä½¿ç”¨ï¼‰
- [ ] âœ… å·²æ¸¬è©¦ Focal Lossï¼ˆå¦‚ä½¿ç”¨ï¼‰
- [ ] âœ… é…ç½®æ–‡ä»¶ä¸­ `use_sample_weights=false`
- [ ] âœ… é…ç½®æ–‡ä»¶ä¸­ `balance_sampler.enabled=false`
- [ ] âœ… GPU å¯ç”¨ï¼ˆ`torch.cuda.is_available()`ï¼‰
- [ ] âœ… æ•¸æ“šæ–‡ä»¶å­˜åœ¨ä¸”å®Œæ•´

---

## ğŸ“ ä¸‹ä¸€æ­¥

å®Œæˆ Day 1-3 çš„è¨“ç·´å¾Œ:

1. **åˆ†æçµæœ**: æŸ¥çœ‹ TensorBoard æ—¥èªŒ
2. **æ¯”è¼ƒé…ç½®**: å“ªå€‹é…ç½®æ•ˆæœæœ€å¥½ï¼Ÿ
3. **éŒ¯èª¤åˆ†æ**: æŸ¥çœ‹æ··æ·†çŸ©é™£ï¼Œå“ªå€‹é¡åˆ¥ä»ç„¶å›°é›£ï¼Ÿ
4. **é€²ä¸€æ­¥å„ªåŒ–**:
   - è³‡æ–™å¢å¼·
   - é›†æˆå­¸ç¿’
   - èª¿æ•´ triple-barrier åƒæ•¸

---

**æœ€å¾Œæ›´æ–°**: 2025-10-19
**ç‰ˆæœ¬**: v1.0
**ç‹€æ…‹**: å¯ç«‹å³åŸ·è¡Œ âœ…
