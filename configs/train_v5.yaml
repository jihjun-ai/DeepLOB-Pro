# ===================================================================
# DeepLOB V5 训练配置 (Triple-Barrier 标签 + 样本权重)
# V5 为预设/核心，支持 stock_ids 且保留泛化能力
# ===================================================================

# ==================== 运行配置 ====================
run:
  seed: 42  # 固定随机性（含 cudnn deterministic）

# ==================== 标签配置 ====================
labels:
  num_classes: 3
  class_names: ["下跌", "持平", "上涨"]  # 中文名称
  class_names_en: ["down", "stationary", "up"]  # 英文名称
  class_ids: [0, 1, 2]  # 标签值
  format: "v5"  # V5 标签格式

  # 类别权重计算
  weight_calculation:
    epsilon: 1.0e-6  # 避免除零
    normalize: true  # 归一化到均值=1

# ==================== 可视化配置 ====================
visualization:
  confusion_matrix:
    normalize: true  # 归一化混淆矩阵
    dpi: 150  # 图像分辨率
    figsize: [8, 6]  # 图像大小
    cmap: "Blues"  # 颜色映射

# ==================== 数据配置 ====================
data:
  # 数据路径
  train: "data/processed_v6/npz/stock_embedding_train.npz"
  val: "data/processed_v6/npz/stock_embedding_val.npz"
  test: "data/processed_v6/npz/stock_embedding_test.npz"
  norm_meta: "data/processed_v6/npz/normalization_meta.json"

  # V5 标签配置（核心）
  v5_labels: true  # y: {0,1,2}（已转换）；保留 y_raw（如果有）

  # y_raw 验证（可选）
  y_raw_validation:
    enabled: true
    expected_values: [-1, 0, 1]  # y_raw 的期望值

  # 样本权重
  use_sample_weights: false  # 启用逐样本权重
  weights_normalize: "mean_to_1"  # 权重均值归一（或 "none"）

  # Stock IDs（可选，用于泛化测试）
  use_stock_ids: false  # 读取 stock_ids 给模型用

  # 数据验证
  fail_on_missing_keys: true  # 缺必备键即报错

# ==================== DataLoader 配置 ====================
dataloader:
  batch_size: 2048  # 增大 batch（256→2048，直接大 batch 訓練，BatchNorm 更穩定）
  num_workers: 12  # 增加 workers（4→12，餵飽 RTX 5090）
  pin_memory: true

  # 平衡采样器（暫時關閉，避免過度擬合少數類）
  balance_sampler:
    enabled: false    # 關閉！改用 class_weights 處理不平衡
    strategy: "inv_freq"  # 逆频率采样

# ==================== 模型配置 ====================
model:
  arch: "DeepLOB"  # 输入相容 (100,20)

  input:
    shape: [100, 20]  # 启动时强检

  num_classes: 3  # {0:下跌, 1:持平, 2:上涨}

  # DeepLOB 架构参数
  conv1_filters: 32
  conv2_filters: 32
  conv3_filters: 32
  lstm_hidden_size: 32  # 保持小模型（控制過擬合）
  fc_hidden_size: 32    # 保持小模型（控制過擬合）
  dropout: 0.7  # 進一步增加 dropout（0.6→0.7，對抗嚴重過擬合）

  # Stock Embeddings（当 data.use_stock_ids=true 生效）
  embeddings:
    enabled: false  # 预设关闭（泛化优先）
    num_stocks: 367  # 从 metadata 获取
    dim: 16  # 8~16
    dropout: 0.1
    weight_decay: 0.0001
    max_norm: null  # 梯度裁剪（可选）
    unk_strategy: "explicit_unk"  # 或 "hash"
    feature_dropout:
      p: 0.3  # 训练时以 UNK 置换 id
    conditioning: "film"  # "film"/"gate"/"concat"（推荐 film/gate）

# ==================== 损失函数配置 ====================
loss:
  type: "ce"  # CrossEntropy（train_v5.py 目前只支持 ce）

  # 类别权重（自動處理不平衡）
  class_weights: "none"  # "auto"（逆频率）或 "none"

  # 标签平滑（關閉，不平衡時有害）
  label_smoothing:
    global: 0.0  # 關閉平滑
    flat_bonus: 0.00  # 持平类额外平滑（0~0.05）

# ==================== 优化器配置 ====================
optim:
  name: "adamw"
  lr: 0.0002    # 大幅降低學習率（0.0008→0.0002，對抗過擬合）
  weight_decay: 0.001  # 增加權重衰減（0.0005→0.001，增強正則化）
  grad_clip: 1.0  # 保持梯度裁剪
  amp: false  # 關閉混合精度（LSTM + 大 batch 會導致梯度 NaN）
  use_bf16: false  # 關閉 BF16

  # AdamW 额外参数
  betas: [0.9, 0.999]
  eps: 1.0e-8
  amsgrad: false

# ==================== 学习率调度器 ====================
sched:
  name: "cosine"  # cosine warmup + decay
  warmup_ratio: 0.1  # 增加預熱（0.05→0.1，給模型更多穩定時間）
  eta_min: 1.0e-5  # 提高最小 LR（5e-6→1e-5，避免過度 fine-tune）

# ==================== 训练配置 ====================
train:
  epochs: 30  # 大 batch 需更多 epochs（20→30，補償步數減少）
  accumulate_steps: 1  # 無梯度累積（直接使用 batch_size=2048）

  # 早停
  early_stop:
    metric: "val.f1_macro_weighted"  # 以加权 macro-F1 为准
    patience: 8  # 大 batch 增加耐心（5→8，收斂較平滑需更多時間）
    mode: "max"

# ==================== 评估配置 ====================
eval:
  # 分组策略
  group_split:
    by_stock: true  # 严格 by-stock 切分

  # 评估指标
  metrics:
    unweighted: ["acc", "f1_macro", "per_class_pr_rc", "confusion"]
    weighted: ["f1_macro", "loss"]

  # 分组细分
  breakdowns: ["reasons", "t_hit_bucket", "ret_quantile", "stock"]

  # t_hit 分桶
  thit_buckets: [0, 5, 10, 20, 100]

  # |ret| 分位数
  ret_quantiles: [0.8, 0.9, 0.95]

# ==================== 校准配置 ====================
calibration:
  enabled: true
  type: "temperature"  # 温度缩放
  opt_metric: "weighted_nll"  # 优化加权 NLL
  lr: 0.01  # 温度优化学习率
  max_iter: 50  # 温度优化最大迭代次数

# ==================== 推理配置 ====================
inference:
  decision: "argmax"  # "argmax" 或 "cost_sensitive"

  cost_matrix:
    path: null  # null 为单位成本矩阵

  hold_threshold: 0.0  # >0 时低信心→flat

# ==================== 日志配置 ====================
logging:
  dir: "logs/deeplob_v5"
  save_best_by: "val.f1_macro_weighted"

  # 输出工件
  artifacts:
    - "model"
    - "norm_meta"
    - "label_mapping"
    - "calibration"
    - "cost_matrix"
    - "metrics_json"
    - "logs_csv"
    - "confmat_png"

  # WandB（可选）
  wandb:
    enabled: false
    project: "deeplob-v5"
    entity: null

# ==================== 安全检查 ====================
safety_checks:
  validate_label_set: true  # y ∈ {0,1,2}
  validate_weights: true  # 权重为有限正值
  validate_norm_meta: true  # 名称/顺序一致
  print_data_summary: true  # 启动时打印数据摘要

# ==================== 硬件配置 ====================
hardware:
  device: "cuda"
  num_workers: 12  # 與 dataloader 一致
  pin_memory: true
  prefetch_factor: 4  # 增加預取（2→4，減少 GPU 等待）
  persistent_workers: true
  enable_tf32: true  # 啟用 TF32（RTX 5090 加速 50%）

# ==================== 續訓配置 ====================
resume:
  enabled: false  # 是否從檢查點續訓
  checkpoint_path: "checkpoints/v5/deeplob_v5_best.pth"  # 檢查點路徑
  load_optimizer: true  # 是否載入優化器狀態

# ==================== 其他配置 ====================
misc:
  save_last: true
  output_dir: "checkpoints/v5"
