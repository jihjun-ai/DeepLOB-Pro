# ===================================================================
# DeepLOB V5 Recovery V6 - å°æŠ—éæ“¬åˆ + æ¸¬è©¦åŸå§‹ v5 æ•¸æ“š
# åŸºæ–¼å¯¦é©— #5-v2 å¤±æ•—ç¶“é©—ï¼šéæ“¬åˆåš´é‡ (Train-Val å·®è· 33%)
# ===================================================================

# ==================== åŸºç¤é…ç½® ====================
run:
  seed: 42

labels:
  num_classes: 3
  class_names: ["ä¸‹è·Œ", "æŒå¹³", "ä¸Šæ¼²"]
  class_names_en: ["down", "stationary", "up"]
  class_ids: [0, 1, 2]
  format: "v5"

  weight_calculation:
    epsilon: 1.0e-6
    normalize: true

visualization:
  confusion_matrix:
    normalize: true
    dpi: 150
    figsize: [8, 6]
    cmap: "Blues"

data:
  train: "data/processed_v5/npz/stock_embedding_train.npz"       # ğŸ”§ ä½¿ç”¨åŸå§‹ v5
  val: "data/processed_v5/npz/stock_embedding_val.npz"
  test: "data/processed_v5/npz/stock_embedding_test.npz"
  norm_meta: "data/processed_v5/npz/normalization_meta.json"

  v5_labels: true
  y_raw_validation:
    enabled: true
    expected_values: [-1, 0, 1]

  use_sample_weights: false  # ğŸ”§ é—œé–‰ç•°å¸¸æ¬Šé‡
  weights_normalize: "mean_to_1"
  use_stock_ids: false
  fail_on_missing_keys: true

# ==================== DataLoader é…ç½® ====================
dataloader:
  batch_size: 512
  num_workers: 4
  pin_memory: true

  balance_sampler:
    enabled: false
    strategy: "inv_freq"

# ==================== æ¨¡å‹é…ç½® ====================
model:
  arch: "DeepLOB"
  input:
    shape: [100, 20]
  num_classes: 3

  # ğŸ”§ é™ä½å®¹é‡å°æŠ—éæ“¬åˆ
  conv1_filters: 32
  conv2_filters: 32
  conv3_filters: 32
  lstm_hidden_size: 48  # ğŸ”§ é™ä½ (64â†’48)
  fc_hidden_size: 48    # ğŸ”§ é™ä½ (64â†’48)
  dropout: 0.6          # ğŸ”§ å¢å¼· (0.5â†’0.6)

  embeddings:
    enabled: false

# ==================== æå¤±å‡½æ•¸é…ç½® ====================
loss:
  type: "ce"

  # ğŸ”§ ä½¿ç”¨è‡ªå‹•æ¬Šé‡ï¼ˆé©æ‡‰ v5 åŸå§‹æ•¸æ“šåˆ†å¸ƒï¼‰
  class_weights: "auto"

  label_smoothing:
    global: 0.15      # ğŸ”§ å¢å¼· (0.1â†’0.15)
    flat_bonus: 0.0

# ==================== å„ªåŒ–å™¨é…ç½® ====================
optim:
  name: "adamw"
  lr: 0.00005           # ğŸ”§ é™ä½ (0.00008â†’0.00005)
  weight_decay: 0.001   # ğŸ”§ å¢å¼· (0.0005â†’0.001)
  grad_clip: 0.5
  amp: false
  use_bf16: false
  betas: [0.9, 0.999]
  eps: 1.0e-8
  amsgrad: false

# ==================== å­¸ç¿’ç‡èª¿åº¦å™¨ ====================
sched:
  name: "cosine"
  warmup_ratio: 0.15
  eta_min: 5.0e-6

# ==================== è¨“ç·´é…ç½® ====================
train:
  epochs: 50
  accumulate_steps: 1

  early_stop:
    metric: "val.f1_macro_unweighted"
    patience: 12      # ğŸ”§ ç¸®çŸ­ (15â†’12)
    mode: "max"

# ==================== è©•ä¼°é…ç½® ====================
eval:
  group_split:
    by_stock: true

  metrics:
    unweighted: ["acc", "f1_macro", "per_class_pr_rc", "confusion"]
    weighted: ["f1_macro", "loss"]

  breakdowns: ["reasons", "t_hit_bucket", "ret_quantile", "stock"]
  thit_buckets: [0, 5, 10, 20, 100]
  ret_quantiles: [0.8, 0.9, 0.95]

# ==================== æ ¡æº–é…ç½® ====================
calibration:
  enabled: true
  type: "temperature"
  opt_metric: "weighted_nll"
  lr: 0.01
  max_iter: 50

# ==================== æ¨ç†é…ç½® ====================
inference:
  decision: "argmax"
  cost_matrix:
    path: null
  hold_threshold: 0.0

# ==================== æ—¥èªŒé…ç½® ====================
logging:
  dir: "logs/deeplob_v5_recovery_v6"
  save_best_by: "val.f1_macro_unweighted"

  artifacts:
    - "model"
    - "norm_meta"
    - "label_mapping"
    - "calibration"
    - "cost_matrix"
    - "metrics_json"
    - "logs_csv"
    - "confmat_png"

  wandb:
    enabled: false

# ==================== å®‰å…¨æª¢æŸ¥ ====================
safety_checks:
  validate_label_set: true
  validate_weights: true
  validate_norm_meta: true
  print_data_summary: true

# ==================== ç¡¬ä»¶é…ç½® ====================
hardware:
  device: "cuda"
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: true

# ==================== çºŒè¨“é…ç½® ====================
resume:
  enabled: false
  checkpoint_path: "checkpoints/v5_recovery_v6/deeplob_v5_best.pth"
  load_optimizer: true

# ==================== å…¶ä»–é…ç½® ====================
misc:
  save_last: true
  output_dir: "checkpoints/v5_recovery_v6"

# ===================================================================
# å¯¦é©— #6 - V6 èª¿æ•´ç¸½çµ
# ===================================================================
# åŸºæ–¼å¯¦é©— #5-v2 (Val Acc 45.80%, éæ“¬åˆåš´é‡) çš„æ”¹é€²ï¼š
#
# 1. âœ… æ•¸æ“šé›†ï¼šbalanced â†’ v5 (æ¸¬è©¦åŸå§‹æ¨™ç±¤)
# 2. âœ… LSTM/FCï¼š64â†’48 (é™ä½å®¹é‡)
# 3. âœ… Dropoutï¼š0.5â†’0.6 (å¢å¼·æ­£å‰‡åŒ–)
# 4. âœ… LRï¼š0.00008â†’0.00005 (æ›´ä¿å®ˆ)
# 5. âœ… Weight decayï¼š0.0005â†’0.001 (æ›´å¼·L2)
# 6. âœ… Label smoothingï¼š0.1â†’0.15 (æ›´å¼·å¹³æ»‘)
# 7. âœ… Class weightsï¼šmanualâ†’auto (é©æ‡‰v5æ•¸æ“š)
# 8. âœ… Patienceï¼š15â†’12 (æ›´å¿«æ­¢æ)
#
# æ¸¬è©¦ç›®çš„ï¼š
#   - é©—è­‰ v5 åŸå§‹æ¨™ç±¤æ˜¯å¦æ¯” balanced æ›´å¥½
#   - å°æŠ—éæ“¬åˆ (ç›®æ¨™ Train-Val < 20%)
#   - æœŸæœ› Val Acc > 47% (å¦‚æœ v5 æ¨™ç±¤æ›´å¥½)
#
# ä½¿ç”¨æ–¹æ³•ï¼š
#   python scripts/train_deeplob_v5.py \
#       --config configs/train_v5_recovery_v6.yaml \
#       --data-dir ./data/processed_v5/npz \
#       --epochs 50
# ===================================================================
