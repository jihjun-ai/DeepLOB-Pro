# é è¨ˆç®—æ¬Šé‡è¨­è¨ˆæ–¹æ¡ˆ

**æ ¸å¿ƒç†å¿µ**: é å…ˆè¨ˆç®—å¤šç¨®æ¬Šé‡ç­–ç•¥ï¼Œè¨“ç·´æ™‚éˆæ´»é¸æ“‡

**æ—¥æœŸ**: 2025-10-23
**ç‰ˆæœ¬**: v1.0

---

## ğŸ¯ è¨­è¨ˆç›®æ¨™

### å•é¡Œ
```
ç•¶å‰å›°å¢ƒï¼š
- é å…ˆä¿å­˜æ¬Šé‡ â†’ éˆæ´»æ€§å·®
- è¨“ç·´æ™‚è¨ˆç®—æ¬Šé‡ â†’ æ¯æ¬¡éƒ½è¦ç®—

ç†æƒ³æ–¹æ¡ˆï¼š
- é å…ˆè¨ˆç®—ã€Œå¤šç¨®ç­–ç•¥ã€çš„æ¬Šé‡
- ä¿å­˜åœ¨ metadata ä¸­ï¼ˆä¸å¢åŠ å¤ªå¤šç©ºé–“ï¼‰
- è¨“ç·´æ™‚é¸æ“‡ä½¿ç”¨å“ªä¸€ç¨®
```

### è§£æ±ºæ–¹æ¡ˆ
```python
# é è™•ç†æ™‚ï¼šè¨ˆç®—å¤šç¨®æ¬Šé‡ç­–ç•¥çš„ã€Œé¡åˆ¥æ¬Šé‡ã€ï¼ˆä¸æ˜¯æ¨£æœ¬æ¬Šé‡ï¼‰
metadata['weight_strategies'] = {
    'balanced': {-1: 1.11, 0: 0.83, 1: 1.11},
    'sqrt_balanced': {-1: 1.05, 0: 0.91, 1: 1.05},
    'effective_num_0.99': {-1: 1.20, 0: 0.75, 1: 1.18},
    'effective_num_0.999': {-1: 1.35, 0: 0.68, 1: 1.32},
    'focal_recommended': {-1: 1.0, 0: 1.0, 1: 1.0},  # Focal Loss ä¸éœ€æ¬Šé‡
    'uniform': {-1: 1.0, 0: 1.0, 1: 1.0}
}

# è¨“ç·´æ™‚ï¼šé¸æ“‡ä½¿ç”¨
python train.py --weight-strategy balanced
python train.py --weight-strategy effective_num_0.99
python train.py --weight-strategy uniform  # ä¸ä½¿ç”¨æ¬Šé‡
```

---

## ğŸ“Š å»ºè­°é å…ˆè¨ˆç®—çš„æ¬Šé‡ç­–ç•¥

### é¡åˆ¥ 1: åŸºæ–¼æ¨£æœ¬æ•¸é‡çš„æ¬Šé‡ âœ… æ¨è–¦é å…ˆè¨ˆç®—

#### 1.1 Balanced (æ¨™æº–å¹³è¡¡)
```python
def compute_balanced_weights(labels):
    """
    æ¨™æº–å¹³è¡¡æ¬Šé‡
    å…¬å¼: weight = total / (n_classes * class_count)
    """
    unique, counts = np.unique(labels[~np.isnan(labels)], return_counts=True)
    total = len(labels[~np.isnan(labels)])
    n_classes = len(unique)

    return {
        int(label): total / (n_classes * count)
        for label, count in zip(unique, counts)
    }

# ç¯„ä¾‹è¼¸å‡ºï¼ˆNeutral 14%ï¼‰
# {-1: 1.11, 0: 2.38, 1: 1.11}
```

**ç‰¹é»**:
- âœ… æœ€å¸¸ç”¨çš„åŸºæº–
- âœ… è¨ˆç®—ç°¡å–®
- âš ï¸ ä¸è€ƒæ…®é¡åˆ¥é›£åº¦

**å»ºè­°**: **å¿…é ˆé å…ˆè¨ˆç®—** â­â­â­â­â­

---

#### 1.2 Square Root Balanced (å¹³æ–¹æ ¹å¹³è¡¡)
```python
def compute_sqrt_balanced_weights(labels):
    """
    å¹³æ–¹æ ¹å¹³è¡¡æ¬Šé‡ï¼ˆæ›´æº«å’Œï¼‰
    å…¬å¼: weight = sqrt(total / (n_classes * class_count))
    """
    balanced = compute_balanced_weights(labels)
    return {
        label: np.sqrt(weight)
        for label, weight in balanced.items()
    }

# ç¯„ä¾‹è¼¸å‡ºï¼ˆNeutral 14%ï¼‰
# {-1: 1.05, 0: 1.54, 1: 1.05}  # æ¯” balanced æº«å’Œ
```

**ç‰¹é»**:
- âœ… æ¯” balanced æ›´æº«å’Œï¼ˆé¿å…æ¬Šé‡éé«˜ï¼‰
- âœ… æ¸›å°‘è¨“ç·´ä¸ç©©å®šé¢¨éšª
- âœ… æ–‡ç»æ¨è–¦ç”¨æ–¼æ¥µç«¯ä¸å¹³è¡¡

**å»ºè­°**: **å¼·çƒˆæ¨è–¦é å…ˆè¨ˆç®—** â­â­â­â­â­

---

#### 1.3 Log Balanced (å°æ•¸å¹³è¡¡)
```python
def compute_log_balanced_weights(labels):
    """
    å°æ•¸å¹³è¡¡æ¬Šé‡ï¼ˆæœ€æº«å’Œï¼‰
    å…¬å¼: weight = log(total / class_count)
    """
    unique, counts = np.unique(labels[~np.isnan(labels)], return_counts=True)
    total = len(labels[~np.isnan(labels)])

    return {
        int(label): np.log(total / count + 1)  # +1 é¿å… log(0)
        for label, count in zip(unique, counts)
    }

# ç¯„ä¾‹è¼¸å‡ºï¼ˆNeutral 14%ï¼‰
# {-1: 1.25, 0: 2.08, 1: 1.30}  # æœ€æº«å’Œ
```

**ç‰¹é»**:
- âœ… æœ€æº«å’Œçš„å¹³è¡¡ç­–ç•¥
- âœ… é©åˆæ¥µç«¯ä¸å¹³è¡¡ï¼ˆå¦‚ 1:99ï¼‰
- âš ï¸ æ•ˆæœå¯èƒ½ä¸å¦‚ sqrt

**å»ºè­°**: **å¯é¸é å…ˆè¨ˆç®—** â­â­â­

---

#### 1.4 Effective Number of Samples (æœ‰æ•ˆæ¨£æœ¬æ•¸)
```python
def compute_effective_num_weights(labels, beta=0.99):
    """
    æœ‰æ•ˆæ¨£æœ¬æ•¸æ¬Šé‡ï¼ˆè€ƒæ…®æ¨£æœ¬é‡è¤‡åº¦ï¼‰
    å…¬å¼: weight = (1 - beta) / (1 - beta^n)

    Args:
        beta: é‡è¤‡åº¦åƒæ•¸ï¼ˆ0.9, 0.99, 0.999, 0.9999ï¼‰
              - è¶Šæ¥è¿‘ 1 â†’ èªç‚ºæ¨£æœ¬è¶Šç¨ç‰¹
              - è¶Šæ¥è¿‘ 0 â†’ èªç‚ºæ¨£æœ¬è¶Šé‡è¤‡
    """
    unique, counts = np.unique(labels[~np.isnan(labels)], return_counts=True)

    weights = {}
    for label, count in zip(unique, counts):
        effective_num = (1 - beta) / (1 - beta**count)
        weights[int(label)] = 1.0 / effective_num

    # æ­£è¦åŒ–
    total_weight = sum(weights.values())
    return {k: v / total_weight * len(weights) for k, v in weights.items()}

# ç¯„ä¾‹è¼¸å‡ºï¼ˆNeutral 14%, beta=0.99ï¼‰
# {-1: 1.05, 0: 1.75, 1: 1.08}

# ç¯„ä¾‹è¼¸å‡ºï¼ˆNeutral 14%, beta=0.999ï¼‰
# {-1: 1.02, 0: 1.92, 1: 1.04}
```

**ç‰¹é»**:
- âœ… è€ƒæ…®æ¨£æœ¬é‡è¤‡åº¦ï¼ˆé‡è¦ï¼ï¼‰
- âœ… CVPR 2019 è«–æ–‡æ¨è–¦
- âœ… é©åˆé•·å°¾åˆ†å¸ƒ
- âš ï¸ éœ€è¦é¸æ“‡ beta åƒæ•¸

**å»ºè­°**: **å¼·çƒˆæ¨è–¦é å…ˆè¨ˆç®—å¤šå€‹ beta å€¼** â­â­â­â­â­

æ¨è–¦é è¨ˆç®—ï¼š
- `beta=0.9`ï¼ˆèªç‚ºæ¨£æœ¬è¼ƒé‡è¤‡ï¼‰
- `beta=0.99`ï¼ˆæ¨™æº–è¨­å®šï¼‰
- `beta=0.999`ï¼ˆèªç‚ºæ¨£æœ¬è¼ƒç¨ç‰¹ï¼‰
- `beta=0.9999`ï¼ˆæ¥µç«¯ç¨ç‰¹ï¼‰

---

### é¡åˆ¥ 2: åŸºæ–¼æ¥­å‹™é‚è¼¯çš„æ¬Šé‡ âš ï¸ å»ºè­°é å…ˆè¨ˆç®—

#### 2.1 Class-Balanced (CB) Focal Loss Weights
```python
def compute_cb_focal_weights(labels, beta=0.999, gamma=2.0):
    """
    Class-Balanced Focal Loss æ¬Šé‡
    çµåˆ Effective Number + Focal Loss æ¦‚å¿µ

    Reference: CVPR 2019 - "Class-Balanced Loss Based on Effective Number of Samples"
    """
    effective_weights = compute_effective_num_weights(labels, beta)

    # Focal Loss èª¿æ•´ï¼ˆé ä¼°å›°é›£åº¦ï¼‰
    # å‡è¨­ Neutral æœ€é›£ï¼ˆå› ç‚ºæ¨£æœ¬å°‘ï¼‰
    difficulty_factors = {
        -1: 1.0,  # Down: å®¹æ˜“
         0: 1.5,  # Neutral: å›°é›£ï¼ˆæ‰‹å‹•è¨­å®šï¼‰
         1: 1.0   # Up: å®¹æ˜“
    }

    return {
        label: effective_weights[label] * difficulty_factors.get(label, 1.0)
        for label in effective_weights
    }
```

**ç‰¹é»**:
- âœ… çµåˆæ¨£æœ¬æ•¸é‡ + é¡åˆ¥é›£åº¦
- âœ… SOTA æ–¹æ³•
- âš ï¸ éœ€è¦æ‰‹å‹•è¨­å®šé›£åº¦ä¿‚æ•¸

**å»ºè­°**: **å¯é¸é å…ˆè¨ˆç®—** â­â­â­â­

---

#### 2.2 Cost-Sensitive (æ¥­å‹™æˆæœ¬)
```python
def compute_cost_sensitive_weights(labels, cost_matrix):
    """
    åŸºæ–¼æ¥­å‹™æˆæœ¬çš„æ¬Šé‡

    Args:
        cost_matrix: éŒ¯èª¤æˆæœ¬çŸ©é™£
        ä¾‹å¦‚: {
            (-1, -1): 0,      # Down é æ¸¬å° Downï¼Œæˆæœ¬ 0
            (-1, 0): 50000,   # Down é æ¸¬éŒ¯æˆ Neutralï¼Œæå¤± 5 è¬
            (-1, 1): 100000,  # Down é æ¸¬éŒ¯æˆ Upï¼Œæå¤± 10 è¬
            ...
        }
    """
    # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„å¹³å‡éŒ¯èª¤æˆæœ¬
    unique = [-1, 0, 1]
    avg_costs = {}

    for true_label in unique:
        costs = [cost_matrix[(true_label, pred)] for pred in unique if pred != true_label]
        avg_costs[true_label] = np.mean(costs)

    # æ­£è¦åŒ–ç‚ºæ¬Šé‡
    total_cost = sum(avg_costs.values())
    return {k: v / total_cost * len(unique) for k, v in avg_costs.items()}

# ç¯„ä¾‹ï¼šäº¤æ˜“æˆæœ¬
cost_matrix = {
    # (true, pred): cost
    (-1, -1): 0, (-1, 0): 50000, (-1, 1): 100000,
    (0, -1): 10000, (0, 0): 0, (0, 1): 10000,
    (1, -1): 100000, (1, 0): 50000, (1, 1): 0
}

# è¼¸å‡ºï¼š{-1: 2.0, 0: 0.5, 1: 2.0}
```

**ç‰¹é»**:
- âœ… ç›´æ¥å°æ‡‰æ¥­å‹™ç›®æ¨™
- âœ… å¯è§£é‡‹æ€§å¼·
- âš ï¸ éœ€è¦å®šç¾©æˆæœ¬çŸ©é™£

**å»ºè­°**: **å¼·çƒˆæ¨è–¦é å…ˆè¨ˆç®—ï¼ˆå¦‚æœæœ‰æ¥­å‹™æˆæœ¬æ•¸æ“šï¼‰** â­â­â­â­â­

---

### é¡åˆ¥ 3: ä¸éœ€è¦é å…ˆè¨ˆç®—çš„æ¬Šé‡ âŒ

#### 3.1 Focal Loss
```python
# Focal Loss ä¸ä½¿ç”¨é¡åˆ¥æ¬Šé‡ï¼Œè€Œæ˜¯å‹•æ…‹èª¿æ•´æ¨£æœ¬æ¬Šé‡
# å…¬å¼: FL = -(1 - p_t)^gamma * log(p_t)
# å…¶ä¸­ p_t æ˜¯é æ¸¬æ¦‚ç‡ï¼ˆè¨“ç·´æ™‚æ‰çŸ¥é“ï¼‰

# é è™•ç†æ™‚åªéœ€è¨˜éŒ„ï¼š
metadata['weight_strategies']['focal_loss'] = {
    'type': 'focal',
    'gamma': 2.0,  # æ¨è–¦å€¼
    'alpha': None,  # å¯é¸çš„é¡åˆ¥æ¬Šé‡
    'class_weights': {-1: 1.0, 0: 1.0, 1: 1.0}  # å¦‚æœä¸ç”¨é¡å¤–æ¬Šé‡
}
```

**ç‰¹é»**:
- âœ… è‡ªå‹•èª¿æ•´ï¼ˆåŸºæ–¼é æ¸¬æ¦‚ç‡ï¼‰
- âœ… ä¸éœ€è¦é¡åˆ¥æ¬Šé‡
- âš ï¸ éœ€è¦åœ¨è¨“ç·´æ™‚å¯¦ä½œ

**å»ºè­°**: **ä¸é å…ˆè¨ˆç®—ï¼Œåªè¨˜éŒ„åƒæ•¸** â­â­â­â­

---

#### 3.2 Dynamic Weights (å‹•æ…‹æ¬Šé‡)
```python
# å‹•æ…‹æ¬Šé‡æ ¹æ“šè¨“ç·´éšæ®µèª¿æ•´ï¼ˆè¨“ç·´æ™‚æ‰èƒ½è¨ˆç®—ï¼‰
# ä¾‹å¦‚ï¼š
# - Epoch 1-10: å¼·è¿«å­¸ç¿’å°‘æ•¸é¡åˆ¥
# - Epoch 11-50: æ ¹æ“šé©—è­‰æ€§èƒ½èª¿æ•´
# - Epoch 51+: å¾®èª¿

# é è™•ç†æ™‚åªéœ€è¨˜éŒ„å»ºè­°çš„èª¿æ•´ç­–ç•¥ï¼š
metadata['weight_strategies']['dynamic'] = {
    'type': 'dynamic',
    'schedule': {
        'early': {-1: 2.0, 0: 0.5, 1: 2.0},
        'mid': {-1: 1.2, 0: 1.0, 1: 1.2},
        'late': {-1: 1.0, 0: 1.0, 1: 1.0}
    }
}
```

**å»ºè­°**: **ä¸é å…ˆè¨ˆç®—ï¼Œåªè¨˜éŒ„ç­–ç•¥** â­â­

---

## ğŸ¨ å®Œæ•´å¯¦ä½œè¨­è¨ˆ

### Step 1: ä¿®æ”¹ `preprocess_single_day.py`

```python
def compute_all_weight_strategies(labels: np.ndarray) -> Dict[str, Dict]:
    """
    è¨ˆç®—æ‰€æœ‰æ¬Šé‡ç­–ç•¥

    Args:
        labels: æ¨™ç±¤é™£åˆ— (-1, 0, 1, NaN)

    Returns:
        æ‰€æœ‰æ¬Šé‡ç­–ç•¥çš„å­—å…¸
    """
    strategies = {}

    # 1. Balanced ç³»åˆ—
    strategies['balanced'] = compute_balanced_weights(labels)
    strategies['sqrt_balanced'] = compute_sqrt_balanced_weights(labels)
    strategies['log_balanced'] = compute_log_balanced_weights(labels)

    # 2. Effective Number ç³»åˆ—ï¼ˆå¤šå€‹ betaï¼‰
    for beta in [0.9, 0.99, 0.999, 0.9999]:
        key = f'effective_num_{str(beta).replace(".", "")}'
        strategies[key] = compute_effective_num_weights(labels, beta)

    # 3. CB Focal ç³»åˆ—
    strategies['cb_focal_099'] = compute_cb_focal_weights(labels, beta=0.99)
    strategies['cb_focal_0999'] = compute_cb_focal_weights(labels, beta=0.999)

    # 4. æ¥­å‹™æˆæœ¬ï¼ˆå¦‚æœæœ‰å®šç¾©ï¼‰
    # strategies['cost_sensitive'] = compute_cost_sensitive_weights(labels, cost_matrix)

    # 5. ä¸ä½¿ç”¨æ¬Šé‡
    strategies['uniform'] = {-1: 1.0, 0: 1.0, 1: 1.0}

    # 6. Focal Lossï¼ˆè¨˜éŒ„åƒæ•¸ï¼‰
    strategies['focal_loss'] = {
        'type': 'focal',
        'gamma': 2.0,
        'class_weights': {-1: 1.0, 0: 1.0, 1: 1.0}
    }

    return strategies


# åœ¨ save_preprocessed_npz() ä¸­ä¿å­˜
def save_preprocessed_npz(..., label_preview=None):
    # ... ç¾æœ‰ä»£ç¢¼ ...

    # ğŸ†• å¦‚æœæœ‰ label_previewï¼Œè¨ˆç®—æ‰€æœ‰æ¬Šé‡ç­–ç•¥
    if label_preview is not None and 'labels_array' in label_preview:
        labels = label_preview['labels_array']
        weight_strategies = compute_all_weight_strategies(labels)

        # ä¿å­˜åˆ° metadata
        metadata['weight_strategies'] = {
            name: {
                'class_weights': weights,
                'description': get_strategy_description(name)
            }
            for name, weights in weight_strategies.items()
        }
```

---

### Step 2: Metadata çµæ§‹

```json
{
  "symbol": "2330",
  "date": "20250901",
  "label_preview": {
    "down_count": 2273,
    "neutral_count": 11395,
    "up_count": 2288,
    "down_pct": 0.1425,
    "neutral_pct": 0.7142,
    "up_pct": 0.1434
  },
  "weight_strategies": {
    "balanced": {
      "class_weights": {"-1": 1.11, "0": 0.83, "1": 1.11},
      "description": "Standard balanced weights"
    },
    "sqrt_balanced": {
      "class_weights": {"-1": 1.05, "0": 0.91, "1": 1.05},
      "description": "Square root balanced (gentler)"
    },
    "effective_num_099": {
      "class_weights": {"-1": 1.05, "0": 1.75, "1": 1.08},
      "description": "Effective number (beta=0.99)"
    },
    "effective_num_0999": {
      "class_weights": {"-1": 1.02, "0": 1.92, "1": 1.04},
      "description": "Effective number (beta=0.999)"
    },
    "cb_focal_0999": {
      "class_weights": {"-1": 1.02, "0": 2.88, "1": 1.04},
      "description": "Class-Balanced Focal (beta=0.999)"
    },
    "uniform": {
      "class_weights": {"-1": 1.0, "0": 1.0, "1": 1.0},
      "description": "No weighting"
    },
    "focal_loss": {
      "type": "focal",
      "gamma": 2.0,
      "class_weights": {"-1": 1.0, "0": 1.0, "1": 1.0},
      "description": "Use Focal Loss (gamma=2.0)"
    }
  }
}
```

---

### Step 3: è¨“ç·´æ™‚ä½¿ç”¨

```python
# train_deeplob_generic.py

def load_class_weights(metadata, strategy='balanced'):
    """
    å¾ metadata è¼‰å…¥é¡åˆ¥æ¬Šé‡

    Args:
        metadata: NPZ metadata
        strategy: æ¬Šé‡ç­–ç•¥åç¨±

    Returns:
        class_weights: {-1: w1, 0: w2, 1: w3}
    """
    if 'weight_strategies' not in metadata:
        # å¦‚æœæ²’æœ‰é å…ˆè¨ˆç®—ï¼Œå‹•æ…‹è¨ˆç®—
        logging.warning("No pre-computed weights, using balanced")
        return compute_class_weight('balanced', ...)

    strategies = metadata['weight_strategies']

    if strategy not in strategies:
        logging.error(f"Strategy '{strategy}' not found. Available: {list(strategies.keys())}")
        return {-1: 1.0, 0: 1.0, 1: 1.0}

    strategy_config = strategies[strategy]

    # å¦‚æœæ˜¯ Focal Lossï¼Œç‰¹æ®Šè™•ç†
    if strategy_config.get('type') == 'focal':
        logging.info("Using Focal Loss (no class weights)")
        return None  # è¨“ç·´æ™‚ä½¿ç”¨ Focal Loss

    return strategy_config['class_weights']


# ä½¿ç”¨ç¯„ä¾‹
config = load_yaml('configs/train_v5.yaml')

# å¾é…ç½®è®€å–æ¬Šé‡ç­–ç•¥
weight_strategy = config.get('weight_strategy', 'balanced')

# è¼‰å…¥æ¬Šé‡
class_weights = load_class_weights(metadata, strategy=weight_strategy)

if class_weights is not None:
    # ä½¿ç”¨é¡åˆ¥æ¬Šé‡
    criterion = nn.CrossEntropyLoss(
        weight=torch.FloatTensor([class_weights[-1], class_weights[0], class_weights[1]])
    )
else:
    # ä½¿ç”¨ Focal Loss
    criterion = FocalLoss(gamma=2.0)
```

---

### Step 4: é…ç½®æ–‡ä»¶

```yaml
# configs/train_v5.yaml

# æ¬Šé‡ç­–ç•¥é¸æ“‡
weight_strategy: "effective_num_0999"  # å¯é¸å€¼è¦‹ä¸‹æ–¹

# å¯ç”¨çš„æ¬Šé‡ç­–ç•¥ï¼š
# - balanced: æ¨™æº–å¹³è¡¡
# - sqrt_balanced: å¹³æ–¹æ ¹å¹³è¡¡ï¼ˆæº«å’Œï¼‰
# - log_balanced: å°æ•¸å¹³è¡¡ï¼ˆæœ€æº«å’Œï¼‰
# - effective_num_09: Effective Number (beta=0.9)
# - effective_num_099: Effective Number (beta=0.99)
# - effective_num_0999: Effective Number (beta=0.999) â­ æ¨è–¦
# - effective_num_09999: Effective Number (beta=0.9999)
# - cb_focal_099: Class-Balanced Focal (beta=0.99)
# - cb_focal_0999: Class-Balanced Focal (beta=0.999)
# - uniform: ä¸ä½¿ç”¨æ¬Šé‡
# - focal_loss: ä½¿ç”¨ Focal Loss
# - custom: è‡ªå®šç¾©ï¼ˆåœ¨ä»£ç¢¼ä¸­è¨­å®šï¼‰
```

---

## ğŸ“Š æ–‡ä»¶å¤§å°å½±éŸ¿

### è¨ˆç®—

```python
# æ¯å€‹æ¬Šé‡ç­–ç•¥éœ€è¦å„²å­˜ 3 å€‹æ•¸å­—ï¼ˆ3 å€‹é¡åˆ¥ï¼‰
# JSON æ ¼å¼ç´„ 100 bytes/ç­–ç•¥

strategies = [
    'balanced',
    'sqrt_balanced',
    'log_balanced',
    'effective_num_09',
    'effective_num_099',
    'effective_num_0999',
    'effective_num_09999',
    'cb_focal_099',
    'cb_focal_0999',
    'uniform',
    'focal_loss'
]

# 11 å€‹ç­–ç•¥ * 100 bytes = 1.1 KB/è‚¡ç¥¨

# å–®ä¸€äº¤æ˜“æ—¥ï¼ˆ195 æª”ï¼‰
195 * 1.1 KB = 214 KB

# å…¨å¹´ï¼ˆ250 äº¤æ˜“æ—¥ï¼‰
214 KB * 250 = 53.5 MB

# å°æ¯”ï¼š
# - ç„¡æ¬Šé‡ç­–ç•¥: 12.5 GB
# - æœ‰æ¬Šé‡ç­–ç•¥: 12.5 GB + 53.5 MB â‰ˆ 12.55 GB
# - å¢åŠ : 0.4%ï¼ˆå¹¾ä¹å¯å¿½ç•¥ï¼‰
```

**çµè«–**: å¢åŠ  11 å€‹æ¬Šé‡ç­–ç•¥ï¼Œåªå¢åŠ  0.4% æ–‡ä»¶å¤§å° âœ…

---

## ğŸ¯ æ¨è–¦é…ç½®

### æœ€å°é…ç½®ï¼ˆå¿…é ˆï¼‰

```python
weight_strategies = {
    'balanced': {...},           # åŸºæº–
    'effective_num_0999': {...}, # æ¨è–¦
    'uniform': {...}             # ä¸ä½¿ç”¨
}
```

**æ–‡ä»¶å¢åŠ **: ~300 bytes/è‚¡ç¥¨ï¼Œå¹¾ä¹å¯å¿½ç•¥

---

### æ¨™æº–é…ç½®ï¼ˆæ¨è–¦ï¼‰â­

```python
weight_strategies = {
    'balanced': {...},
    'sqrt_balanced': {...},
    'effective_num_099': {...},
    'effective_num_0999': {...},
    'cb_focal_0999': {...},
    'uniform': {...},
    'focal_loss': {...}
}
```

**æ–‡ä»¶å¢åŠ **: ~700 bytes/è‚¡ç¥¨ï¼Œå¯å¿½ç•¥

---

### å®Œæ•´é…ç½®ï¼ˆç ”ç©¶ç”¨ï¼‰

```python
weight_strategies = {
    'balanced': {...},
    'sqrt_balanced': {...},
    'log_balanced': {...},
    'effective_num_09': {...},
    'effective_num_099': {...},
    'effective_num_0999': {...},
    'effective_num_09999': {...},
    'cb_focal_099': {...},
    'cb_focal_0999': {...},
    'uniform': {...},
    'focal_loss': {...}
}
```

**æ–‡ä»¶å¢åŠ **: ~1.1 KB/è‚¡ç¥¨ï¼Œå…¨å¹´ +53.5 MBï¼ˆ0.4%ï¼‰

---

## âœ… ç¸½çµ

### æ¨è–¦é å…ˆè¨ˆç®—çš„æ¬Šé‡ï¼š

| æ¬Šé‡ç­–ç•¥ | å„ªå…ˆç´š | ç†ç”± |
|---------|-------|------|
| `balanced` | â­â­â­â­â­ | å¿…é ˆï¼ˆåŸºæº–ï¼‰ |
| `sqrt_balanced` | â­â­â­â­ | æº«å’Œç‰ˆæœ¬ï¼Œé¿å…éé«˜ |
| `effective_num_0999` | â­â­â­â­â­ | SOTAï¼Œè€ƒæ…®é‡è¤‡åº¦ |
| `effective_num_099` | â­â­â­â­ | å¦ä¸€å€‹ beta é¸é … |
| `cb_focal_0999` | â­â­â­ | çµåˆé›£åº¦çš„é€²éšç‰ˆ |
| `uniform` | â­â­â­â­â­ | å¿…é ˆï¼ˆä¸ä½¿ç”¨æ¬Šé‡ï¼‰ |

### ä¸é å…ˆè¨ˆç®—çš„æ¬Šé‡ï¼š

| æ¬Šé‡ç­–ç•¥ | åŸå›  |
|---------|------|
| `focal_loss` | å‹•æ…‹åŸºæ–¼é æ¸¬æ¦‚ç‡ |
| `dynamic_weights` | æ ¹æ“šè¨“ç·´éšæ®µèª¿æ•´ |
| `custom_manual` | æ‰‹å‹•å¾®èª¿ï¼ˆè¨“ç·´æ™‚æ±ºå®šï¼‰ |

### æª”æ¡ˆå¤§å°å½±éŸ¿ï¼š

```
æ¨™æº–é…ç½®ï¼ˆ7 å€‹ç­–ç•¥ï¼‰ï¼š~700 bytes/è‚¡ç¥¨
å…¨å¹´æ•¸æ“šå¢åŠ ï¼š~43 MBï¼ˆ0.34%ï¼‰
çµè«–ï¼šå¹¾ä¹å¯å¿½ç•¥ âœ…
```

---

**æ—¥æœŸ**: 2025-10-23
**ç‰ˆæœ¬**: v1.0
**ä¸‹ä¸€æ­¥**: å¯¦ä½œåˆ° `preprocess_single_day.py`
