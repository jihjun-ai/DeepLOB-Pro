# DeepLOB 調參歷史

### 每次保留數據及成果,簡要說明(其他廢話不用),這是改下次調參參考用

#### 環境: conda activate deeplob-pro

---

## 實驗 #3 - 2025-10-18

**問題診斷**:
- Epoch 1-12: Train Acc 28.4%→53.0% (持續上升)
- Val Acc: 31.3%→34.1% (停滯)
- **Val Loss 爆炸**: 0.885→1.425 (嚴重過擬合)
- Grad Norm 爆炸: 1.19→7.69

**根本原因**:
1. LR 1e-4 + batch 256 → 梯度估計不穩定
2. Dropout 0.3 太低 → 記憶訓練集
3. LSTM/FC 48 units 仍過大
4. Grad clip 1.0 無法控制 norm 爆炸

**調整策略**:
```yaml
# 架構縮小
lstm_hidden_size: 48 → 32
fc_hidden_size: 48 → 32
dropout: 0.3 → 0.5

# 穩定訓練
batch_size: 256 → 512 (穩定梯度)
lr: 1e-4 → 5e-5 (減半)
grad_clip: 1.0 → 0.5 (強力裁剪)
weight_decay: 1e-4 → 5e-4 (5x 正則化)

# 學習率調度
warmup_ratio: 0.1 → 0.15 (延長穩定期)
eta_min: 1e-5 → 5e-6 (降低最小LR)

# 訓練時長
epochs: 30 → 40 (小LR需更多時間)
patience: 10 → 8 (快速止損)
```

**預期效果**:
- Grad norm 控制在 2.0 以下
- Val Loss 不再上升
- Val F1 > 35% (目標)
- Train-Val Gap 縮小至 < 10%


