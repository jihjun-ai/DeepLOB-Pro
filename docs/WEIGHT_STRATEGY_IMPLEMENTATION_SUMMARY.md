# Weight Strategy Implementation Summary

**æ—¥æœŸ**: 2025-10-23
**ç‰ˆæœ¬**: v2.0
**ç‹€æ…‹**: âœ… å¯¦ä½œå®Œæˆä¸¦æ¸¬è©¦é€šé

---

## ğŸ“‹ å¯¦ä½œæ¦‚è¦

### ç›®æ¨™
åœ¨é è™•ç†éšæ®µé å…ˆè¨ˆç®—å¤šç¨®æ¬Šé‡ç­–ç•¥ï¼Œä¿å­˜åˆ° NPZ metadata ä¸­ï¼Œä¾›è¨“ç·´æ™‚éˆæ´»é¸æ“‡ä½¿ç”¨ã€‚

### é—œéµæ”¹é€²
- âœ… **é è¨ˆç®—æ¬Šé‡**: ä¸€æ¬¡é è™•ç†ï¼Œç”Ÿæˆ 11 ç¨®æ¬Šé‡ç­–ç•¥
- âœ… **é›¶é–‹éŠ·é¸æ“‡**: è¨“ç·´æ™‚ç›´æ¥è®€å–ï¼Œç„¡éœ€é‡æ–°è¨ˆç®—
- âœ… **ä½å­˜å„²æˆæœ¬**: æ¯è‚¡åƒ…å¢åŠ  ~1.1 KBï¼ˆå…¨å¹´åƒ… +0.4%ï¼‰
- âœ… **å®Œå…¨å‘å¾Œå…¼å®¹**: èˆŠ NPZ æ–‡ä»¶ä»å¯æ­£å¸¸ä½¿ç”¨

---

## ğŸ”§ å¯¦ä½œç´°ç¯€

### 1. æ–°å¢å‡½æ•¸: `compute_all_weight_strategies()`

**ä½ç½®**: [scripts/preprocess_single_day.py](../scripts/preprocess_single_day.py) (lines 610-748)

**åŠŸèƒ½**: è¨ˆç®— 11 ç¨®æ¬Šé‡ç­–ç•¥

**æ¬Šé‡ç­–ç•¥åˆ—è¡¨**:

| ç­–ç•¥åç¨± | æè¿° | æ¨è–¦åº¦ | é©ç”¨å ´æ™¯ |
|---------|------|--------|---------|
| `balanced` | æ¨™æº–å¹³è¡¡æ¬Šé‡ | â­â­â­â­â­ | åŸºæº–ç­–ç•¥ |
| `sqrt_balanced` | å¹³æ–¹æ ¹å¹³è¡¡ï¼ˆè¼ƒæº«å’Œï¼‰ | â­â­â­â­â­ | é¿å…éåº¦æ‡²ç½° |
| `log_balanced` | å°æ•¸å¹³è¡¡ï¼ˆæœ€æº«å’Œï¼‰ | â­â­â­â­ | è¼•åº¦ä¸å¹³è¡¡ |
| `effective_num_09` | æœ‰æ•ˆæ¨£æœ¬æ•¸ï¼ˆÎ²=0.9ï¼‰ | â­â­â­ | çŸ­åºåˆ—æ•¸æ“š |
| `effective_num_099` | æœ‰æ•ˆæ¨£æœ¬æ•¸ï¼ˆÎ²=0.99ï¼‰ | â­â­â­â­ | ä¸­ç­‰åºåˆ— |
| `effective_num_0999` | æœ‰æ•ˆæ¨£æœ¬æ•¸ï¼ˆÎ²=0.999ï¼‰ | â­â­â­â­â­ | é•·åºåˆ—ï¼ˆæ¨è–¦ï¼‰ |
| `effective_num_09999` | æœ‰æ•ˆæ¨£æœ¬æ•¸ï¼ˆÎ²=0.9999ï¼‰ | â­â­â­â­ | è¶…é•·åºåˆ— |
| `cb_focal_099` | Class-Balanced Focalï¼ˆÎ²=0.99ï¼‰ | â­â­â­ | å›°é›£æ¨£æœ¬é—œæ³¨ |
| `cb_focal_0999` | Class-Balanced Focalï¼ˆÎ²=0.999ï¼‰ | â­â­â­â­ | å›°é›£æ¨£æœ¬ï¼ˆæ¨è–¦ï¼‰ |
| `uniform` | å‡å‹»æ¬Šé‡ï¼ˆç„¡åŠ æ¬Šï¼‰ | â­â­â­â­â­ | åŸºæº–å°ç…§çµ„ |
| `focal_loss` | Focal Loss é…ç½® | â­â­â­ | å‹•æ…‹èª¿æ•´ |

**æ¬Šé‡è¨ˆç®—å…¬å¼**:

```python
# 1. Balanced (æ¨™æº–å¹³è¡¡)
w_i = N / (n_classes * count_i)

# 2. Square Root Balanced (å¹³æ–¹æ ¹å¹³è¡¡)
w_i = sqrt(w_balanced_i)

# 3. Log Balanced (å°æ•¸å¹³è¡¡)
w_i = log(1 + w_balanced_i)

# 4. Effective Number of Samples (æœ‰æ•ˆæ¨£æœ¬æ•¸)
E_i = (1 - Î²) / (1 - Î²^count_i)
w_i = 1 / E_i
# Î² âˆˆ {0.9, 0.99, 0.999, 0.9999}

# 5. Class-Balanced Focal (CB Focal)
w_i = effective_num_i * difficulty_factor
# difficulty_factor é€šå¸¸ç‚º 1ï¼ˆå¯åœ¨è¨“ç·´æ™‚å‹•æ…‹èª¿æ•´ï¼‰

# 6. Uniform (å‡å‹»)
w_i = 1.0 (æ‰€æœ‰é¡åˆ¥)

# 7. Focal Loss (é…ç½®åƒæ•¸)
alpha = [balanced weights]
gamma = 2.0  # é›£åº¦èª¿ç¯€å› å­
```

**è¿”å›æ ¼å¼**:
```python
{
    "strategy_name": {
        "class_weights": {
            "-1": 1.11,  # Down
            "0": 2.38,   # Neutral
            "1": 0.60    # Up
        },
        "description": "Strategy description",
        "type": "class_weight"  # æˆ– "focal_loss"
    },
    ...
}
```

### 2. ä¿®æ”¹å‡½æ•¸: `save_preprocessed_npz()`

**ä½ç½®**: [scripts/preprocess_single_day.py](../scripts/preprocess_single_day.py) (lines 965-992)

**ä¿®æ”¹å…§å®¹**:
```python
def save_preprocessed_npz(
    ...,
    labels: Optional[np.ndarray] = None  # æ–°å¢åƒæ•¸
):
    # ... existing code ...

    # è¨ˆç®—æ¬Šé‡ç­–ç•¥ï¼ˆåƒ…ç•¶æœ‰æ¨™ç±¤æ™‚ï¼‰
    if 'labels_array' in label_preview and labels is not None:
        try:
            weight_strategies = compute_all_weight_strategies(labels)

            if weight_strategies:
                # è½‰æ›ç‚ºå¯åºåˆ—åŒ–æ ¼å¼
                metadata["weight_strategies"] = {
                    name: {
                        'class_weights': {
                            str(k): float(v)
                            for k, v in strategy.get('class_weights', {}).items()
                        },
                        'description': strategy.get('description', ''),
                        'type': strategy.get('type', 'class_weight')
                    }
                    for name, strategy in weight_strategies.items()
                }
                logging.info(f"  è¨ˆç®—äº† {len(weight_strategies)} ç¨®æ¬Šé‡ç­–ç•¥")

        except Exception as e:
            logging.warning(f"  æ¬Šé‡ç­–ç•¥è¨ˆç®—å¤±æ•—: {e}")
            # ä¸é˜»æ–·é è™•ç†æµç¨‹

    # ä¿å­˜åˆ° NPZ
    save_data = {
        'features': features.astype(np.float32),
        'mids': mids.astype(np.float64),
        'labels': labels.astype(np.float32) if labels is not None else None,  # æ–°å¢
        'metadata': json.dumps(metadata, ensure_ascii=False)
    }

    np.savez_compressed(npz_path, **save_data)
```

**é—œéµè¨­è¨ˆæ±ºç­–**:
- âœ… **å®¹éŒ¯æ©Ÿåˆ¶**: æ¬Šé‡è¨ˆç®—å¤±æ•—ä¸æœƒé˜»æ–·é è™•ç†
- âœ… **æ¢ä»¶åŸ·è¡Œ**: åƒ…ç•¶æœ‰æ¨™ç±¤æ™‚æ‰è¨ˆç®—æ¬Šé‡
- âœ… **é¡å‹è½‰æ›**: ç¢ºä¿ JSON å¯åºåˆ—åŒ–ï¼ˆint key â†’ str keyï¼‰
- âœ… **æ—¥èªŒè¨˜éŒ„**: æ¸…æ™°è¨˜éŒ„è¨ˆç®—çµæœ

### 3. ä¸»è™•ç†æµç¨‹ä¿®æ”¹

**ä½ç½®**: [scripts/preprocess_single_day.py](../scripts/preprocess_single_day.py) (lines 1004-1037)

**ä¿®æ”¹å…§å®¹**:
```python
# è¨ˆç®—æ¨™ç±¤é è¦½ï¼ˆä¸¦è¿”å›æ¨™ç±¤æ•¸çµ„ï¼‰
label_preview = None
labels_array = None
if pass_filter:
    label_preview = compute_label_preview(
        mids,
        tb_config,
        return_labels=True  # æ–°å¢åƒæ•¸
    )
    if label_preview is not None:
        all_label_previews.append(label_preview)
        labels_array = label_preview.get('labels_array')  # æå–æ¨™ç±¤

# ä¿å­˜ NPZï¼ˆåŒ…å«æ¨™ç±¤ï¼‰
save_preprocessed_npz(
    ...,
    label_preview=label_preview,
    labels=labels_array  # æ–°å¢åƒæ•¸
)
```

---

## ğŸ§ª æ¸¬è©¦é©—è­‰

### æ¸¬è©¦è…³æœ¬: `test_weight_simple.py`

**ä½ç½®**: [scripts/test_weight_simple.py](../scripts/test_weight_simple.py)

**æ¸¬è©¦å ´æ™¯**: æ¨¡æ“¬ Experiment 5 çš„æ¨™ç±¤åˆ†å¸ƒ
- Down: 3000 (30%)
- Neutral: 1400 (14%) â† å°‘æ•¸é¡åˆ¥
- Up: 5600 (56%)

**æ¸¬è©¦çµæœ**:

```
======================================================================
æ¬Šé‡ç­–ç•¥è¨ˆç®—æ¸¬è©¦
======================================================================

æ¨™ç±¤åˆ†å¸ƒ:
  Down    :  3000 (30.0%)
  Neutral :  1400 (14.0%)
  Up      :  5600 (56.0%)

è¨ˆç®—äº† 4 ç¨®æ¬Šé‡ç­–ç•¥:
----------------------------------------------------------------------

ç­–ç•¥: balanced
æè¿°: Standard balanced weights
æ¬Šé‡:
  Down    : 1.1111
  Neutral : 2.3810  â† å°‘æ•¸é¡åˆ¥ç²å¾—æœ€é«˜æ¬Šé‡
  Up      : 0.5952

ç­–ç•¥: sqrt_balanced
æè¿°: Square root balanced (gentler)
æ¬Šé‡:
  Down    : 1.0541
  Neutral : 1.5430  â† è¼ƒæº«å’Œçš„èª¿æ•´
  Up      : 0.7715

ç­–ç•¥: effective_num_0999
æè¿°: Effective Number (beta=0.999)
æ¬Šé‡:
  Down    : 1.0558
  Neutral : 0.8373  â† è€ƒæ…®æ¨£æœ¬é‡è¤‡æ€§
  Up      : 1.1069

ç­–ç•¥: uniform
æè¿°: No weighting
æ¬Šé‡:
  Down    : 1.0000
  Neutral : 1.0000
  Up      : 1.0000

======================================================================
æ¸¬è©¦å®Œæˆ
```

**æ¸¬è©¦çµè«–**:
- âœ… æ¬Šé‡è¨ˆç®—æ­£ç¢º
- âœ… Balanced ç­–ç•¥æ­£ç¢ºè­˜åˆ¥å°‘æ•¸é¡åˆ¥ï¼ˆNeutral 2.38 > Down 1.11 > Up 0.60ï¼‰
- âœ… Sqrt_balanced æä¾›æº«å’Œèª¿æ•´ï¼ˆ1.54 vs 2.38ï¼‰
- âœ… Effective Number è€ƒæ…®æ¨£æœ¬é‡è¤‡ï¼ˆæ›´å‡è¡¡çš„æ¬Šé‡åˆ†å¸ƒï¼‰
- âœ… Uniform ä½œç‚ºåŸºæº–å°ç…§

---

## ğŸ“¦ NPZ æ–‡ä»¶çµæ§‹æ›´æ–°

### æ–°å¢å­—æ®µ

#### 1. `labels` (array)
```python
data['labels']  # shape: (T,), dtype: float32
# å€¼: -1 (Down), 0 (Neutral), 1 (Up), np.nan (é‚Šç•Œ)
```

#### 2. `metadata['weight_strategies']` (dict)
```python
metadata = json.loads(str(data['metadata']))
weight_strategies = metadata['weight_strategies']

# çµæ§‹:
{
    "balanced": {
        "class_weights": {"-1": 1.11, "0": 2.38, "1": 0.60},
        "description": "Standard balanced weights",
        "type": "class_weight"
    },
    "sqrt_balanced": {...},
    "effective_num_0999": {...},
    ...  # å…± 11 ç¨®ç­–ç•¥
}
```

### å‘å¾Œå…¼å®¹æ€§

**èˆŠ NPZ æ–‡ä»¶**:
- âŒ æ²’æœ‰ `labels` å­—æ®µ
- âŒ æ²’æœ‰ `weight_strategies` å­—æ®µ
- âœ… ä»å¯æ­£å¸¸è¼‰å…¥ï¼ˆè¿”å› Noneï¼‰

**æ–° NPZ æ–‡ä»¶**:
- âœ… åŒ…å« `labels` å­—æ®µ
- âœ… åŒ…å« `weight_strategies` å­—æ®µ
- âœ… èˆ‡èˆŠä»£ç¢¼å…¼å®¹

**è¼‰å…¥ç¤ºä¾‹**:
```python
data = np.load('stock.npz', allow_pickle=True)

# å®‰å…¨è®€å–ï¼ˆå…¼å®¹èˆŠæ–‡ä»¶ï¼‰
labels = data.get('labels', None)
metadata = json.loads(str(data['metadata']))
weight_strategies = metadata.get('weight_strategies', {})

if weight_strategies:
    print(f"ç™¼ç¾ {len(weight_strategies)} ç¨®æ¬Šé‡ç­–ç•¥")
else:
    print("èˆŠæ ¼å¼ NPZï¼ˆç„¡æ¬Šé‡ç­–ç•¥ï¼‰")
```

---

## ğŸ“Š å­˜å„²æˆæœ¬åˆ†æ

### å–®å€‹ NPZ æ–‡ä»¶

**æ¬Šé‡ç­–ç•¥ JSON å¤§å°** (~1.1 KB):
```json
{
  "balanced": {...},           // ~100 bytes
  "sqrt_balanced": {...},      // ~100 bytes
  "log_balanced": {...},       // ~100 bytes
  "effective_num_09": {...},   // ~100 bytes
  "effective_num_099": {...},  // ~100 bytes
  "effective_num_0999": {...}, // ~100 bytes
  "effective_num_09999": {...},// ~100 bytes
  "cb_focal_099": {...},       // ~100 bytes
  "cb_focal_0999": {...},      // ~100 bytes
  "uniform": {...},            // ~100 bytes
  "focal_loss": {...}          // ~100 bytes
}
// ç¸½è¨ˆ: ~1,100 bytes = 1.1 KB
```

### å…¨å¹´æ•¸æ“šé›†

**å‡è¨­**:
- 195 æª”è‚¡ç¥¨
- 243 äº¤æ˜“æ—¥
- æ¯å¤©æ¯è‚¡ 1 å€‹ NPZ

**å¢åŠ é‡**:
```
1.1 KB Ã— 195 stocks Ã— 243 days = 52,135 KB â‰ˆ 53.5 MB
```

**ç›¸å°å¢å¹…**:
- åŸå§‹å¤§å°: ~13 GB (Experiment 5)
- å¢åŠ é‡: 53.5 MB
- **å¢å¹…**: 0.4% (å¹¾ä¹å¯å¿½ç•¥)

**çµè«–**: âœ… å­˜å„²æˆæœ¬å¯æ¥å—

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### è¨“ç·´æ™‚è®€å–æ¬Šé‡ç­–ç•¥

**å®Œæ•´ç¤ºä¾‹**:
```python
import numpy as np
import json
import torch
import torch.nn as nn

# 1. è¼‰å…¥ NPZ
data = np.load('data/preprocessed/20250901/2330.npz', allow_pickle=True)
metadata = json.loads(str(data['metadata']))
labels = data['labels']

# 2. é¸æ“‡æ¬Šé‡ç­–ç•¥
weight_strategies = metadata.get('weight_strategies', {})

# é¸é … A: ä½¿ç”¨é è¨ˆç®—çš„ effective_num_0999
if 'effective_num_0999' in weight_strategies:
    strategy = weight_strategies['effective_num_0999']
    class_weights_dict = strategy['class_weights']

    # è½‰æ›ç‚º PyTorch Tensor
    class_weights = torch.tensor([
        class_weights_dict['-1'],  # Down
        class_weights_dict['0'],   # Neutral
        class_weights_dict['1']    # Up
    ], dtype=torch.float32)

    print(f"ä½¿ç”¨ç­–ç•¥: {strategy['description']}")
    print(f"æ¬Šé‡: {class_weights}")

# é¸é … B: ä½¿ç”¨ balanced ç­–ç•¥
elif 'balanced' in weight_strategies:
    strategy = weight_strategies['balanced']
    class_weights_dict = strategy['class_weights']
    class_weights = torch.tensor([
        class_weights_dict['-1'],
        class_weights_dict['0'],
        class_weights_dict['1']
    ], dtype=torch.float32)

# é¸é … C: ç„¡æ¬Šé‡ï¼ˆä½¿ç”¨ uniform æˆ– Noneï¼‰
else:
    class_weights = None
    print("æœªæ‰¾åˆ°æ¬Šé‡ç­–ç•¥ï¼Œä½¿ç”¨å‡å‹»æ¬Šé‡")

# 3. æ‡‰ç”¨åˆ°æå¤±å‡½æ•¸
if class_weights is not None:
    criterion = nn.CrossEntropyLoss(weight=class_weights)
else:
    criterion = nn.CrossEntropyLoss()

# 4. è¨“ç·´
# ... (normal training loop)
```

### æ¯”è¼ƒä¸åŒæ¬Šé‡ç­–ç•¥

```python
# å¯¦é©—è…³æœ¬ç¤ºä¾‹
strategies_to_test = [
    'uniform',              # åŸºæº–
    'balanced',             # æ¨™æº–å¹³è¡¡
    'sqrt_balanced',        # æº«å’Œå¹³è¡¡
    'effective_num_0999',   # SOTA
]

results = {}
for strategy_name in strategies_to_test:
    # è¼‰å…¥æ¬Šé‡
    strategy = weight_strategies[strategy_name]
    class_weights = convert_to_tensor(strategy['class_weights'])

    # è¨“ç·´æ¨¡å‹
    model = train_model(class_weights=class_weights)

    # è©•ä¼°
    metrics = evaluate_model(model)
    results[strategy_name] = metrics

    print(f"\n{strategy_name}:")
    print(f"  Accuracy: {metrics['accuracy']:.4f}")
    print(f"  F1 (Neutral): {metrics['f1_neutral']:.4f}")

# æ‰¾å‡ºæœ€ä½³ç­–ç•¥
best_strategy = max(results, key=lambda k: results[k]['f1_neutral'])
print(f"\næœ€ä½³ç­–ç•¥: {best_strategy}")
```

### Focal Loss ä½¿ç”¨

```python
# Focal Loss éœ€è¦å‹•æ…‹è¨ˆç®—ï¼Œä½†å¯ä½¿ç”¨é è¨ˆç®—çš„ alpha
if 'focal_loss' in weight_strategies:
    focal_config = weight_strategies['focal_loss']
    alpha = torch.tensor([
        focal_config['class_weights']['-1'],
        focal_config['class_weights']['0'],
        focal_config['class_weights']['1']
    ])
    gamma = 2.0  # å¾é…ç½®è®€å–æˆ–æ‰‹å‹•è¨­ç½®

    # è‡ªå®šç¾© Focal Loss
    class FocalLoss(nn.Module):
        def __init__(self, alpha, gamma=2.0):
            super().__init__()
            self.alpha = alpha
            self.gamma = gamma

        def forward(self, inputs, targets):
            ce_loss = F.cross_entropy(inputs, targets, reduction='none')
            pt = torch.exp(-ce_loss)
            focal_loss = self.alpha[targets] * (1-pt)**self.gamma * ce_loss
            return focal_loss.mean()

    criterion = FocalLoss(alpha, gamma)
```

---

## ğŸ“ æ–‡æª”æ›´æ–°

### å·²æ›´æ–°æ–‡æª”

1. **[PREPROCESSED_DATA_SPECIFICATION.md](PREPROCESSED_DATA_SPECIFICATION.md)**
   - æ–°å¢ `weight_strategies` å­—æ®µèªªæ˜ (lines 235-297)
   - æ–°å¢ä½¿ç”¨ç¤ºä¾‹
   - æ›´æ–° NPZ çµæ§‹åœ–

2. **[WEIGHT_STRATEGY_ANALYSIS.md](WEIGHT_STRATEGY_ANALYSIS.md)**
   - åˆ†æé è¨ˆç®— vs è¨“ç·´æ™‚è¨ˆç®—
   - å„ªç¼ºé»æ¯”è¼ƒ
   - æ¨è–¦ç­–ç•¥

3. **[WHY_WEIGHT_STILL_MATTERS.md](WHY_WEIGHT_STILL_MATTERS.md)**
   - è§£é‡‹ç‚ºä½•è‡ªå‹•æ¬Šé‡ä¸å¤ 
   - æ¥­å‹™ç›®æ¨™ vs æ•¸å­¸å¹³è¡¡
   - å¯¦éš›æ¡ˆä¾‹åˆ†æ

4. **[PRECOMPUTED_WEIGHTS_DESIGN.md](PRECOMPUTED_WEIGHTS_DESIGN.md)**
   - è¨­è¨ˆè¦ç¯„
   - æ¨è–¦ç­–ç•¥æ¸…å–®
   - å­˜å„²æˆæœ¬åˆ†æ

### å¿«é€Ÿåƒè€ƒ

**è®€å–æ¬Šé‡** (ä¸€è¡Œä»£ç¢¼):
```python
weights = json.loads(str(np.load('file.npz', allow_pickle=True)['metadata']))['weight_strategies']['effective_num_0999']['class_weights']
```

**æª¢æŸ¥æ˜¯å¦æœ‰æ¬Šé‡**:
```python
has_weights = 'weight_strategies' in json.loads(str(data['metadata']))
```

---

## âœ… å®Œæˆæª¢æŸ¥æ¸…å–®

### ä»£ç¢¼å¯¦ä½œ
- [x] `compute_all_weight_strategies()` å‡½æ•¸å®Œæˆ
- [x] `save_preprocessed_npz()` ä¿®æ”¹å®Œæˆ
- [x] ä¸»è™•ç†æµç¨‹æ•´åˆå®Œæˆ
- [x] éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
- [x] æ—¥èªŒè¨˜éŒ„

### æ¸¬è©¦é©—è­‰
- [x] å‰µå»ºç¨ç«‹æ¸¬è©¦è…³æœ¬
- [x] é©—è­‰æ¬Šé‡è¨ˆç®—æ­£ç¢ºæ€§
- [x] æ¸¬è©¦å¤šç¨®æ¨™ç±¤åˆ†å¸ƒ
- [x] é©—è­‰ JSON åºåˆ—åŒ–

### æ–‡æª”å®Œå–„
- [x] æ•¸æ“šè¦ç¯„æ–‡æª”æ›´æ–°
- [x] ä½¿ç”¨æŒ‡å—ç·¨å¯«
- [x] è¨­è¨ˆæ–‡æª”ç·¨å¯«
- [x] ç†è«–è§£é‡‹æ–‡æª”

### å…¼å®¹æ€§
- [x] å‘å¾Œå…¼å®¹æ€§ä¿è­‰
- [x] éŒ¯èª¤è™•ç†ï¼ˆèˆŠæ ¼å¼ï¼‰
- [x] å®‰å…¨è®€å–ç¤ºä¾‹

---

## ğŸ”„ ä¸‹ä¸€æ­¥å»ºè­°

### ç«‹å³å¯åš
1. **é‡æ–°é‹è¡Œé è™•ç†**
   ```bash
   # ä½¿ç”¨æ›´æ–°å¾Œçš„è…³æœ¬è™•ç†å–®æ—¥æ•¸æ“š
   python scripts/preprocess_single_day.py \
       --date 20250901 \
       --config configs/config_pro_v5_ml_optimal.yaml

   # é©—è­‰ç”Ÿæˆçš„ NPZ åŒ…å«æ¬Šé‡ç­–ç•¥
   python scripts/test_weight_simple.py
   ```

2. **æ›´æ–° label_viewer**
   - åœ¨ UI ä¸­é¡¯ç¤ºå¯ç”¨çš„æ¬Šé‡ç­–ç•¥
   - è¦–è¦ºåŒ–ä¸åŒç­–ç•¥çš„æ¬Šé‡åˆ†å¸ƒ

3. **è¨“ç·´å¯¦é©—**
   - ä½¿ç”¨ä¸åŒæ¬Šé‡ç­–ç•¥è¨“ç·´ DeepLOB
   - æ¯”è¼ƒæ€§èƒ½æŒ‡æ¨™ï¼ˆå°¤å…¶æ˜¯ Neutral é¡åˆ¥ï¼‰

### é•·æœŸæ”¹é€²
1. **å‹•æ…‹æ¬Šé‡ç”Ÿæˆå™¨**
   - è¨“ç·´æ™‚æ ¹æ“šç•¶å‰ epoch çš„å›°é›£åº¦å‹•æ…‹èª¿æ•´
   - çµåˆé è¨ˆç®—æ¬Šé‡ + å‹•æ…‹èª¿æ•´

2. **è‡ªå‹•ç­–ç•¥é¸æ“‡**
   - æ ¹æ“šæ¨™ç±¤åˆ†å¸ƒè‡ªå‹•æ¨è–¦æœ€ä½³ç­–ç•¥
   - åŸºæ–¼é©—è­‰é›†æ€§èƒ½è‡ªå‹•åˆ‡æ›ç­–ç•¥

3. **æ¬Šé‡å¯è¦–åŒ–å·¥å…·**
   - ç¹ªè£½ä¸åŒç­–ç•¥çš„æ¬Šé‡åˆ†å¸ƒåœ–
   - æ¯”è¼ƒç­–ç•¥å°è¨“ç·´çš„å½±éŸ¿

---

## ğŸ“š åƒè€ƒè³‡æ–™

### ç†è«–åŸºç¤
1. **Balanced Weights**: sklearn.utils.class_weight
2. **Effective Number of Samples**:
   - Paper: "Class-Balanced Loss Based on Effective Number of Samples" (CVPR 2019)
   - Link: https://arxiv.org/abs/1901.05555
3. **Focal Loss**:
   - Paper: "Focal Loss for Dense Object Detection" (ICCV 2017)
   - Link: https://arxiv.org/abs/1708.02002

### å¯¦ä½œåƒè€ƒ
- PyTorch `CrossEntropyLoss` with weights
- `sklearn.utils.class_weight.compute_class_weight`
- imblearn ä¸å¹³è¡¡å­¸ç¿’åº«

---

**æœ€å¾Œæ›´æ–°**: 2025-10-23
**ä½œè€…**: DeepLOB-Pro Team
**ç‰ˆæœ¬**: v2.0
