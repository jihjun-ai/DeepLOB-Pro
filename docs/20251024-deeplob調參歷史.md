# DeepLOB èª¿åƒæ­·å²è¨˜éŒ„

æ¯æ¬¡ä¿ç•™æ•¸æ“šåŠæˆæžœ,ç°¡è¦èªªæ˜Ž(å…¶ä»–å»¢è©±ä¸ç”¨),é€™æ˜¯æ”¹ä¸‹æ¬¡èª¿åƒåƒè€ƒç”¨

## æ ¼å¼:

**æ—¥æœŸ**:
**é…ç½®**:
**çµæžœ**:
**å•é¡Œ**:
**çµè«–**:
---

## å¯¦é©— 1: é¦–æ¬¡è¨“ç·´ï¼ˆé…ç½®éŒ¯èª¤ï¼‰

**æ—¥æœŸ**: 2025-10-24

**é…ç½®**:
```yaml
batch_size: 384
lr: 0.000004
weight_decay: 0.001
dropout: 0.7
warmup_ratio: 0.40
epochs: 30
grad_clip: 0.8
sched: cosine
eta_min: 3.0e-6

# âŒ éŒ¯èª¤é…ç½®
data:
  train: "data/processed_v6/npz/stock_embedding_train.npz"  # V6 ä¸å­˜åœ¨ï¼
```

**çµæžœ**:
| Epoch | Train Loss | Val Loss | Train Acc | Val Acc | Val F1 (W) | LR | Grad |
|-------|------------|----------|-----------|---------|------------|-----|------|
| 1 | 1.1093 | 1.1102 | 34.32% | 30.77% | 0.2036 | ~0 | 1.69 |
| 2 | 1.0940 | 1.0950 | 35.66% | **32.23%** | 0.3128 | ~1e-6 | 1.30 |
| 3 | 1.0858 | 1.0918 | 37.53% | 30.23% | 0.2675 | ~1e-6 | 1.57 |
| 4 | 1.0773 | 1.0966 | 39.23% | 28.93% | 0.2372 | ~1e-6 | 2.18 |
| 5 | 1.0678 | 1.1069 | 40.93% | 28.81% | 0.2339 | ~2e-6 | 2.80 |
| 6 | 1.0564 | 1.1010 | 42.73% | 30.33% | 0.2589 | ~2e-6 | 3.49 |
| 7 | 1.0421 | 1.1042 | 44.67% | 30.90% | 0.2649 | ~2e-6 | 4.29 |

**å•é¡Œ**:
1. **é…ç½®éŒ¯èª¤** âŒ: æ•¸æ“šè·¯å¾‘æŒ‡å‘ä¸å­˜åœ¨çš„ `processed_v6`
2. **æ€§èƒ½æ¥µå·®**: Val Acc æœ€é«˜åƒ… 32.23%ï¼ˆæ‡‰é” 51%+ï¼‰
3. **åš´é‡éŽæ“¬åˆ**: Train Acc å¾ž 34% å‡åˆ° 45%ï¼ŒVal Acc åè€Œä¸‹é™
4. **Val Loss æƒ¡åŒ–**: å¾ž 1.0950 (Epoch 2) ä¸Šå‡åˆ° 1.1042 (Epoch 7)
5. **F1 æ¥µä½Ž**: 0.20-0.31ï¼ˆå¹¾ä¹Žç„¡é æ¸¬èƒ½åŠ›ï¼‰

**æ ¹æœ¬åŽŸå› **:
- **æ•¸æ“šè·¯å¾‘éŒ¯èª¤**: é…ç½®æŒ‡å‘ V6ï¼Œä½†å¯¦éš›åªæœ‰ V7 æ•¸æ“š
- è¨“ç·´éŽç¨‹å¯èƒ½ä½¿ç”¨äº†éŒ¯èª¤/ç¼ºå¤±çš„æ•¸æ“š
- æˆ–è¨“ç·´è…³æœ¬æœ‰ fallback æ©Ÿåˆ¶ä½†æ•¸æ“šè³ªé‡å·®

**è§£æ±ºæ–¹æ¡ˆ**:
âœ… å·²ä¿®æ­£é…ç½® â†’ `data/processed_v7/npz/*`

**V7 æ•¸æ“šç¢ºèª**:
- è¨“ç·´æ¨£æœ¬: 1,017,054
- æ¨™ç±¤åˆ†å¸ƒ: 30.86% / 42.96% / 26.19%ï¼ˆå¥åº·ï¼‰

**çµè«–**: âŒ å¯¦é©—ç„¡æ•ˆï¼ˆé…ç½®éŒ¯èª¤ï¼‰ï¼Œéœ€é‡æ–°è¨“ç·´

---

## å¯¦é©— 2: ä¿®æ­£é…ç½®å¾Œé‡è¨“ï¼ˆå¾…åŸ·è¡Œï¼‰

**æ—¥æœŸ**: 2025-10-24

**é…ç½®**:
```yaml
batch_size: 384
lr: 0.000004
weight_decay: 0.001
dropout: 0.7
warmup_ratio: 0.40
epochs: 30
patience: 5
grad_clip: 0.8
sched: cosine
eta_min: 3.0e-6
min_delta: 0.0008

# âœ… ä¿®æ­£å¾Œé…ç½®
data:
  train: "data/processed_v7/npz/stock_embedding_train.npz"
  val: "data/processed_v7/npz/stock_embedding_val.npz"
  test: "data/processed_v7/npz/stock_embedding_test.npz"
```

**é æœŸç›®æ¨™**ï¼ˆåŸºæ–¼å¯¦é©— 5/6 åƒè€ƒï¼‰:
- âœ… Val Acc > 51%ï¼ˆé¦–æ¬¡æ‡‰é” 50%+ï¼‰
- âœ… Val F1 (Weighted) > 0.47
- âœ… Grad Norm < 4.5ï¼ˆå…¨ç¨‹ï¼‰
- âœ… Train/Val å·®è· < 10%ï¼ˆå¥åº·æ³›åŒ–ï¼‰
- âœ… Val Loss ç©©å®šä¸‹é™ï¼ˆä¸åå½ˆï¼‰

**åœæ­¢è¦å‰‡**:
- ðŸ”¥ Grad Norm > 6.0 é€£çºŒ 2 epochs â†’ é™ lr æˆ– batch
- ðŸ”¥ Val Loss ä¸Šå‡ > 10% from best â†’ æ—©åœå¤±æ•ˆ
- ðŸ”¥ Train/Val å·®è· > 15% â†’ éŽæ“¬åˆ

**çµæžœ**: âŒ æœªåŸ·è¡Œï¼ˆç™¼ç¾æ•¸æ“šæ¨™æº–åŒ–å•é¡Œï¼‰

**æ ¹æœ¬åŽŸå› è¨ºæ–·**:
1. **æ•¸æ“šå®Œå…¨æœªæ¨™æº–åŒ–**:
   - èˆŠæ•¸æ“š: Min=0, Max=2571, Mean=81.9, Std=101.5 âŒ
   - é æœŸ: Meanâ‰ˆ0, Stdâ‰ˆ1, Range: -5~+5

2. **å•é¡Œæºé ­**:
   - `preprocess_single_day.py`: åªä¿å­˜åŽŸå§‹ LOB æ•¸æ“šï¼ˆæœªæ¨™æº–åŒ–ï¼‰
   - `extract_tw_stock_data_v7.py`: å®šç¾©äº† `zscore_apply()` ä½†å¾žæœªèª¿ç”¨ âŒ

3. **å½±éŸ¿**:
   - æ¨¡åž‹æŽ¥æ”¶åŽŸå§‹åƒ¹æ ¼æ•¸æ“šï¼ˆ0~2571ï¼‰
   - æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
   - å­¸ç¿’çŽ‡ä¸åŒ¹é…
   - Val Acc 32%ã€F1 0.31ï¼ˆå®Œå…¨ç„¡æ³•å­¸ç¿’ï¼‰

---

## å¯¦é©— 2b: ä¿®å¾© V7 æ¨™æº–åŒ–ï¼ˆ2025-10-24ï¼‰â­â­â­

**æ—¥æœŸ**: 2025-10-24

**ä¿®å¾©å…§å®¹**:

1. **ä¿®æ”¹ `extract_tw_stock_data_v7.py` (ç¬¬ 685-707 è¡Œ)**:
```python
# ðŸ†• V7 ä¿®å¾©ï¼šæ·»åŠ æ¨™æº–åŒ–æ­¥é©Ÿ
norm_config = config.get('normalization', {})
norm_method = norm_config.get('method', 'rolling_zscore')
norm_window = norm_config.get('window', 100)
norm_min_periods = norm_config.get('min_periods', 20)

# æ‡‰ç”¨æ¨™æº–åŒ–
if norm_method == 'rolling_zscore':
    concat_features = zscore_apply(
        concat_features, mu=None, sd=None,
        method='rolling_zscore',
        window=norm_window, min_periods=norm_min_periods
    )
```

2. **é‡æ–°ç”Ÿæˆè¨“ç·´æ•¸æ“š**:
```bash
# å‚™ä»½èˆŠæ•¸æ“š
mv data/processed_v7 data/processed_v7_old

# é‡æ–°ç”Ÿæˆï¼ˆä½¿ç”¨ä¿®å¾©å¾Œçš„ V7 è…³æœ¬ï¼‰
python scripts/extract_tw_stock_data_v7.py \
    --preprocessed-dir ./data/preprocessed_swing \
    --output-dir ./data/processed_v7 \
    --config configs/config_pro_v7_optimal.yaml \
    --json ./data/dataset_selection.json
```

**é©—è­‰çµæžœ**: âœ… æ¨™æº–åŒ–æˆåŠŸ
```
Train: Min=-9.96, Max=9.96, Mean=0.01, Std=1.44  âœ…
Val:   Min=-9.96, Max=9.96, Mean=-0.01, Std=1.43 âœ…
Test:  Min=-9.96, Max=9.96, Mean=0.05, Std=1.45  âœ…
```

**æ•¸æ“šè¦æ¨¡**:
- Train: 1,017,054 æ¨£æœ¬
- Val: 163,725 æ¨£æœ¬
- Test: 169,047 æ¨£æœ¬
- æ¨™ç±¤åˆ†å¸ƒ: Down 30.9%, Neutral 43.0%, Up 26.2%ï¼ˆå¥åº·ï¼‰

**çµè«–**: âœ… æ•¸æ“šæ¨™æº–åŒ–å•é¡Œå·²å¾¹åº•ä¿®å¾©ï¼Œå¯ä»¥é‡æ–°è¨“ç·´

---

## å¯¦é©— 3: ä½¿ç”¨æ­£ç¢ºæ¨™æº–åŒ–æ•¸æ“šè¨“ç·´ï¼ˆå¾…åŸ·è¡Œï¼‰

**æ—¥æœŸ**: 2025-10-24

**é…ç½®**: ï¼ˆèˆ‡å¯¦é©— 2 ç›¸åŒï¼Œä½†ä½¿ç”¨ä¿®å¾©å¾Œçš„æ•¸æ“šï¼‰
```yaml
batch_size: 384
lr: 0.000004
weight_decay: 0.001
dropout: 0.7
warmup_ratio: 0.40
epochs: 30
patience: 5
grad_clip: 0.8
sched: cosine
eta_min: 3.0e-6
min_delta: 0.0008

# âœ… æ•¸æ“šå·²æ­£ç¢ºæ¨™æº–åŒ–
data:
  train: "data/processed_v7/npz/stock_embedding_train.npz"
  val: "data/processed_v7/npz/stock_embedding_val.npz"
  test: "data/processed_v7/npz/stock_embedding_test.npz"
```

**é æœŸç›®æ¨™**ï¼ˆåŸºæ–¼å¯¦é©— 5 åƒè€ƒï¼‰:
- âœ… Val Acc > 51%ï¼ˆæ­£ç¢ºæ•¸æ“šæ‡‰é”æ¨™ï¼‰
- âœ… Val F1 (Weighted) > 0.47
- âœ… Grad Norm < 4.5ï¼ˆå…¨ç¨‹ï¼‰
- âœ… Train/Val å·®è· < 10%ï¼ˆå¥åº·æ³›åŒ–ï¼‰
- âœ… Val Loss ç©©å®šä¸‹é™ï¼ˆä¸åå½ˆï¼‰

**è¨“ç·´æŒ‡ä»¤**:
```bash
python scripts\train_deeplob_v5.py --config configs\train_v5.yaml --data-dir data\processed_v7\npz
```

**çµæžœ**: ï¼ˆå¾…è¨“ç·´å¾Œè£œå……ï¼‰

---

