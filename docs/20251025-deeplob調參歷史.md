# DeepLOB 調參歷史記錄

每次保留數據及成果,簡要說明(其他廢話不用),這是改下次調參參考用

## 格式:

**日期**:
**配置**:
**結果**:
**問題**:
**結論**:

---

## V7 實驗 1 (重新開始,V7 數據)

**日期**: 2025-10-25

**數據**: V7 (processed_v7, 更乾淨、無重複計算、標籤一致性高)

**配置**:

```yaml
# 模型容量 (降低)
conv_filters: 32 (48→32, -33%)
lstm_hidden: 48 (64→48, -25%)
dropout: 0.75 (0.70→0.75, +7%)

# 優化器 (慢學習+強正則)
lr: 1e-6 (2.5e-6→1e-6, -60%) ⭐⭐⭐
weight_decay: 0.002 (0.001→0.002, +100%) ⭐⭐⭐
batch_size: 256 (512→256, -50%)

# 學習率調度
warmup_ratio: 0.30 (0.20→0.30)
eta_min: 3e-7 (1e-6→3e-7)

# 訓練策略
epochs: 15 (20→15)
patience: 1 (2→1) ⭐⭐⭐
label_smoothing: 0.02 (0.015→0.02)
```

**先前結果** (實驗 6b 配置在 V7 數據):

```
Epoch 1: Train 45.03% | Val 49.33% | F1 0.4748 | Grad 1.24
Epoch 2: Train 48.40% | Val 49.78% | F1 0.4850 | Grad 1.32
Epoch 3: Train 50.54% | Val 50.09% | F1 0.4871 | Grad 1.67 ⭐ 最佳
Epoch 4: Train 52.82% | Val 49.98% | F1 0.4883 | Grad 2.25
Epoch 5: Train 55.76% | Val 49.20% | F1 0.4777 | Grad 3.34
Epoch 6: Train 59.23% | Val 47.93% | F1 0.4742 | Grad 5.12 ❌
```

**問題**:

1. 嚴重過擬合: Epoch 3 後 Train-Val Gap 從 0.45% → 11.30%
2. Val 性能惡化: Val Acc 50.09% → 47.93% (-2.16%)
3. 梯度持續增長: 1.24 → 5.12 (4.1倍)
4. 最佳點過早: Epoch 3 就達峰值

**根本原因**:

- V7 數據更"乾淨"(無重複計算、標籤一致性高)
- V5/V6 的配置是針對"髒數據"優化的
- 乾淨數據 + 大容量模型 + 高學習率 = 快速過擬合

**改進策略**:

1. 降低模型容量 (32 filters, 48 hidden)
2. 大幅降低學習率 (-60%)
3. 大幅提高正則化 (dropout +7%, weight_decay +100%)
4. 極激進早停 (patience=1)

**預期效果**:

- Epoch 3-5 達最佳
- Val Acc 52-55%
- Train-Val Gap < 5%
- 梯度 < 3.0

---

## 
