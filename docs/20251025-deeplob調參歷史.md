# DeepLOB 調參歷史記錄

每次保留數據及成果,簡要說明(其他廢話不用),這是改下次調參參考用

## 格式:

**日期**:
**配置**:
**結果**:
**問題**:
**結論**:

---

## V7 實驗 1 (重新開始,V7 數據)

**日期**: 2025-10-25

**數據**: V7 (processed_v7, 更乾淨、無重複計算、標籤一致性高)

**配置**:

```yaml
# 模型容量 (降低)
conv_filters: 32 (48→32, -33%)
lstm_hidden: 48 (64→48, -25%)
dropout: 0.75 (0.70→0.75, +7%)

# 優化器 (慢學習+強正則)
lr: 1e-6 (2.5e-6→1e-6, -60%) ⭐⭐⭐
weight_decay: 0.002 (0.001→0.002, +100%) ⭐⭐⭐
batch_size: 256 (512→256, -50%)

# 學習率調度
warmup_ratio: 0.30 (0.20→0.30)
eta_min: 3e-7 (1e-6→3e-7)

# 訓練策略
epochs: 15 (20→15)
patience: 1 (2→1) ⭐⭐⭐
label_smoothing: 0.02 (0.015→0.02)
```

**先前結果** (實驗 6b 配置在 V7 數據):

```
Epoch 1: Train 45.03% | Val 49.33% | F1 0.4748 | Grad 1.24
Epoch 2: Train 48.40% | Val 49.78% | F1 0.4850 | Grad 1.32
Epoch 3: Train 50.54% | Val 50.09% | F1 0.4871 | Grad 1.67 ⭐ 最佳
Epoch 4: Train 52.82% | Val 49.98% | F1 0.4883 | Grad 2.25
Epoch 5: Train 55.76% | Val 49.20% | F1 0.4777 | Grad 3.34
Epoch 6: Train 59.23% | Val 47.93% | F1 0.4742 | Grad 5.12 ❌
```

**問題**:

1. 嚴重過擬合: Epoch 3 後 Train-Val Gap 從 0.45% → 11.30%
2. Val 性能惡化: Val Acc 50.09% → 47.93% (-2.16%)
3. 梯度持續增長: 1.24 → 5.12 (4.1倍)
4. 最佳點過早: Epoch 3 就達峰值

**根本原因**:

- V7 數據更"乾淨"(無重複計算、標籤一致性高)
- V5/V6 的配置是針對"髒數據"優化的
- 乾淨數據 + 大容量模型 + 高學習率 = 快速過擬合

**改進策略**:

1. 降低模型容量 (32 filters, 48 hidden)
2. 大幅降低學習率 (-60%)
3. 大幅提高正則化 (dropout +7%, weight_decay +100%)
4. 極激進早停 (patience=1)

**預期效果**:
- Epoch 3-5 達最佳
- Val Acc 52-55%
- Train-Val Gap < 5%
- 梯度 < 3.0

**結果** (實際訓練):
```
Epoch 1: Train 40.58% | Val 48.60% | F1 0.4520 | Grad 1.75
Epoch 5: Train 48.86% | Val 49.54% | F1 0.4890 | Grad 2.10
Epoch 6: Train 50.13% | Val 49.74% | F1 0.4928 | Grad 2.62
Epoch 7: Train 51.41% | Val 50.18% | F1 0.4932 | Grad 3.18 ⭐ Val Acc 最佳
Epoch 8: Train 52.73% | Val 49.95% | F1 0.4949 | Grad 3.81 ⭐ Val F1 最佳
Epoch 9: Train 53.97% | Val 49.65% | F1 0.4887 | Grad 4.46 ❌ 過擬合
```

**成果**:
- ✅ Val Acc 提升: 50.09% → 50.18% (+0.09%)
- ✅ Val F1 提升: 0.4871 → 0.4949 (+0.0078)
- ✅ 最佳點延後: Epoch 3 → Epoch 7-8 (延後 4-5 epochs)
- ✅ 過擬合改善: Gap 11.30% → 4.32% (-6.98%)
- ✅ 梯度控制: 5.12 → 4.46 (-0.66)

**仍存在問題**:
- ⚠️ Epoch 7-9: Gap 從 1.23% 快速惡化到 4.32%
- ⚠️ 梯度持續增長: 1.75 → 4.46 (2.5倍)
- ⚠️ Val F1 在 Epoch 8 達峰後下降

**結論**:
- 降低模型容量 + 降低學習率 **有效延緩過擬合**
- 但學習率 1e-6 仍偏高, 需進一步降低到 7e-7
- 正則化需加強 (dropout 0.80, weight_decay 0.003)

---

## V7 實驗 2

**日期**: 2025-10-25

**數據**: V7 (同實驗 1)

**配置** (基於實驗 1 改進):
```yaml
# 正則化 (極限)
batch_size: 128 (256→128, -50%) ⭐
dropout: 0.80 (0.75→0.80, +7%)
label_smoothing: 0.03 (0.02→0.03, +50%)

# 優化器 (超慢學習)
lr: 7e-7 (1e-6→7e-7, -30%) ⭐⭐⭐
weight_decay: 0.003 (0.002→0.003, +50%) ⭐⭐⭐
grad_clip: 1.5 (2.0→1.5, -25%)

# 學習率調度
warmup_ratio: 0.40 (0.30→0.40, 前 8/20 epochs)
warmup_start_factor: 0.15 (0.2→0.15, 起點 1e-7)
eta_min: 2e-7 (3e-7→2e-7)

# 訓練策略
epochs: 20 (15→20, 超慢需更長)
patience: 2 (1→2)
```

**改進重點**:
- 學習率降到接近極限 (7e-7)
- 正則化接近極限 (dropout 0.80, weight_decay 0.003)
- Batch size 128 (梯度噪音更大防過擬合)

**預期效果**:
- Epoch 8-12 達最佳
- Val Acc > 50.5%
- Train-Val Gap < 3%
- 梯度 < 3.5

---

## 
