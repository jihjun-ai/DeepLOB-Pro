# 為何數據健檢通過，但訓練仍然失敗？

**日期**: 2025-10-22
**核心問題**: 數據通過 `stability_check.py` 和 `data_health_check.py`，為何訓練時仍出現嚴重過擬合？

---

## 🔍 問題分析

### 實際數據狀況

**標籤分布** (訓練集 7,564,697 樣本):
```
Down:     3,454,588  (45.7%)
Neutral:  1,133,146  (15.0%)  🚨
Up:       2,976,963  (39.4%)

最大類別占比: 45.7%
不平衡比: 3.05x (Down / Neutral)
```

### 健檢結果

#### `data_health_check.py` 判定：✅ 通過

**檢查項目與閾值**:
```python
# 檢查 1: 標籤不平衡檢查
if max_pct < 60:  # 最大類別 < 60%
    status = "✅ 通過"
    # 實際: 45.7% < 60% → PASS

# 檢查 1: 失衡程度檢查
if max_pct >= 90:
    status = "❌ 極度失衡"
elif max_pct >= 70:
    status = "⚠️ 嚴重失衡"
elif max_pct >= 60:
    status = "⚠️ 中度失衡"
else:
    status = "✅ 相對均衡"
    # 實際: 45.7% < 60% → 相對均衡

# 不平衡比檢查（隱含）
# 通常認為 < 5x 可接受
# 實際: 3.05x < 5x → PASS
```

**結論**: 從數據質量角度，這份數據確實「可以學」（有信號、無洩漏、樣本充足）

---

## ❓ 核心矛盾

### 健檢標準 vs 訓練需求

| 項目 | 健檢閾值 | 實際值 | 健檢判定 | 訓練需求 | 訓練判定 |
|------|---------|--------|---------|---------|---------|
| **最大類別占比** | < 60% | 45.7% | ✅ 通過 | < 40% | ❌ 失敗 |
| **最小類別占比** | > 10%? | 15.0% | ✅ 通過 | > 25% | ❌ 失敗 |
| **不平衡比** | < 5x | 3.05x | ✅ 通過 | < 2x | ❌ 失敗 |
| **標籤熵** | > 0.8 | ~0.88 | ✅ 通過 | > 0.95 | ⚠️ 勉強 |

### 關鍵發現

**健檢標準**: 「數據有學習價值」（Data is learnable）
- 有明確任務
- 無未來資訊洩漏
- 樣本量充足
- 分布不極端（< 60% 就算均衡）

**訓練需求**: 「模型能有效學習」（Model can learn effectively）
- 每個類別都有足夠樣本
- 類別分布相對平衡（< 40% 主流）
- 避免模型偏向多數類
- 少數類有足夠代表性

---

## 📊 為何通過健檢但訓練失敗？

### 原因 1: 健檢閾值過於寬鬆 ⭐⭐⭐⭐⭐

**`data_health_check.py` 的判定邏輯**:

```python
# Line 169-182
max_pct = pcts.max()

if max_pct >= 90:
    status = "❌ 極度失衡"
    results['balance_status'] = "severe_imbalance"
    results['pass'] = False
elif max_pct >= 70:
    status = "⚠️ 嚴重失衡"
    results['balance_status'] = "high_imbalance"
    results['pass'] = False
elif max_pct >= 60:
    status = "⚠️ 中度失衡"
    results['balance_status'] = "moderate_imbalance"
    results['pass'] = False
else:
    status = "✅ 相對均衡"
    results['balance_status'] = "balanced"
    # ← 45.7% 被判定為「相對均衡」
```

**問題診斷**:
- 60% 閾值太寬鬆（適用於 2 分類，不適用於 3 分類）
- 3 分類理想分布: 33.3% / 33.3% / 33.3%
- 實際分布: 45.7% / 15.0% / 39.4%（嚴重偏離）
- 但仍被判定為「相對均衡」

**建議修正**（針對 3 分類）:
```python
if num_classes == 3:
    ideal_pct = 100 / 3  # 33.3%
    max_deviation = max_pct - ideal_pct

    if max_deviation > 20:  # > 53.3%
        status = "❌ 極度失衡"
    elif max_deviation > 12:  # > 45.3%
        status = "⚠️ 嚴重失衡"  # ← 45.7% 應該落在這裡
    elif max_deviation > 7:   # > 40.3%
        status = "⚠️ 中度失衡"
    else:
        status = "✅ 相對均衡"
```

---

### 原因 2: 健檢未考慮訓練動態 ⭐⭐⭐⭐

**`data_health_check.py` 檢查的是靜態數據質量**:
- ✅ 特徵與標籤有相關性（檢查 5: 基準對比）
- ✅ 無未來資訊洩漏（檢查 2）
- ✅ 樣本量充足（檢查 3）
- ✅ 分布穩定（檢查 4）

**但未檢查訓練動態行為**:
- ❌ 模型是否會偏向多數類？
- ❌ 少數類是否會被忽略？
- ❌ 梯度是否穩定？
- ❌ 過擬合風險？

**實際訓練時發生**:
```
Epoch 1-5 的動態:
- 模型快速記住訓練集 (Train Acc: 44% → 67%)
- 但驗證集幾乎不進步 (Val Acc: 43% → 46%)
- 模型策略: 大量預測 Down (45.7%)，忽略 Neutral (15%)
- 結果: Val Loss 爆炸, 過擬合
```

---

### 原因 3: 健檢未模擬實際訓練條件 ⭐⭐⭐

**健檢使用的模型**: Logistic Regression
- 簡單線性模型
- 不容易過擬合
- 對不平衡相對魯棒（使用 `class_weight='balanced'`）

**實際訓練使用**: DeepLOB (CNN-LSTM)
- 複雜深度模型
- 容易過擬合
- 對不平衡敏感（即使有 `class_weight`）

**差異導致**:
```python
# 健檢: Logistic Regression 在 3.05x 不平衡下仍能學習
clf = LogisticRegression(class_weight='balanced')
# Train Acc: ~55%, Test Acc: ~53%
# → 判定「數據可學」✅

# 實際: DeepLOB 在 3.05x 不平衡下嚴重過擬合
model = DeepLOB(...)
# Train Acc: 67%, Val Acc: 46%（差距 21%）
# → 實際「訓練失敗」❌
```

---

### 原因 4: `stability_check.py` 檢查的是時間穩定性，不是平衡性

**`stability_check.py` 的目的**:
```python
# 驗證必要條件 4: 訊號非瞬時幻覺（有可遷移的穩定性）
#
# 檢驗項：
# 1. 滾動回測 (Rolling Backtest)
# 2. IC 穩定性分析
# 3. 學習曲線
# 4. 特徵重要度穩定性
```

**檢查重點**:
- ✅ 訊號在不同時間段是否穩定？
- ✅ 今天學到的規律，明天是否仍有效？
- ✅ AUC > 0.5, IC > 0, 正比例 > 60%

**不檢查**:
- ❌ 標籤分布是否平衡
- ❌ 訓練是否會過擬合
- ❌ 模型是否偏向某一類

**結論**: 穩定性通過 ≠ 訓練無問題

---

## 🎯 總結：健檢 vs 訓練成功的差異

### 健檢關注的問題

| 問題 | 檢查項目 | 實際狀況 |
|------|---------|---------|
| **數據有問題嗎?** | 未來洩漏、噪音、極端不平衡 | ✅ 無問題 |
| **數據可學嗎?** | 基準模型準確率、特徵相關性 | ✅ 可學 (LR 達 53%) |
| **訊號穩定嗎?** | 時間遷移性、滾動回測 AUC | ✅ 穩定 (AUC > 0.5) |

### 訓練成功的額外要求

| 問題 | 要求 | 實際狀況 |
|------|-----|---------|
| **分布夠平衡嗎?** | 3 類接近 33.3% | ❌ 45.7/15.0/39.4 |
| **少數類夠多嗎?** | 每類 > 25% | ❌ Neutral 僅 15% |
| **模型會過擬合嗎?** | Train/Val 差距 < 10% | ❌ 差距 21% |
| **需要特殊處理嗎?** | 平衡採樣、調整權重 | ❌ 未啟用 |

---

## 💡 解決方案

### 方案 1: 更新健檢標準（長期）

**修改 `data_health_check.py`**，針對 3 分類問題：

```python
# 更嚴格的平衡檢查（3 分類）
if num_classes == 3:
    ideal = 100 / 3  # 33.3%
    deviations = np.abs(pcts - ideal)
    max_dev = deviations.max()

    if max_dev > 15:  # 任一類偏離 > 15%
        status = "⚠️ 不適合深度學習"
        results['pass'] = False
        results['warning'] = "建議重新生成數據或啟用平衡採樣"
    elif max_dev > 10:
        status = "⚠️ 需要平衡採樣"
        results['pass'] = True
        results['require_balance_sampler'] = True
    else:
        status = "✅ 平衡良好"
```

**新增檢查項目**:
```python
# 檢查 6: 訓練可行性檢查（模擬 DeepLOB 訓練）
def check_training_feasibility(X, y, weights):
    """
    使用簡化版 DeepLOB 檢查是否會過擬合
    """
    # 1. 切分 train/val (80/20)
    # 2. 訓練簡單 MLP（模擬深度學習）
    # 3. 檢查 train/val 差距
    # 4. 如果差距 > 15%，警告需要調整
```

---

### 方案 2: 調整訓練策略（短期）⭐⭐⭐⭐⭐

**不修改健檢，而是調整訓練**：

#### 2.1 啟用平衡採樣器

```yaml
# train_v5.yaml
dataloader:
  balance_sampler:
    enabled: true  # ← 強制每個 batch 類別平衡
```

**效果**: 即使數據不平衡 (45.7/15.0/39.4)，每個 batch 也接近 (33/33/33)

#### 2.2 降低 batch size

```yaml
dataloader:
  batch_size: 256  # 512 → 256
```

**原因**: 平衡採樣時，需要從少數類 (15%) 大量重複採樣，小 batch 更穩定

#### 2.3 增強正則化

```yaml
model:
  dropout: 0.6  # 0.5 → 0.6

optim:
  weight_decay: 0.001  # 0.0005 → 0.001
```

---

### 方案 3: 重新生成平衡數據（根本）⭐⭐⭐⭐⭐

**調整 Triple-Barrier 參數**，讓標籤分布更接近 30/40/30:

```yaml
# config_pro_v5_ml_optimal.yaml
triple_barrier:
  pt_multiplier: 2.5  # 3.5 → 2.5 (更容易觸發邊界 → 更多 up/down)
  sl_multiplier: 2.5
  min_return: 0.0025  # 0.0015 → 0.0025 (更高閾值 → 更多 neutral)
```

**重新生成數據**:
```bash
python scripts\extract_tw_stock_data_v6.py ^
    --preprocessed-dir .\data\preprocessed_v5 ^
    --output-dir .\data\processed_v6_balanced ^
    --config .\configs\config_pro_v5_ml_optimal.yaml
```

**驗證新分布**:
```bash
# 期望: Down 28-35%, Neutral 35-45%, Up 28-35%
```

**優點**:
- 從源頭解決問題
- 訓練更穩定
- 不需要特殊處理

---

## 📋 行動檢查清單

### 立即行動（使用現有數據）

- [ ] 修改 `train_v5.yaml`:
  - [ ] `balance_sampler.enabled: true`
  - [ ] `batch_size: 256`
  - [ ] `dropout: 0.6`
  - [ ] `weight_decay: 0.001`
- [ ] 重新訓練 20 epochs
- [ ] 監控 Train/Val 差距是否 < 10%
- [ ] 檢查 Val F1 是否 > 0.55

### 長期優化（重新生成數據）

- [ ] 調整 `config_pro_v5_ml_optimal.yaml`:
  - [ ] `pt_multiplier: 2.5`
  - [ ] `min_return: 0.0025`
- [ ] 重新生成數據（8 分鐘）
- [ ] 驗證標籤分布接近 30/40/30
- [ ] 重新訓練
- [ ] 預期 Val F1 > 0.60

### 改進健檢腳本（可選）

- [ ] 更新 `data_health_check.py`:
  - [ ] 針對 3 分類調整閾值
  - [ ] 新增「訓練可行性」檢查
  - [ ] 輸出「建議啟用平衡採樣」警告
- [ ] 更新文檔說明健檢局限性

---

## ✅ 結論

### 核心問題

**健檢標準 ≠ 訓練成功標準**

- **健檢**: 數據質量合格（無洩漏、有信號、樣本充足）
- **訓練**: 模型能有效學習（分布平衡、不過擬合、少數類有效）

### 為何會有落差？

1. **閾值設計差異**: 健檢 60% vs 訓練 40%
2. **檢查目的不同**: 健檢關注數據問題，訓練關注學習效果
3. **模型複雜度不同**: 健檢用 LR，訓練用 DeepLOB
4. **未模擬訓練動態**: 健檢是靜態分析，訓練有動態過擬合

### 解決之道

**短期**（1 小時）:
```bash
# 啟用平衡採樣 + 降低 batch size + 增強正則化
# 預期改善: Val F1 0.40 → 0.55
```

**長期**（3 小時）:
```bash
# 調整 TB 參數 → 重新生成平衡數據 → 訓練
# 預期改善: Val F1 0.40 → 0.60+
```

---

**最後更新**: 2025-10-22
**關鍵啟示**: 通過健檢只是第一步，訓練成功還需要更嚴格的條件
