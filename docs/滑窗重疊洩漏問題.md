# 滑窗重疊洩漏問題

**日期**: 2025-10-21
**問題**: 即使使用時間序列切分，洩漏測試仍然失敗

---

## 🔍 問題發現

### 時間序列切分已正確實施 ✅

數據生成日誌顯示：
```
時間序列切分:
  訓練日期: 20250901 ~ 20250909 (7天)
  驗證日期: 20250910 ~ 20250911 (2天)
  測試日期: 20250912 ~ 20250912 (1天)
```

### 但洩漏測試仍失敗 ❌

```
檢查 2: 未來資訊洩漏測試
  基準模型（正常對齊）: 準確率 0.594 (59.4%)
  測試 A: 時間打亂標籤:    準確率 0.538 (53.8%)
  下降幅度: 0.056 (5.6%)
  結果: ❌ 失敗 - 打亂後仍高準確率，可能有洩漏
```

**期望**: 下降幅度 > 10%（打亂後應接近隨機 33%）
**實際**: 下降幅度僅 5.6%（打亂後仍 53.8%）

---

## 🎯 根本原因：滑窗重疊洩漏

### 問題機制

即使訓練集和測試集**按時間完全分離**，滑窗重疊仍會導致**同一集合內部洩漏**！

### 視覺化說明

**當前實作**（步長 = 1）：
```
同一天內的滑窗（例如 Day 1）:
t=0    [特徵0, 特徵1, ..., 特徵99] → 標籤99
t=1    [特徵1, 特徵2, ..., 特徵100] → 標籤100
t=2    [特徵2, 特徵3, ..., 特徵101] → 標籤101
       └────── 99% 特徵重疊！ ──────┘
```

### 洩漏原理

1. **特徵高度相似**
   ```python
   window_1 = [特徵0, 特徵1, ..., 特徵99]
   window_2 = [特徵1, 特徵2, ..., 特徵100]
   相關性 = 99/100 = 99%
   ```

2. **模型學到錯誤模式**
   - 模型學習：「相似特徵 → 相似標籤」
   - 而非真正的：「特徵模式 → 價格變動」

3. **打亂標籤仍有效**
   ```
   打亂前：
   window_1 → label_1
   window_2 → label_2 (應該相似，因為特徵相似)

   打亂後：
   window_1 → label_X
   window_2 → label_Y (可能不同，但模型仍能猜對一部分)
   ```

   **原因**: 模型利用「特徵間的相似性」來預測，而非真正理解價格變動

---

## 🛠️ 解決方案：增加滑窗步長

### 修改 1: 配置文件

**文件**: `configs/config_pro_v5_ml_optimal.yaml`

```yaml
data:
  seq_len: 100
  slide_step: 10  # 新增！滑窗步長

  # 說明：
  #   - slide_step=1:   步長 1（99% 重疊，可能洩漏）
  #   - slide_step=10:  步長 10（90% 減少，降低洩漏）
  #   - slide_step=100: 步長 100（無重疊，但樣本數大減）
  #   - 推薦值：10（平衡洩漏風險與樣本數）
```

### 修改 2: 代碼實現

**文件**: `scripts/extract_tw_stock_data_v6.py`

**修改位置**: 第 867-909 行（滑窗生成）

```python
# 舊代碼（步長 = 1）
for t in range(SEQ_LEN - 1, max_t):
    window_start = t - SEQ_LEN + 1
    # ...

# 新代碼（可配置步長）
slide_step = config.get('data', {}).get('slide_step', 1)
for t in range(SEQ_LEN - 1, max_t, slide_step):  # 加上步長！
    window_start = t - SEQ_LEN + 1
    # ...
```

### 影響分析

| 步長 | 重疊率 | 樣本數影響 | 洩漏風險 | 推薦度 |
|------|--------|-----------|---------|--------|
| 1    | 99%    | 100%      | ⚠️ 高    | ❌     |
| 5    | 95%    | 20%       | ⚠️ 中    | ⭐⭐⭐ |
| 10   | 90%    | 10%       | ✅ 低    | ⭐⭐⭐⭐⭐ |
| 50   | 50%    | 2%        | ✅ 極低  | ⭐⭐⭐  |
| 100  | 0%     | 1%        | ✅ 無    | ⭐⭐   |

**推薦**: `slide_step=10`
- 樣本數減少至 10%（約 90 萬樣本，仍足夠）
- 重疊率降至 90%（相關性大幅下降）
- 預期洩漏測試通過（下降幅度 > 15%）

---

## 📊 預期改善

### 樣本數變化

**修正前**（步長 = 1）:
```
訓練集: ~6,300,000 樣本
驗證集: ~1,950,000 樣本
測試集: ~900,000 樣本
```

**修正後**（步長 = 10）:
```
訓練集: ~630,000 樣本（減少 90%）
驗證集: ~195,000 樣本
測試集: ~90,000 樣本
```

**說明**: 樣本數雖減少，但仍遠超過深度學習訓練需求（通常 10 萬樣本已足夠）

### 洩漏測試預期

**修正前**:
```
基準準確率: 59.4%
打亂後準確率: 53.8%
下降幅度: 5.6% ❌
```

**修正後**（預期）:
```
基準準確率: 50-55%（可能略降）
打亂後準確率: 33-40%（接近隨機）
下降幅度: > 15% ✅
```

### 相鄰窗口相關性

**修正前**（步長 = 1）:
```
window_1 與 window_2 的特徵相關性: 0.99（99%）
```

**修正後**（步長 = 10）:
```
window_1 與 window_2 的特徵相關性: 0.10（10%）
```

---

## 🎯 執行計畫

### 步驟 1: 修改配置 ✅

```bash
# 已完成
# 新增 data.slide_step: 10
```

### 步驟 2: 修改代碼 ✅

```bash
# 已完成
# 修改滑窗生成邏輯，支持可配置步長
```

### 步驟 3: 重新生成數據 ⏳

```bash
conda activate deeplob-pro
python scripts/extract_tw_stock_data_v6.py \
    --preprocessed-dir ./data/preprocessed_v5_1hz \
    --output-dir ./data/processed_v6_final \
    --config ./configs/config_pro_v5_ml_optimal.yaml
```

**預計時間**: ~10-15 分鐘（樣本數減少，速度更快）

### 步驟 4: 驗證改善

```bash
python scripts/data_health_check.py \
    --train-npz data/processed_v6_final/npz/stock_embedding_train.npz \
    --val-npz data/processed_v6_final/npz/stock_embedding_val.npz \
    --test-npz data/processed_v6_final/npz/stock_embedding_test.npz \
    --output-dir data/processed_v6_final/health_check
```

**驗收標準**:
- ✅ 檢查 2（洩漏測試）: 下降幅度 > 10%
- ✅ 檢查 4（穩定性）: PSI < 0.1
- ✅ 總體評估: 通過

---

## 💡 關鍵洞察

### 1. 時間切分不夠

**僅按時間切分訓練/測試集是不夠的！**

```
✅ 訓練集（Day 1-7）和測試集（Day 10）時間分離
❌ 訓練集**內部**的 Day 1 仍有滑窗重疊洩漏
```

### 2. 滑窗重疊是獨立問題

**滑窗重疊洩漏 ≠ 時間洩漏**

- **時間洩漏**: 訓練集包含測試集的未來信息
  - 解決: 時間序列切分 ✅

- **滑窗洩漏**: 相鄰樣本特徵高度相似
  - 解決: 增加滑窗步長 ✅

### 3. 兩者必須同時解決

```
只用時間切分:     洩漏測試仍失敗 ❌
只用滑窗步長:     可能有時間洩漏 ❌
兩者都用:         洩漏完全消除 ✅
```

---

## 🔗 相關文檔

- [數據洩漏問題解決方案](數據洩漏問題解決方案.md) - 時間洩漏部分
- [2025-10-21_數據質量改進記錄](2025-10-21_數據質量改進記錄.md) - 完整改進記錄

---

**最後更新**: 2025-10-21
**狀態**: 代碼修改完成，待重新生成數據驗證
**下一步**: 執行步驟 3（重新生成數據）
